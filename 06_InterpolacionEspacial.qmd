---
title: "Interpolación espacial en R"
subtitle: "Geoestadística i Tècniques d'Observació Global (24/25)" 
author: "Aitor Ameztegui (UdL)"
date: "last-modified"
format: 
    html:
        theme: cerulean
        toc: true
editor_options: 
  chunk_output_type: console
---

## Introducción y objetivo

Hasta ahora, hemos trabajado de varias maneras con el fichero de estaciones meteorólogicas del valle del Ebro (`estaciones.shp`). En primer lugar, extrajimos los valores de temperatura, así como una serie de predictores (elevación, distancia al Atlántico...) para ajustar modelos de regresión lineal. También utilizamos predictores continuos para generar mapas de temperatura espacialmente continuos, más allá de las zonas donde hay estaciones. Ahora haremos algo parecido, pero en vez de usar las variables explicativas (elevación, etc.) como predictores, vamos a utilizar los valores de temperatura medidos, así como su distribución espacial, para generar mapas continuos de temperatura. Es el proceso que se conoce como **interpolación espacial**, y veremos varios métodos. Pero antes de nada, debemos cargar las librerías y ficheros de datos necesarios. En este caso, además de los paquetes típicos que solemos usar (`tmap`, `sf`, `terra`...) usaremos la librería `gstat`

```{r, warning=F, message=F}
library(tmap)
library(sf)
library(terra)
library(gstat)


estaciones <- st_read('data/meteo/meteo_espacial/estaciones_meteo.shp')

```

Y podemos visualizar los datos, como hemos visto en otras unidades:

```{r}
tm_shape(estaciones) +
    tm_dots(col="Tmed_MES", size=0.25, title = "Temp. media (ºC)") +
    tm_text("Tmed_MES", just="left", xmod=.5, size = 0.7) +
    tm_legend(legend.outside=TRUE)
```

Existen varios métodos de interpolación de información espacial, y se suelen clasificar en métodos *determinísticos* y métodos *geoestadísticos*. Los primeros simplemente realizan una inferencia de la información entre dos puntos "suavizando" la diferencia de valores entre ellos, mientras que los métodos geoestadísticos utilizan las propiedades estadísticas de los valores para realizar la interpolación. Veamos en primer lugar los métodos determinísticos:

## Métodos determinísticos de interpolación

Exploraremos dos métodos determinísticos: **vecino más próximo** (aka **Thiessen**) y técnicas basadas en asignar pesos según el **inverso de la distancia** (**IDW**, de las siglas en inglés de *inverse distance weighted*).

### Método de polígonos de Thiessen o Voronoi (nearest neighbor interpolation)

Es el método más simple (y más antiguo) de interpolación. Lo introdujo Alfred H. Thiessen hace más de un siglo. El procedimiento consiste en asignar, a cada punto del territorio no muestreado (para el que no tenemos información), el valor del punto muestreado más próximo. Esto genera una superficie **teselada** en el que las lineas que separan las teselas corresponden a la mitad de la distancia entre dos puntos. Estas líneas se conectan, de manera que cada área comprende uno de los puntos de la muestra.

Veamos como hacerlo en R, usando la función `voronoi()` de la librería `dismo`:

```{r}
library(dismo)
thiessen <- voronoi(x = st_coordinates(estaciones))
```

Veamos el objeto que ha generado esta función:

```{r}
plot(thiessen) +
points(estaciones, pch = 19)
```

::: {#note style="background: #F5F5DC"}
**NOTA:** ArcMap también ofrece la posibilidad de realizar una interpolación por polígonos de Thiessen, mediante la función `Natural neighbor` que se encuentra dentro del módulo *Spatial Analyst/Interpolation.*
:::

### Inverse Distance Weighted (IDW)

El método IDW calcula un valor para cada punto sin él usando valores de los vecinos más próximos. Los pesos asignados a cada vecino son proporcionales a su cercanía al punto del que se quiere obtener el valor, y se pueden modular con el parámetro del exponente. Cuanto mayor sea dicho parámetro, más peso tendrán los puntos cercanos.

Para poder aplicar el idw, debemos, en primer lugar, crear un grid vacío a partir de un raster, al que después asignaremos los valores que determine la función. Para crear dicho grid y raster debemos seguir los siguientes pasos:

```{r}
# Creamos el raster vacío, con la misma extensión y crs que nuestros datos
r <- rast(ext(estaciones), crs = crs(estaciones))

# Definimos la resolución de este raster
res(r) <- 1000

# Lo convertimos a grid mediante la función `st_as_stars()` del paquete `stars`
library(stars)
grid <- st_as_stars(r, na.rm = FALSE)

```

Una vez generado el objeto `grid` podemos generar la interpolación, usando la función `idw()`, del paquete `gstat()`. Esta función tiene una notación parecida a la de la regresión, ya que debemos especificar una fórmula (en este caso `Tmed_MES ~ 1`), el dataset donde estan los datos (`estaciones`), y el objeto para el que queremos generar la interpolación (`grid`)

```{r}
idw <- idw(formula = Tmed_MES ~ 1, locations = estaciones, newdata = grid)
```

Sin embargo, este objeto no tiene el formato `SpatRaster`, sino que es un objeto de tipo `stars` que contiene tanto la predicción como la varianza:

```{r}
idw
```

Para poder visualizar el resultado debemos convertirlo a `SpatRaster`:

```{r}
idw_raster <- rast(as(idw, "Raster"))
```

Ahora podemos visualizar fácilmente los resultados de la interpolación con `plot()`:

```{r}
plot(idw_raster$var1.pred)
```

Y añadir los puntos observados:

```{r}
plot(idw_raster$var1.pred)
points(estaciones, pch = 19, cex = 0.8) 
#text(estaciones, label= "Tmed_MES", cex = 0.8, pos = 2)
```

Con esto ya habríamos completado la interpolación espacial usando el método IDW. Podríamos jugar con varios de los parámetros de la función: el número máximo de vecinos a considerar (`nmax`), o el exponente a usar en la fórmula (`idp`). Por ejemplo, si usamos un exponente alto:

```{r}
idw_raster2 <- idw(formula = Tmed_MES ~ 1, locations = estaciones, newdata = grid, idp = 15)
plot(idw_raster2)
```

Y si usamos uno muy bajo:

```{r}

idw_raster3 <- idw(formula = Tmed_MES ~ 1, locations = estaciones, newdata = grid, idp = 0.0001)
plot(idw_raster3)
```

Esto es todo lo que necesitamos saber sobre la interpolación mediante IDW. Este es uno de los métodos más usados, debido a que es simple y en la mayor parte de los casos funciona muy bien. Sin embargo, la elección del exponente no deja de ser subjetiva, y como acabamos de ver puede tener un efecto muy grande en las predicciones. Hay un segundo tipo de interpolaciones que usan la información espacial de los puntos (información de 1r y 2º orden) para derivar modelos probabilísticos con los valores predichos. Son los llamados métodos geoestadísticos.

::: {style="background: #F5F5DC"}
**NOTA:** ArcGis y QGis también ofrecen la posibilidad de realizar una interpolación por IDW. En ArcGis Pro se puede hacer mediante la función `IDW` que se encuentra dentro del módulo *Spatial Analyst/Interpolation*. Esta función nos permite seleccionar el exponente de la ecuación, el radio de búsqueda de vecinos, definir obstáculos... En QGis se puede obtener mediante la herramienta *Spatial Analysis/Interpolation*.
:::

## Métodos geoestadísticos (kriging)

Tras aprender cómo interpolar siguiendo dos de los métodos determinísticos más típicos (polígonos de Thiessen e IDW), es el turno de los métodos geoestadísticos, entre los que el *kriging* es sin duda el más popular. Esta técnica se basa en modelos probabilísticos para calcular el valor de la variable respuesta en cualquier punto. El kriging se basa en el semivariograma de la variable que se quiere interpolar para ajustar y parametrizar un modelo, así que podríamos decir que funciona mejor cuanto mayor sea la autocorrelación espacial de la variable a interpolar. Es un método que además de generar las predicciones, ofrece también una estimación del error cometido en dichas estimación, lo que nos permite evaluar la calidad de la interpolación. Por último, permite un alto grado de personalización, de manera que con un ajuste adecuado de los parámetros se generan predicciones muy buenas.

El proceso es similar al que hemos visto en el ejemplo del IDW, Debemos generar un raster en "blanco" al que luego asignaremos los valores resultantes de la interpolación. La diferencia es que la interpolación por*kriging* se basa en el semivariograma, y por tanto, debemos generarlo. Los pasos a seguir serán por tanto:

1.  Obtener el semivariograma empírico a partir de nuestros datos
2.  Determinar los parámetros (rank, nugget, sill) del semivariograma teórico
3.  Ajustar el semivariograma teórico
4.  Ajustar el modelo de *kriging*

### Crear el semivariograma observado

Podemos hacerlo directamente a partir de nuestro fichero de puntos, utilizando la función `variogram()`. Esta función ploteará el semivariograma a partir de los puntos observados, y podremos determinar los parámetros del semivariograma teórico (rank, nugget, sill). La sintaxis de la función `variogram()` es similar a la que hemos visto en IDW o en los modelos de regresión.

Mediante el argumento `formula` podemos definir el tipo de kriging a aplicar (los más típicos son **ordinary kriging** y **universal kriging**). En este ejemplo implementaremos un **ordinary kriging**, por lo que la fórmula será del tipo (`<variable> ~ 1`). No lo veremos aquí, pero en caso de querer interpilar usando el *universal kriging* la fórmula sería: `<variable> ~ x + y`.

Creemos por tanto el variograma empírico:

```{r}
ve <- variogram(Tmed_MES ~ 1, estaciones)
```

Y podemos visualizarlo:

```{r}
plot(ve, plot.numbers = T)

```

### Determinar los parámetros del semivariograma teórico

También podemos inspeccionar el objeto `ve` que acabamos de crear, para determinar los valores de *nugget*, *sill* y *rank* del semivariograma teórico que tendremos que ajustar:

```{r}
ve
```

El *nugget* será el mínimo valor de `gamma` (en este caso, 0.3919), el *sill* se alcanza cuando *gamma* se estabiliza (3.27518), y el *range* será la distancia a la que se alcanza el *sill* (51476.26). Estos números los emplearemos en el siguiente paso, cuando ajustemos el semivariograma teórico.

### Ajustar el semivariograma teórico

Para este paso debemos modelizar una curva que ajuste lo mejor posible los valores del semivariograma empírico. Para ello, debemos seleccionar la forma que queremos que tenga el semivariograma, y asignarle los parámetros que hemos definido antes. Podemos acceder al catálogo de formas disponibles mediante:

```{r}
show.vgms()
```

En este caso vamos a seleccionar la curva de tipo "Exp", y la aplicaremos con la función `fit.variogram()`:

```{r}
vt <- fit.variogram(ve, vgm(psill = 3.27518, model = "Exp", range = 51476.26, nugget = 0.3919))
vt
```

Ahora podemos plotearlo, a ver si realmente ajusta bien:

```{r}
plot(ve, pl = T, model = vt)
```

Vemos que, efectivamente, el ajuste es bastante bueno, por lo que nos conformamos con el semivariograma teórico ajustado.

### Aplicar el modelo de kriging a los datos:

A partir de aquí el procedimiento es similar al que hemos visto para *IDW*: debemos crear un raster vacío con la extensión del área a analizar, y después le asignaremos los valores generados por el kriging. Como antes ya hemos generado el objeto `grd`, no necesitamos volver a hacerlo, y podemos generar la interpolación, de forma similar a la que hemos visto antes, usando la función `krige()`:

```{r}

k <- krige(Tmed_MES ~ 1, locations = estaciones, newdata = grid, model = vt)
```

El objeto generado (`k`) contiene mucha información, pero nos interesa los valores de temperatura predichos para cada punto (columna `var1.pred`), y la varianza (precisión) de las predicciones (columna `var1.var`). Igual que antes, debemos transformar este objeto a uno de tipo `SpatRaster`

```{r}
k2 <- rast(as(k, "Raster"))

```

Veamos el aspecto de la interpolación generada:

```{r}
plot(k2$var1.pred, main = "Predicción")
```

Incluso podemos representar encima los puntos observados:

```{r}
plot(k2$var1.pred, main = "Predicció")
points(estaciones, pch = 19, cex = 0.8) 
```

Echemos ahora un vistazo a la precisión de las predicciones:

```{r}
plot(k2$var1.var, main = "Varianza")
points(estaciones, pch = 19, cex = 0.8) 
```

Vemos que el error es mínimo en cada una de las observaciones, y mayor en las zonas donde hay espacios grandes sin datos de estaciones.

Existe una función que automatiza todo el proceso de ajuste del modelo de kriging, de manera que no hay que determinar los parámetros, la forma, etc. manualmente. Si estáis pensando que podía haber explicado este método desde el principio, tened en cuenta que es importante entender cómo se genera el proceso antes de realizarlo de manera automática. La función en cuestión es `autoKrige()`, del paquete `automap`:

```{r}
library(automap)
autok <- autoKrige(Tmed_MES ~ 1, estaciones,  grid)

autok$var_model
```

Además, nos genera un output muy adecuado con sólo usar la función `plot()`

```{r}
plot(autok)
```

::: {style="background: #F5F5DC"}
**NOTA**: ArcGIS y QGis también ofrece la posibilidad de realizar una interpolación por kriging, mediante la función `Kriging` que se encuentra dentro del módulo *Spatial Analyst/Interpolation* o *Spatial Analysis/Interpolation*
:::

Esto es todo lo que necesitamos saber de la interpolación mediante kriging. El hecho de que permita optimizar los parámetros y que nos proporciones estimaciones de la precisión hacen sin duda del *kriging* el método de interpolación más completo y utilizado.

### Otros ajustes de kriging

El modelo de kriging que hemos usado hasta ahora es un kriging ordinario, lo que se indica al ajustar la función `krige()`, indicando `Tmed_MES ~ 1`. Para seleccionar otro tipo de kriging, podemos cambiar la notación de esa fórmula, de acuerdo a lo siguiente:

-   Kriging simple: `Z ~ 1` (requiere definir el parámetro `beta`
-   Kriging ordinario: `Z ~ 1`
-   Kriging universal: `Z ~ x + y`

Veamos por ejemplo cual sería el resultado de un ajuste por kriging universal, el método más común:

```{r}
estaciones$x <- st_coordinates(estaciones)[,1]
estaciones$y <- st_coordinates(estaciones)[,2]

uk <- krige(Tmed_MES~ x + y, locations = estaciones, newdata = grid, model = vt)

uk2 <- rast(as(uk, "Raster"))
 
plot(uk2$var1.pred, main = "Predicción por Universal kriging")

auto_uk <- autoKrige(Tmed_MES ~ x + y, estaciones,  grid)
plot(auto_uk)
```

## Validación y métricas de calidad de los modelos de interpolación

Tras haber interpolado en base a dos métodos (IDW y kriging) se hace necesario evaluar cómo de buenas son esas interpolaciones. Esto lo haremos mediante una validación cruzada y el cálculo de una serie de métricas de calidad del modelo:

### Validación cruzada

La validación cruzada consiste en comparar, para cada valor de la muestra (cada observación) la diferencia entre el valor observado y el predicho por el modelo. Sin embargo, no podemos incluir el punto u observación que queremos evaluar, ya que si no la predicción sería exactamente igual a la observación. Por ello, lo que se hace es ir excluyendo una a una las observaciones, y se determina cuál sería el valor predicho para ese punto por un modelo elaborado con todos los demás puntos. Esto se hace de manera repetitiva - iterativa - con todos los puntos de la muestra, y al final tendremos una serie de valores (residuos) de la diferencia entre el valor observado y el predicho.

`R` nos pone fácil realizar la validación cruzada, a través de la función `krige.cv()`, del paquete `gstat`. Dicha función requiere como entrada un objeto de tipo `gstat` en el argumento `model`:

```{r}
idw_cv <- krige.cv(formula = Tmed_MES ~ 1, locations = estaciones) 

```

Una vez ajustado, podemos acceder a los datos:

```{r}
idw_cv
```

Y por tanto representar el gráfico de valores observados y predichos:

```{r}
plot(idw_cv$observed, idw_cv$var1.pred, main = "Observed vs. predicted for IDW") +
abline(0,1)
```

Esto mismo lo podemos hacer para el modelo de interpolado mediante ordinary kriging:

```{r}
ok_cv <- krige.cv(formula = Tmed_MES ~ 1, locations = estaciones,  model = vt)
plot(ok_cv$observed, ok_cv$var1.pred, main = "Observed vs. predicted for Ordinary kriging") +
abline(0,1)
```

... o el de universal kriging

```{r}
uk_cv <- krige.cv(Tmed_MES~x+y, locations = estaciones,  model = vt)
plot(uk_cv$observed, uk_cv$var1.pred, main = "Observed vs. predicted for Universal kriging") +
abline(0,1)
```

### Métricas de calidad

La validación cruzada ya es una pista muy buena de si la interpolación que hemos generado es adecuada o no, ya que nos permite evaluar los sesgos en las predicciones - una predicción no sesgada debería ajustarse de manera simétrica y cercana a la recta 1:1 entre valores observados y predichos-. Pero hay maneras más cuantitativas de realizar una evaluación de la calidad del modelo. Para ello podemos calcular algunos indicadores o métricas:

-   **Correlación observados-predichos**

Lógicamente, cuanto mayor sea la correlación entre valores observados y predichos, mejor será el modelo ajustado. Podemos calcularlo para el IDW y el kriging:

```{r}
# IDW
cor(idw_cv$var1.pred, idw_cv$observed)

# Ordinary Krigging
cor(ok_cv$var1.pred, ok_cv$observed)

# Universal Krigging
cor(uk_cv$var1.pred, uk_cv$observed)

```

Vemos que en todos los casos son muy altos, y son valores muy similares.

-   **Media de los residuos (error medio, ME)**

Tal y como vimos en la unidad relativa a la regresión lineal, nos interesa aquí que los residuos sean lo más pequeños posible (en valor absoluto) y que además tengan media próxima a cero. Podemos calcular la media:

```{r}
#IDW
mean(idw_cv$residual)

# Ordinary Kriging
mean(ok_cv$residual)

# Universal Kriging
mean(uk_cv$residual)
```

...y además construir el boxplot o histograma

```{r}
hist(idw_cv$residual, main = "Histograma de residuos para IDW")
hist(ok_cv$residual,  main = "Histograma de residuos para ordinary kriging")
hist(uk_cv$residual,  main = "Histograma de residuos para universal kriging")
```

Vemos también que parecen normales y centrados en el cero.

-   **Media estandarizada del error de predicción (mean square predictor error; MSPE)**

El MSPE es la media del cuadrado de los errores de predicción, es decir, de los residuos. Interesa por tanto que sea lo más pequeño posible:

```{r}
# Para IDW
mean(idw_cv$residual^2)

# Para ordinary Kriging
mean(ok_cv$residual^2)

# Para universal Kriging
mean(uk_cv$residual^2)
```

-   **Raíz del error cuadrático medio (Root of Mean Squared Error; RMSE)**:

El RMSE es una medida muy común de *performance* de un modelo. Es la raíz del cociente entre la suma de los cuadrados de los residuos y el número de observaciones. Tiene la ventaja de que está en las mismas unidades que la variable respuesta, por lo que su valor es fácilmente interpretable como una especie de "error medio" en las predicciones:

```{r}
# Para IDW
sqrt(sum(idw_cv$residual^2)/length(idw_cv$residual))

# Para ordinary kriging
sqrt(sum(ok_cv$residual^2)/length(ok_cv$residual))

# Para universal kriging
sqrt(sum(uk_cv$residual^2)/length(uk_cv$residual))
```

Podemos incluso hacer una tabla resumen con los parámetros:

```{r, echo = F}
metricas <- data.frame(
    Metodo = c("IDW", "Ordinary kriging", "Universal kriging"),
    Correlacion = c(cor(idw_cv$var1.pred, idw_cv$observed),
                    cor(ok_cv$var1.pred, ok_cv$observed),
                    cor(uk_cv$var1.pred, uk_cv$observed)),
    ME = c(mean(idw_cv$residual),
           mean(ok_cv$residual),
           mean(uk_cv$residual)),
    MSPE = c(mean(idw_cv$residual^2),
             mean(ok_cv$residual^2),
             mean(uk_cv$residual^2)),
    MRSE = c(sqrt(sum(idw_cv$residual^2)/length(idw_cv$residual)),
             sqrt(sum(ok_cv$residual^2)/length(ok_cv$residual)),
             sqrt(sum(uk_cv$residual^2)/length(uk_cv$residual)))
    )
    
     
knitr::kable(metricas)

```

En este caso, todos los indicadores parecen favorecer el kriging: los residuos son más bajos, las métricas de error también, y la correlación entre valores observados y predichos es ligeramente mejor. Por tanto, consideraremos que esta interpolación es más adecuada que la de IDW. En concreto, el *universal kriging* parece ser el método que produce las mejores predicciones (aunque por poco, los tres métodos son bastante similares).
