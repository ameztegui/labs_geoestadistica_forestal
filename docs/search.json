[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "",
    "text": "Presentación\nBienvenidos a la asignatura de “Geoestadística y Técnicas de Observación Global”. Esta asignatura se incluye en la doble titulación del Grado en Ingeniería Forestal y Grado en Conservación de la Naturaleza. Se trata de una asignatura en la que se enseñan técnicas y métodos para el análisis estadístico, modelización y predicción de procesos espaciales."
  },
  {
    "objectID": "index.html#qué-es-la-geoestadística",
    "href": "index.html#qué-es-la-geoestadística",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "¿Qué es la geoestadística?",
    "text": "¿Qué es la geoestadística?\nLa geoestadística es un tipo de estadística utilizada para analizar y predecir los valores asociados a fenómenos espaciales o espacio-temporales. Incorpora las coordenadas espaciales (y en algunos casos temporales) de los datos en los análisis. Las primeras herramientas geoestadísticas se desarrollaron para describir patrones espaciales y interpolar valores en lugares donde no se tomaron muestras. El análisis geoestadístico moderno permite también construir modelos de interpolación e incertidumbre más precisos, incorporando análisis mulivariados.\nLa geoestadística se utiliza ampliamente en muchos ámbitos de la ciencia y la ingeniería, por ejemplo para estimar niveles de contaminantes y determinar si constituyen una amenaza para la salud, para espacializar los datos procedentes de muestreos no continuos, como el Inventario Forestal Nacional , o para cartografiar características del suelo como los nutrientes, salinidad, etc. Y relacionarlos con el rendimiento de cultivos agrícolas o sistemas forestales, entre otros muchos:\nEn todos estos ejemplos el contexto general es que existe algún fenómeno de interés que se produce en el paisaje I que se caracteriza a partir de muestreos puntuales. La geoestadística se utiliza a continuación para elaborar predicciones en las ubicaciones no muestreadas. En esta asignatura se introducen los principios de la modelización estadística y de la información espacial, para a continuación presentar las herramientas disponibles para un análisis geoestadístico de los procesos de interés."
  },
  {
    "objectID": "index.html#de-qué-va-este-curso",
    "href": "index.html#de-qué-va-este-curso",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "¿De qué va este curso?",
    "text": "¿De qué va este curso?"
  },
  {
    "objectID": "index.html#qué-hay-de-especial-en-lo-espacial",
    "href": "index.html#qué-hay-de-especial-en-lo-espacial",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "¿Qué hay de especial en lo espacial?",
    "text": "¿Qué hay de especial en lo espacial?"
  },
  {
    "objectID": "index.html#cuándo-un-análisis-es-espacial",
    "href": "index.html#cuándo-un-análisis-es-espacial",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "¿Cuándo un análisis es espacial?",
    "text": "¿Cuándo un análisis es espacial?"
  },
  {
    "objectID": "index.html#tipos-de-preguntas-que-requieren-análisis-espacial",
    "href": "index.html#tipos-de-preguntas-que-requieren-análisis-espacial",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "Tipos de preguntas que requieren análisis espacial",
    "text": "Tipos de preguntas que requieren análisis espacial"
  },
  {
    "objectID": "index.html#funcionamiento-de-la-asignatura",
    "href": "index.html#funcionamiento-de-la-asignatura",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "Funcionamiento de la asignatura",
    "text": "Funcionamiento de la asignatura\n\nTipos de sesiones\n\n\nNuestras herramientas\n\n\nEvaluación\n\nEvaluación continua\n\n\n\nBloque\nNúmero de pruebas\nPeso\n\n\n\n\nPrimer parcial\n1\n25%\n\n\nSegundo parcial\n1\n25%\n\n\nPrácticas\n6\n50%\n\n\n\nLa asignatura se evaluará según la siguiente ponderación: \n\nParte teórica: 50% de la nota final  (25% cada bloque)\nParte práctica: 50% de la nota final\n\nCálculo de la nota global: Ex. Parcial 1 x 0.25 + Ex. Parcial 2 x 0.25 + Prácticas x 0.5\nPara aprobar la asignatura se debe obtener una nota igual o superior a 5.0, y cumplir las siguientes condiciones:\n\nBLOQUE TEÓRICO: para aprobar este bloque se debe obtener una nota ≥ 4,0 en cada uno de los parciales, independientemente de la nota de prácticas. Es decir, no se hará media con las prácticas a no ser que se cumpla el requisito mínimo anterior. \nBLOQUE PRÁCTICO: La nota mínima para superar la parte práctica es 5,0. La parte práctica consiste en la entrega de 6 informes de prácticas. Para aprobar el bloque se debe obtenir una nota ≥ 5,0 en al menos 4 de las prácticas. \n\nNOTA: Cada pràctica tendrá una fecha de entrega específica. El retraso en la entrega de los informes se penalizará des de un -30% hasta un -100% de la nota de la práctica entregada fuera de plazo.\n\n\nRecuperación\nEn caso de que no se supere la nota mínima en alguno de los bloques (teoría 1, teoría 2, prácticas), se podrán recuperar dentro del período marcado por el centro (ETSEAFIV). En el caso de recuperación, la nota máxima del bloque de prácticas no podrá ser superior a 5.\n\n\nPlagio o copia\nLa Ley 2/2022 de convivencia universitaria regula lo que se considera fraude académico: cualquier comportamiento premeditado tendente a falsear los resultados de un examen, propio o ajeno, realizado como requisito para superar una asignatura o acreditar el rendimiento académico. Las faltas pueden ser graves o muy graves. Puede consultar en la web de la UdL la Normativa de convivencia universitaria.\nSi se copia o plagia con medios fraudulentos se retirará la actividad de evaluación (por tanto quedará suspendida) y se hará llegar un informe y las evidencias a la coordinación del máster ya los jefes de estudio para iniciar un expediente disciplinario. Las sanciones aplicables incluyen, entre otros y dependiendo de la gravedad de la falta, la pérdida del derecho a ser evaluado de la asignatura, la pérdida de la matrícula de un semestre o curso o la expulsión hasta tres años."
  },
  {
    "objectID": "index.html#bibliografía",
    "href": "index.html#bibliografía",
    "title": "Apuntes y ejercicios de geoestadística para forestales",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nBaddeley, Turner (2015) Spatial Point Patterns: Methodology and Applications with R. Routledge.\nCayuela, De la Cruz (2022) Análisis de datos ecológicos en R. Mundiprensa\nMaestre, Escudeo, Bonet (2008)Introducción al análisis espacial de datos en ecología y ciencias ambientales. U. Rey Juan Carlos.\nPebesma, EJ; Bivand R, Gómez-Rubio V. 2008 Applied Spatial Data Analysis with R. \nSpatial Data Science with R. 2020 Available at https://rspatial.org"
  },
  {
    "objectID": "00_Familiar_RStudio.html#introducción.-objetivo.",
    "href": "00_Familiar_RStudio.html#introducción.-objetivo.",
    "title": "1  Familiarizándose con R y RStudio",
    "section": "1.1 Introducción. Objetivo.",
    "text": "1.1 Introducción. Objetivo.\nEl objetivo principal de este lab es presentarte R y RStudio, el software que utilizaremos a lo largo del curso para recopilar datos, trabajarlos, visualizarlos y producir análisis estadísticos que nos permitan llegar a conclusiones fundamentadas sobre los problemas planteados.\nAsumiremos que no tienes ninguna experiencia previa con R o RStudio, así que en este lab cubriremos lo más básico, empezando por la instalación del software y los primeros pasos. Si ya sabes algo de R, puede que encuentres algunos de los temas bastante básicos, y eres libre de saltar a donde quieras dentro del documento. Ten en cuenta, sin embargo, que a veces daré algunos consejos y sugerencias que pueden ser interesantes incluso si tienes experiencia con R."
  },
  {
    "objectID": "00_Familiar_RStudio.html#qué-son-r-y-rstudio",
    "href": "00_Familiar_RStudio.html#qué-son-r-y-rstudio",
    "title": "1  Familiarizándose con R y RStudio",
    "section": "1.2 ¿Qué son R y RStudio?",
    "text": "1.2 ¿Qué son R y RStudio?\nEn este lab, y durante todo el curso, vamos a utilizar R a través de RStudio. Esto no es obligatorio, por supuesto, pero es muy recomendable. Es común al principio confundir los dos. R es un lenguaje de programación, mientras que RStudio es un entorno de desarrollo integrado (IDE), es decir, una interfaz que añade muchas herramientas y características convenientes y hace mucho más fácil la experiencia de usar R. Tomaré aquí la analogía de ModernDive y la simplificaré diciendo que, si R es el motor de un coche, RStudio sería el panel de mandos. Y como ocurre con el coche, claro que podemos ejecutar R sin RStudio, pero es mucho más fácil aprovechar sus múltiples e interesantes características. Además, RStudio (y el propio R) es gratuito, de código abierto y multiplataforma.\n\n\nInstalación de R y RStudio   Recuerda que R es el nombre del propio lenguaje de programación y RStudio es un IDE (es decir, una interfaz), por lo que no podrás utilizar RStudio sin instalar previamente R.  Descarga e instala la última versión de R aquí Descarga e instala RStudio aquí  Ten en cuenta que si utilizas los ordenadores de la Universidad, estos ya tienen instaladas las versiones adecuadas de R y RStudio."
  },
  {
    "objectID": "00_Familiar_RStudio.html#la-interfaz-de-rstudio",
    "href": "00_Familiar_RStudio.html#la-interfaz-de-rstudio",
    "title": "1  Familiarizándose con R y RStudio",
    "section": "1.3 La interfaz de RStudio",
    "text": "1.3 La interfaz de RStudio\nLa mala noticia es que R es un lenguaje de programación, y esto significa que tienes que escribir comandos en código R, y ejecutarlos para obtener el resultado. No te preocupes, la buena noticia es que no necesitas ser un programador experto para poder utilizar R y sacar mucho partido a sus capacidades.\n\n1.3.1 Apariencia básica\nCuando abras por primera vez RStudio serás recibido por tres paneles:\n\nLa consola interactiva de R (toda la izquierda)\nEntorno/Historia (pestaña en la parte superior derecha) (si está en inglés, verás “Environment/History”\nArchivos/Plots/Paquetes/Ayuda/Visor (pestaña en la parte inferior derecha) (“Files/Plots/Packages/Help/Viewer”)\n\n\n\n\n\n\nApariencia básica de RStudio al abrirlo\n\n\n\n\n\n1.3.1.1 Consola\nLa consola es el corazón de R, es donde R realmente evalúa y ejecuta el código. Esta consola en RStudio es lo único que obtendrías si decidieras usar R sin RStudio. Lo primero que verás en la sesión interactiva de R es un montón de información, seguida de un &gt; y un cursor parpadeante. Esto es un prompt que indica que R está listo para recibir nuevo código.\nLa consola opera con la idea de un bucle “Leer, evaluar, imprimir”: escribes comandos, R intenta ejecutarlos y luego devuelve un resultado. Puedes escribir el código directamente en la consola después del prompt y obtener una respuesta inmediata, o copiarlo desde otro lugar (un editor de texto, por ejemplo) y pegarlo en la consola. Por ejemplo, si escribes 1 + 1 en la consola y pulsas enter (¡házlo ahora!), verás que R da inmediatamente una salida de 2. ¡Eh, ya estás usando R!\n\n\n1.3.1.2 Env~ironment/History\nLa pestaña Entorno (Environment/History) muestra los nombres de todos los objetos que has creado o cargado en tu sesión actual de R (no te preocupes, lo veremos más adelante). También puedes ver información como el número de observaciones y filas en los objetos. La pestaña también tiene algunas acciones en las que se puede hacer clic como Import Dataset que abrirá una interfaz gráfica de usuario (GUI) para importar datos en R.\nLa pestaña Historial de este panel muestra un historial de todo el código que has evaluado previamente en la Consola. Tal vez no se utiliza tanto como la pestaña Entorno, pero puede ser muy útil en momentos puntuales.\nA medida que te sientas más cómodo con R, puede que encuentres el panel Entorno / Historial más y más útil. Pero al principio probablemente lo ignorarás, así que puedes incluso minimizar la ventana haciendo clic en el botón minimizar en la parte superior derecha del panel.\n\n\n1.3.1.3 Files / Plots / Packages / Help\nEl panel Files / Plots / Packages / Help muestra mucha información útil. Vamos a ver cada pestaña en detalle:\n\nArchivos: te da acceso al directorio de archivos de tu disco duro, por lo que es muy útil para encontrar y cargar scripts de código. Una buena característica del panel “Archivos” es que puedes usarlo para establecer tu directorio de trabajo: si tienes todos tus archivos en una carpeta (lo cual deberías), puedes apuntar a ella haciendo clic en “Más” y luego en “Establecer como directorio de trabajo.” Esto facilitará el proceso de leer y guardar archivos, porque RStudio apuntará a ese directorio por defecto. De esta manera no necesitarás indicar la ruta completa cuando quieras cargar un archivo a R.\nPlots: este panel muestra todos los plots (figuras) que se generan durante una sesión de R. Hay botones para abrir el gráfico en una ventana separada y para exportar el gráfico como .pdf o .jpeg. Para ver cómo se muestran los gráficos en el panel Plots, simplemente copia el código siguiente en la consola para mostrar un histograma de la longitud de los pétalos de tres especies de plantas de Iris, que están incluidas en la base de datos iris (cargada con la instalación básica de R). Cuando lo hagas, deberías ver un histograma con la distribución del ancho de los pétalos para tres especies de Iris.\n\n\nhist(iris$Petal.Width, col = \"orange\", main = \"Histogram of petal widths\")\n\n\n\n\n\nPaquetes: muestra una lista de todos los paquetes de R instalados en su disco duro e indica si están cargados o no. Los paquetes que están cargados en la sesión actual están marcados, mientras que los que están instalados pero no cargados todavía están desmarcados. Hablaremos de los paquetes más adelante.\nAyuda: menú de ayuda para las funciones de R. Podemos escribir el nombre de una función en la ventana de búsqueda, o utilizar el código para buscar una función con el nombre. También veremos qué son las funciones en un minuto.\n\nPor supuesto, el diseño en RStudio puede ser modificado, y el usuario puede configurar qué paneles ver, el color del código, y muchas otras cuestiones. Puedes aprender más sobre la personalización de RStudio aquí. De todos modos, no te preocupes por los diferentes paneles y sus funcionalidades por ahora. Aprenderás más sobre ellos a medida que los usemos durante el curso, y espero que pronto te familiarices con ellos."
  },
  {
    "objectID": "00_Familiar_RStudio.html#conceptos-básicos-y-terminología",
    "href": "00_Familiar_RStudio.html#conceptos-básicos-y-terminología",
    "title": "1  Familiarizándose con R y RStudio",
    "section": "1.4 Conceptos básicos y terminología",
    "text": "1.4 Conceptos básicos y terminología\nAntes de empezar a usar R, necesitamos definir algunos conceptos de programación que saldrán a menudo. No es necesario que memorices ninguno de estos conceptos, ya que te familiarizarás con ellos, pero si en algún momento tienes dudas sobre lo que estamos hablando, puedes consultar esta sección (o preguntarme a mí, por supuesto).\n\nCódigo: un trozo de texto que R entiende y es capaz de ejecutar\nEjecutar código: el acto de decirle a R que lea el código y realice las acciones que contenga. Para ejecutar un determinado trozo de código, lo escribimos en la consola y pulsamos Enter.\nObjetos: siempre que guardamos algo en R, creamos un objeto. Una vez guardado, podemos realizar operaciones con los objetos, mostrar su contenido o reasignar su valor (ya veremos cómo). Los objetos pueden ser de muchos tipos, como veremos más adelante.\nFunciones (a veces también llamadas comandos): un tipo específico de objeto, las funciones realizan tareas en R. Toman algunas entradas (llamadas argumentos), y devuelven algunas salidas. Como ejemplo, la función mean() toma como argumento una cadena de valores numéricos - que deben introducirse entre paréntesis - y devuelve… bueno, su media. Trabajaremos mucho con funciones a lo largo de este curso, y tendrás mucha práctica con ellas. Para ayudarte a entender cuándo estamos hablando de una función, también incluiré el () después de ellas, como hicimos con mean() más arriba.\nPaquetes: algunas funciones están incluidas en la instalación estándar de R. Sin embargo, la comunidad de R es rica y muy activa, y cada día se crean cientos de paquetes. Un paquete no es más que una colección de funciones que ha sido creada y liberada para la comunidad (recuerda que R es un software de código abierto). Entre los paquetes que usaremos durante el curso están varios de los principales para tratar con datos espaciales: tmaps, sf, terra…)\nScripts: podemos escribir instrucciones (es decir, código) directamente en la consola, pero esta no es la forma más eficiente de trabajar. El 99% de las veces deberías escribir tus comandos en un script. Un script no es más que un archivo de texto que contiene un conjunto ordenado de instrucciones. Esto significa que podemos escribir un archivo con las instrucciones que queremos ejecutar y luego ejecutarlas todas a la vez, o decidir qué parte ejecutar. Lo mejor de los scripts es que nos permite guardar el código para poder ejecutarlo más tarde, o seguir trabajando en él.\n\n\n1.4.1 ¿Qué son los paquetes de R?\nComo hemos visto, los paquetes de R amplían la funcionalidad de R proporcionando funciones adicionales, y a menudo también incluyen datos y documentación. Están escritos por una comunidad mundial de usuarios de R y pueden descargarse gratuitamente de Internet. Existe un repositorio “oficial” de paquetes R llamado CRAN (Comprehensive R Archive Network), pero los usuarios también pueden alojar sus paquetes en cualquier repositorio de software (por ejemplo, este es un enlace a mi paquete neighborhood, alojado en mi sitio GitHub).\nDeberías pensar en los paquetes de R como en las aplicaciones que descargas en tu teléfono móvil. Un teléfono nuevo tiene ciertamente algunas características agradables cuando lo enciendes por primera vez, pero una de las primeras cosas que hacemos es instalar nuestras aplicaciones favoritas. Así que vamos a ver lo que tenemos que hacer para instalar un paquete de R.\n\n1.4.1.1 Instalación de paquetes\nCada vez que se instala una nueva versión de R (R está en continuo desarrollo, y las principales actualizaciones se producen cada 1-2 años) hay que instalar de nuevo los paquetes deseados. Esto es lo mismo que instalar WhatsApp desde Google Play o la App Store. En R hay dos formas de instalar paquetes.\nLa forma más fácil es utilizar la pestaña “Paquetes” en RStudio. Allí, puedes hacer clic en “Instalar”, escribir el nombre del paquete que quieres, y hacer clic en “Instalar”. Y ¡voilà! El paquete está instalado.\n\nUna segunda forma de instalar un paquete es simplemente escribir install.packages(\"el_nombre_del_paquete\") en la Consola y ejecutar este código (pulsando enter). Ten en cuenta que debe incluir las comillas alrededor del nombre del paquete. Por ejemplo, ejecutar el siguiente código instala el paquete ggplot2:\n\ninstall.packages(\"ggplot2\")\n\n\n\n1.4.1.2 Cargando paquetes\nUna vez que instales un paquete, no necesitarás instalarlo de nuevo, a menos que actualices tu versión de R (siguiendo con la metáfora, esto sería como comprar un nuevo móvil), o quieras actualizar el propio paquete a una nueva versión. Sin embargo, al igual que hay que abrir la aplicación de Instagram o WhatsApp antes de usarla, hay que cargar el paquete antes de usar cualquiera de sus funciones. Esto se hace escribiendo library(). Por ejemplo, prueba a escribir y ejecutar library(ggplot2).\nSi después de ejecutar el código anterior, aparece un cursor parpadeante junto al signo &gt; “prompt”, significa que ha tenido éxito y que el paquete ggplot2 está cargado y listo para ser utilizado. Si, por el contrario, obtiene un “mensaje de error” en rojo que dice ...\nError in library(ggplot2) : there is no package called ‘ggplot2’\n… significa que no lo instalaste correctamente.\n\n\n1.4.1.3 Uso de paquetes\nUn error muy común que cometen los nuevos usuarios de R cuando quieren usar paquetes es que se olvidan de “cargarlos” primero usando el comando library() que acabamos de ver. Recuerda: tienes que cargar cada paquete que quieras usar cada vez que inicies RStudio. Si no “cargas” primero un paquete, pero intentas usar una de sus características, verás un mensaje de error similar a: Error: could not find function\nR te está diciendo que está tratando de usar una función en un paquete que aún no ha sido “cargado”. R no sabe dónde encontrar la función que está utilizando. Casi todos los nuevos usuarios se olvidan de hacer esto cuando empiezan, y es un poco molesto acostumbrarse a hacerlo. Sin embargo, lo recordarás con la práctica y después de algún tiempo se convertirá en algo natural para ti.\n\n\n\n1.4.2 Salvando nuestro código: scripts en R\nHemos visto que un script es un archivo que contiene código. El código en el script no se ejecutará hasta que le digas explícitamente que se ejecute. Esto significa que podemos escribir un archivo con las instrucciones que queremos ejecutar y luego ejecutarlas a la vez, o decidir qué parte ejecutar.La ventaja de esto es sencilla: si escribes código en la consola, se ejecutará automáticamente, pero no se guardará. Así, por ejemplo, si te equivocas al escribir el código en la consola, tendrías que volver a escribirlo todo de nuevo. En cambio, si escribes todo tu código en un script y luego lo guardas, estará disponible en cualquier momento que lo necesites, y si necesitas volver a ejecutar algunos análisis sólo tienes que abrir los scripts necesarios y ejecutar todo el código que contienen. Trabajar en scripts bien organizados y documentados que puedan ser reejecutados múltiples veces por cualquier usuario es la base de la ciencia reproducible.\nPodemos crear un nuevo script eligiendo la opción de menú Archivo / Nuevo archivo / R script, o con el atajo de teclado Ctrl + Alt + Mayúsculas + N. Una vez hecho esto, notaremos que aparece un cuarto panel en RStudio. Podemos abrir varios scripts al mismo tiempo, y se organizarán en pestañas. El nuevo script se llamará Sin título 1, y estará listo para que escribamos el código. Por supuesto, podemos guardarlo donde queramos y con el nombre que deseemos. Los archivos de script son archivos de texto, que pueden ser abiertos por cualquier editor de texto, y compartidos con los colaboradores. Por convención, los scripts de R tienen la extensión .R.\n\nConsejo:  Debes acostumbrarte lo más rápido posible a escribir la mayor parte de tu código en un script. Escribe directamente en la consola sólo para hacer análisis rápidos.\n\n\n\n\nUna vista de la interfaz de RStudio inmediatamente después de crear un script. Fíjate como el panel “consola” está ahora en la parte de abajo, mientras que los scripts están en la parte superior.\n\n\nLos comandos dentro de un script no se ejecutarán inmediatamente, sólo cuando lo ordenes expresamente. Para ejecutar el comando en el que se encuentra el cursor en ese momento es necesario pulsar Ctrl+Enter o hacer clic en el comando Run en la parte superior de las ventanas de script. Ten en cuenta que el cursor no tiene que estar al principio del comando, y que el comando puede extenderse por más de una línea, se ejecutará completamente.\nSin embargo, si una sola línea constituye un comando completo, R sólo ejecutará un comando. Después de ejecutar un comando, el cursor saltará automáticamente al siguiente comando, lo que hace que sea muy eficiente ejecutar grandes trozos de código con sólo pulsar Ctrl+Enter o hacer clic en Run varias veces.\n\n\n\nEl proceso completo de crear un nuevo script, esribir código, y ejecutarlo. it.\n\n\nPara controlar mejor el trozo de código que quieres ejecutar, puedes seleccionarlo y pulsar Ctrl+Enter, y R ejecutará la selección.\nPara ejecutar todo el código del script, pulse Ctrl+Mayús+Enter o haga clic en Fuente en la barra que hay encima del script."
  },
  {
    "objectID": "00_Intro_R.html#introducción.-objetivo.",
    "href": "00_Intro_R.html#introducción.-objetivo.",
    "title": "2  Introducción a R",
    "section": "2.1 Introducción. Objetivo.",
    "text": "2.1 Introducción. Objetivo.\nEn el tutorial anterior vimos cómo instalar R y RStudio, así como alguna de sus principales características. Una vez familiarizados con el entorno en el que trabajaremos, es el momento de empezar a trabajar realmente con R. Como ya dijimos en la presentación de la asignatura, R es una herramienta muy versátil, ya que podemos usarlo de maneras muy distintas: puede ser desde una herramienta estadística hasta un lenguaje de programación compleja. Vamos a ver a continuación algunos de sus usos más básicos, y en el proceso iremos comentando algunas de las particularidades de cómo funciona R. Como ya dijimos en el tutorial anterior, si ya tienes experiencia usando R, puedes saltarte las partes que ya domines."
  },
  {
    "objectID": "00_Intro_R.html#usando-r-como-una-calculadora",
    "href": "00_Intro_R.html#usando-r-como-una-calculadora",
    "title": "2  Introducción a R",
    "section": "2.2 Usando R como una calculadora",
    "text": "2.2 Usando R como una calculadora\nLo más sencillo que puedes hacer con R es utilizarlo como una calculadora, es decir, para hacer aritmética. Por ejemplo, si escribimos la siguiente expresión:\n\n156 * 35\n\n[1] 5460\n\n\nVemos que R imprimirá la respuesta, con un [1] precedente. No te preocupes por esto por ahora, lo explicaremos más adelante. Por ahora piensa en esto como una indicación de salida de resultados.\nSi escribimos un comando incompleto, R esperará que lo completemos. Por ejemplo, intenta escribir en la consola\n1 +\nCuando aprietes Return y la sesión de R muestre un + en vez de &gt;, quiere decir que está esperando a que completemos el comando. Si queremos cancelar una orden incompleta podemos clicar Escape y RStudio volverá a mostrar el icono &gt;. Esto también se puede usar para interrumpir un proceso que se quede colgado o lleve demasiado tiempo.\nCuando se utiliza R como calculadora, el orden de las operaciones es el mismo que aprendimos en el colegio. De mayor a menor precedencia:\n\nParéntesis: (, )\nExponentes: ^ or **\nDivisión: /\nMultiplicación: *\nSuma: +\nResta: -\n\nPor ejemplo:\n\n3 + 2 * 5\n\n[1] 13\n\n(3 + 2) * 5\n\n[1] 25\n\n\nLos paréntesis pueden utilizarse para aclarar el sentido del código. Sin embargo, puede resultar difícil de leer cuando hay muchos o cuando realmente no es necesario. Recuerda que otros (¡o incluso tú mismo!) pueden leer tu código más adelante, y es conveniente que sea lo más inteligible posible.\n\n3 + 2 * 5 ^ 2       # claro, si recuerdas las reglas\n\n[1] 53\n\n3 + 2 * (5 ^ 2)     # probablemente más claro\n\n[1] 53\n\n(3 + (2 * (5 ^ 2))) # más difícil de leer\n\n[1] 53\n\n\nPuede que hayas notado que parte del texto anterior no ha sido procesado por R. En realidad, todo lo que sigue después del símbolo hash # es ignorado por R cuando ejecuta el código. El texto que sigue a # se llama “comentario”, y puede ser muy útil para recordar el propósito y los pasos de un determinado análisis.\n\n2.2.1 Funciones matemáticas\nR tiene muchas funciones matemáticas incorporadas. Para llamar a una función, simplemente escribimos su nombre, seguido de los paréntesis de apertura y cierre. Recuerda que todo lo que escribimos dentro de los paréntesis se llama argumentos de la función (los inputs que requiere para funcionar).\n\n# Veamos algunas funciones trigonométricas\n\nsin(1)  # seno de un número\n\n[1] 0.841471\n\nlog(1)  # logaritmo natural de un número\n\n[1] 0\n\nlog10(10) # logaritmo base 10\n\n[1] 1\n\nexp(0.5) # e^(1/2)\n\n[1] 1.648721\n\n\nTambién podemos utilizar las funciones de R para calcular el máximo, mínimo o media de una serie de valores, para obtener los elementos distintos de una serie de elementos o para extraer elementos de una cadena de caracteres.\n\nmax(c(1,2,5,6,7,9,12))\n\n[1] 12\n\nmean(1:10)\n\n[1] 5.5\n\nunique(c(3,3,4,5,6,6))\n\n[1] 3 4 5 6\n\nsubstr(\"abcdef\", 2,4)\n\n[1] \"bcd\"\n\n\n\nSeries de valores (vectores): Has visto aquí arriba las dos formas principales de crear vectores numéricos en R: concatenando diferentes elementos dentro de la función c(), o definiendo un intervalo mediante 1:10, que equivaldría a decir de 1 a 10. Los vectores pueden contener valores numéricos o caracteres, pero todos los elementos deben ser del mismo tipo. Veremos más sobre vectores más adelante.\n\n\nRecordando los nombres de las funciones y los argumentos:  Como hemos dicho, R tiene multitud de funciones matemáticas, y muchas más están incluidas en los paquetes. Una buena función tendrá un nombre autoexplicativo que será fácil de recordar (por ejemplo, mean(), max()…). Sin embargo, no os preocupéis por intentar recordar todas las funciones de R. Podéis simplemente buscarlas en Google, o si recordáis el comienzo del nombre de la función, escribidlo y pulsad la tecla Tab. Esto mostrará una lista de funciones cuyo nombre coincide con lo que has escrito hasta ahora. Esto se conoce como completar con tabulador, y puede ahorrar mucho tiempo de escritura (y reducir el riesgo de errores de escritura). El completado de tabulador funciona tanto en R como en RStudio. En RStudio esta característica es aún más útil; un extracto del archivo de ayuda de la función se mostrará junto al nombre de la función. Prueba a escribir me y pulsa tab.  Además, si pulsas Tab después de especificar el nombre de la función y el paréntesis de apertura, RStudio proporciona una lista de los argumentos que necesita esa función. Y si se pulsa Tab cuando el cursor está entre dos comillas, proporcionará una lista con las carpetas de tu directorio actual. Además, si escribes un ? antes del nombre de una función, se abrirá la página de ayuda de esa función, que además de proporcionar una descripción detallada de la función y de su funcionamiento, suele mostrar una colección de ejemplos de código que ilustran el uso de la función. Al principio puede que no encuentres estas características tan útiles, pero a medida que escribas más código te encontrarás utilizándolas ampliamente.\n\n\n\n2.2.2 Comparando objetos\nTambién podemos hacer comparaciones en R, y nos dirá si la comparación que estamos probando es cierta (TRUE) o falsa (FALSE). Por ejemplo, prueba las siguientes comparaciones:\n\n1 == 1    # igualdad (se usan dos signos de igual, para diferenciarlo del `=` como asignación)\n\n[1] TRUE\n\n1 != 2    # desigualdad (se lee como \"no es igual a\")\n\n[1] TRUE\n\n2 &lt; 1     # menor que\n\n[1] FALSE\n\n1 &gt; 0     # mayor que\n\n[1] TRUE\n\n6 &lt;= 6    # menor o igual que\n\n[1] TRUE\n\n1 &gt;= -9   # mayor o igual que\n\n[1] TRUE"
  },
  {
    "objectID": "00_Intro_R.html#objetos-en-r",
    "href": "00_Intro_R.html#objetos-en-r",
    "title": "2  Introducción a R",
    "section": "2.3 Objetos en R",
    "text": "2.3 Objetos en R\nCada vez que almacenamos un determinado valor en la memoria de R, estamos creando un objeto. Esto es realmente importante, ya que si no guardamos las operaciones, o los valores, como objetos, estos no estarán disponibles más adelante. Es decir, R simplemente los imprimirá en la consola pero no los almacenará en memoria. Vamos a crear un objeto llamado x. Utilizamos &lt;- para asignar valores a un determinado objeto.\n\nx &lt;- 3\n\nx contiene ahora el valor 3. Si buscamos la pestaña Environment en uno de los paneles de RStudio, veremos que han aparecido x y su valor. Sin embargo, R no imprime nada cuando hacemos esta asignación. En su lugar, lo almacena para más tarde en algo llamado variable, que es el tipo de objeto más simple en R. Las variables se muestran en la pestaña Environment de RStudio, y se almacenan en la memoria hasta que terminamos la sesión actual de R. Para ver el valor almacenado en un objeto, simplemente pedimos a R que evalúe x y nos muestra el valor almacenado:\n\nx\n\n[1] 3\n\n\nUna forma más explícita de pedirle a R que nos muestre el valor almacenado en x es utilizando print de esta manera:\n\nprint(x)\n\n[1] 3\n\n\nLos objetos más sencillos en R son las variables como x, pero en realidad, cualquier entidad que se cree y manipule en R puede ser almacenada como objeto, incluyendo datos, funciones, modelos, gráficos… Para crear un objeto sólo tenemos que asignarle un nombre. Ya hemos mencionado anteriormente que R es un lenguaje orientado a objetos. Esto significa básicamente que está diseñado para utilizar objetos como base de todas las tareas.\n\nConsejo: asignación  También es posible utilizar el operador = para la asignación, como en: x = 1/40. Esto es mucho menos común entre los usuarios de R, y más adelante veremos por qué no es buena idea utilizarlo. Si lo usas, trata de cambiar tus hábitos lo antes posible.\n\n\n2.3.1 Trabajando con variables\nLo interesante es que nuestra variable x está ahora almacenada en memoria, por lo que puede utilizarse en lugar de un número en cualquier cálculo que espere un número. Por ejemplo, prueba esto:\n\nx + 3\n\n[1] 6\n\nlog(x)\n\n[1] 1.098612\n\n\nLas variables se pueden reasignar tantas veces como se desee, pero eso significa que su valor anterior se borrará de la memoria:\n\nx &lt;- 100\n\nx solía contener el valor 3 y ahora tiene el valor 100 (ver la pestaña Environment en RStudio).\nLas asignaciones pueden contener la variable a la que se asigna, y en este caso tomarán el valor almacenado actualmente, calcularán lo que contenga el código y sobrescribirán el valor anterior con el nuevo.\n\nx &lt;- x *2 # observa cómo RStudio actualiza su descripción de x en la pestaña Environment\n\n\nAtención:  Aunque la posibilidad de sobreescribir una variable como resultado de una operación es una de las características más útiles de R, tiene su peligro. Al realizar tareas complejas, es extremadamente fácil sobrescribir una variable sin querer, y todos nuestros cálculos a partir de ese momento corren el riesgo de ser erróneos. Por ejemplo, si ejecutas el código anterior dos veces en lugar de una, x obtendrá un valor de 400 en lugar de 200. Si haces esto sin darte cuenta, x no tendrá el valor que esperas que tenga. Además, si te equivocas en el código anterior y R devuelve un mensaje de error, eso significa que no habrás sobrescrito el valor de x, que seguirá siendo 100.  Por lo tanto, siempre comprueba el valor actual de una variable (en el panel “Environment”) antes de realizar operaciones con ella."
  },
  {
    "objectID": "00_Intro_R.html#tipos-de-datos",
    "href": "00_Intro_R.html#tipos-de-datos",
    "title": "2  Introducción a R",
    "section": "2.4 Tipos de datos",
    "text": "2.4 Tipos de datos\nLas variables en R pueden ser de diferentes tipos. La función class nos ayuda a determinar qué tipo de objeto tenemos:\n\nx &lt;- 100\nclass(x)\n\n[1] \"numeric\"\n\n\nPara trabajar eficientemente en R, es importante aprender los diferentes tipos de variables y lo que podemos hacer con ellas. Estas son:\n\nNumeric: un número entero o decimal dependiendo de si especificamos cifras decimales.\nCharacter: una variable categórica o un texto.\nVector: una lista de valores del mismo tipo.\nFactor: los factores son variables en R que toman un número limitado de valores diferentes; tales variables se denominan a menudo variables categóricas.\nData frame: tabla compuesta por vectores como columnas. Todas las columnas deben tener la misma longitud (número de elementos)\nList: vector con valores de diferentes tipos.\nMatrix: objeto bidimensional (como los data frame) donde los elementos se organizan en filas y columnas, y todos son del mismo tipo.\n\nHay muchos otros tipos de objetos en R, pero estos son los principales. Por ejemplo, otro objeto con el que vamos a trabajar son los objetos model, que almacenan la salida de un determinado modelo estadístico, como un modelo de regresión lineal. Trabajaremos con ellos más adelante. Por ahora, veamos en detalle los principales tipos de datos:\n\n2.4.1 Vectores\nLos vectores son uno de los tipos de objetos más comunes en R. Los vectores pueden almacenar varios valores, pero deben ser necesariamente de la misma clase (todos números, todos texto, etc.). Las listas son un tipo específico de vector que puede contener elementos de diferentes clases.\nTodo vector tiene dos propiedades:\n\nSu tipo (character, integer, double…), que puede determinarse mediante la función typeof().\nSu longitud, que podemos determinar con length().\n\nHay varias formas de crear vectores. La más común es utilizar la función c() que nos permite introducir valores manualmente separándolos con ,.\n\nv1 &lt;- c(1, 2, 3, 4, 5)\nv1\n\n[1] 1 2 3 4 5\n\nv2 &lt;- c('my','name','is', 'Aitor')\nv2\n\n[1] \"my\"    \"name\"  \"is\"    \"Aitor\"\n\n\nComo ves, los vectores no se limitan a almacenar números. Sin embargo, volvamos a insistir en que todos los datos de un vector tienen que ser del mismo tipo: deben ser o bien caracteres, o bien números, o todos han de ser lógicos (TRUE/FALSE)). Esta es una propiedad importante de los vectores: el tipo de datos que contiene el vector es una propiedad del vector, no de cada elemento. Veamos qué ocurre si intentamos crear un vector de datos numéricos y de caracteres:\n\nc(1, 2, \"three\", \"four\", 5)\n\n[1] \"1\"     \"2\"     \"three\" \"four\"  \"5\"    \n\n\nVemos que R ha coercionado los elementos que contienen números a caracteres de texto, de modo que todos los elementos tienen el mismo tipo (carácter).\n\n2.4.1.1 Principales tipos de vectores\nVeamos con más detalle los principales tipos de vectores:\n\n2.4.1.1.1 Vectores lógicos\nLos vectores lógicos sólo pueden tomar tres valores posibles: FALSE, TRUE, y NA (no disponible, lo veremos más adelante). Los vectores lógicos se construyen normalmente con operadores de comparación:\n\nc(1,2,8,4,5,3,7,8,9) &gt;= 5   # Qué elementos son mayores o iguales que 5\n\n[1] FALSE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE\n\n\nLos vectores lógicos tienen la particularidad de que TRUE tiene un valor de 1, y FALSE de 0, así que la suma del vector nos dará el número de TRUE y la media nos dará la proporción de TRUE.\n\n\n2.4.1.1.2 Vectores numéricos\nLos vectoresinteger y doubles se conocen colectivamente como vectores numéricos. En R, los números son doubles (con decimales) por defecto. De todos modos, la diferencia entre entero y decimal no suele ser importante, así que no entraremos en más detalles aquí. Para construir vectores numéricos podemos utilizar la función c() vista anteriormente, pero hay otras dos opciones. Podemos usar :, que produce una secuencia ordenada de números empezando por el primer valor y sumando de uno en uno hasta el último.\n\nv3 &lt;- 1:10\nv3\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nv4 &lt;- -5:3\nv4\n\n[1] -5 -4 -3 -2 -1  0  1  2  3\n\n\nTambién podemos usar seq(), que produce una secuencia de números:\n\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nEl primer argumento define el inicio, y el segundo define el final, que está incluido. El valor por defecto es subir en incrementos de 1, pero un tercer argumento nos permite decirle cuánto debe saltar:\n\nseq(1, 10, 2)\n\n[1] 1 3 5 7 9\n\n\n\n\n2.4.1.1.3 Vectores de carácter\nLos vectores de caracteres son el tipo más complejo de vector atómico, porque cada elemento de un vector de caracteres es una cadena, y una cadena puede contener una cantidad arbitraria de datos.\n\nv5 &lt;- c(\"Lleida\", \"Lleida\", \"Barcelona\", \"Madrid\", \"Lleida\", \"Madrid\")\nv5\n\n[1] \"Lleida\"    \"Lleida\"    \"Barcelona\" \"Madrid\"    \"Lleida\"    \"Madrid\"   \n\n\n\n\n2.4.1.1.4 Valores no presentes (missing values)\nLos vectores, como casi cualquier objeto de datos en R, pueden contener valores perdidos. Estos se indican como NA (no disponible). Sin embargo, ten en cuenta que NA hereda la clase del vector, por lo que un NA dentro de un vector numérico seguirá siendo numérico, mientras que un NA en un vector de caracteres será de tipo carácter.\n\n\n\n2.4.1.2 Trabajando con vectores\nA continuación veremos algunas de las operaciones que podemos hacer con los vectores, y las herramientas que tenemos para trabajar con ellos\n\n2.4.1.2.1 Funciones de longitud y test\nComo hemos dicho anteriormente, las dos características principales de un vector son su tipo y su longitud. Podemos calcular cuántos elementos contiene un vector utilizando la función length():\n\nlength(x)\n\n[1] 1\n\nlength(letters)\n\n[1] 26\n\n\n\n\n2.4.1.2.2 Coerción\nPodemos querer forzar (coaccionar) un vector para que sea de un tipo determinado. Podemos hacerlo llamando a una función como as.logical(), as.integer(), as.double(), o as.character().\n\nas.character(c(1,2,3,4))\n\n[1] \"1\" \"2\" \"3\" \"4\"\n\nas.integer(c(3.5, 4.3, 6.4, 5.0))\n\n[1] 3 4 6 5\n\n\n\n\n2.4.1.2.3 Nombrando vectores\nPor supuesto, también podemos asignar un vector a un objeto, de manera que lo guardemos en memoria. Como se ha visto anteriormente, basta con darle un nombre:\n\nx &lt;- 5:10\n\nR viene con algunos vectores incorporados, que contienen valores comunes útiles. Prueba estos:\n\nLETTERS\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nmonth.abb\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\"\n\nmonth.name\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\nLógicamente, el tipo de datos que se almacena en una variable afecta a lo que podemos hacer con ella:\n\nLETTERS + 1\n\nError in LETTERS + 1: argumento no-numérico para operador binario\n\n\n\n\n2.4.1.2.4 Submuestreando vectores\nUna vez definido un vector, a menudo es útil extraer partes de un vector. Lo hacemos con el operador []. Por ejemplo, podemos extraer el segundo elemento del vector month.name:\n\nmonth.name[2]\n\n[1] \"February\"\n\n\no podemos extraer los meses del 2º al 4º:\n\nmonth.name[2:4]\n\n[1] \"February\" \"March\"    \"April\"   \n\n\nDesenmascaremos el segundo ejemplo; 2:4 genera la secuencia 2,3,4. Esta secuencia se pasa al operador de extracción [], por lo que extraerá el segundo, tercer y cuarto elemento. También podemos generar esta secuencia utilizando la función c():\n\nmonth.name[c(2,3,6)]\n\n[1] \"February\" \"March\"    \"June\"    \n\n\nLos valores se devuelven en el orden en que especificamos los índices.\n\nmonth.name[4:2]\n\n[1] \"April\"    \"March\"    \"February\"\n\n\nTambién podemos extraer el mismo elemento más de una vez:\n\nmonth.name[c(1,1,2,2,2,4)]\n\n[1] \"January\"  \"January\"  \"February\" \"February\" \"February\" \"April\"   \n\n\nTambién es posible modificar la información de una posición concreta utilizando la combinación nombre[posición] y el operador de asignación &lt;-. Por ejemplo:\n\nmonth.name[12] &lt;- \"Navidades!\"\nmonth.name\n\n [1] \"January\"    \"February\"   \"March\"      \"April\"      \"May\"       \n [6] \"June\"       \"July\"       \"August\"     \"September\"  \"October\"   \n[11] \"November\"   \"Navidades!\"\n\n\nSi utilizamos un número negativo como índice de un vector, R devolverá todos los elementos excepto el especificado:\n\nmonth.name[-2]\n\n [1] \"January\"    \"March\"      \"April\"      \"May\"        \"June\"      \n [6] \"July\"       \"August\"     \"September\"  \"October\"    \"November\"  \n[11] \"Navidades!\"\n\n\nTambién podemos omitir varios elementos:\n\nmonth.name[c(-1, -5)]  # o \n\n [1] \"February\"   \"March\"      \"April\"      \"June\"       \"July\"      \n [6] \"August\"     \"September\"  \"October\"    \"November\"   \"Navidades!\"\n\nmonth.name[-c(1,5)]\n\n [1] \"February\"   \"March\"      \"April\"      \"June\"       \"July\"      \n [6] \"August\"     \"September\"  \"October\"    \"November\"   \"Navidades!\"\n\n\nAdemás de proporcionar una lista de índices que queremos conservar (o eliminar, si les ponemos el prefijo -), podemos pasar un vector lógico a R indicando los índices que queremos seleccionar:\n\nmonth.name[c(TRUE, FALSE, TRUE, TRUE, FALSE, FALSE,\n             FALSE, TRUE, TRUE, FALSE, FALSE, TRUE)]\n\n[1] \"January\"    \"March\"      \"April\"      \"August\"     \"September\" \n[6] \"Navidades!\"\n\n\nLa idea de seleccionar elementos de un vector utilizando un vector lógico de subconjuntos puede parecer un poco esotérica, y mucho más teclear que simplemente seleccionar los elementos que queremos por índice, pero se vuelve realmente útil cuando escribimos código para generar el vector lógico:\n\nmy_vector &lt;- c(10, 3, 6, 7, 9)\nmy_vector &gt; 6\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE\n\n\n\nmy_vector[my_vector &gt; 6]\n\n[1] 10  7  9\n\n\n\nConsejo: Combinando condiciones lógicas  Hay muchas situaciones en las que podemos querer combinar varios criterios lógicos. Por ejemplo, podríamos querer encontrar todos los elementos que están entre dos valores. En R existen varias operaciones para combinar vectores lógicos:\n\n-&, el operador lógico “Y”: devuelve TRUE si tanto la izquierda como la derecha son TRUE.\n-|, el operador lógico “O”: devuelve TRUE, si la izquierda o la derecha (o ambas) son TRUE.\n- ! El operador lógico “NOT”: convierte “TRUE” en “FALSE” y “FALSE” en “TRUE”. Puede negar una sola condición lógica (por ejemplo, !TRUE se convierte en FALSE), o todo un vector de condiciones (por ejemplo, !c(TRUE, FALSE) se convierte en c(FALSE, TRUE)).\nAdemás, puede comparar los elementos de un mismo vector utilizando la función all (que devuelve TRUE si todos los elementos del vector son TRUE) y la función any (que devuelve TRUE si uno o más elementos del vector son TRUE).\n\n\n\n\n2.4.2 Factores\nLos factores son un tipo específico de vector de caracteres, en el que los elementos sólo pueden tomar un número predefinido y finito de valores, llamados niveles, levels. Por ejemplo: un campo de datos como el estado civil puede contener sólo valores de soltero, casado, separado, divorciado o viudo.\nPodemos crear un factor utilizando la función factor(). Podemos proporcionar los posibles niveles de un factor. Se inferirán de los datos si no se proporcionan.\n\nestado &lt;- factor(c(\"soltero\", \"casado\", \"casado\", \"divorciado\", \"viudo\"))\n\nlevels(estado)\n\n[1] \"casado\"     \"divorciado\" \"soltero\"    \"viudo\"     \n\n\n\n\n2.4.3 Data frames\nLos data frame son el objeto más común para almacenar datos en R. Un data frame es una tabla o una estructura bidimensional (tiene filas y columnas). Cada columna suele contener valores de una variable, por lo que podríamos considerar que un data frame es un conjunto de vectores de igual longitud. Cada fila contiene un valor de cada columna.\nLos data frame deben tener ciertas características:\n\nLos nombres de las columnas deben ser no vacíos.\n\n- Los nombres de las filas (si existen) deben ser únicos.\n- Cada columna debe contener el mismo número de elementos.\nPara crear un data frame podemos utilizar la función data.frame y proporcionar una lista de vectores con nombre:\n\ngrades &lt;- data.frame(Name = c(\"Mark\", \"Lewis\", \"Brian\", \"Matthew\"),\n                     Course = c(2, 2, 1, 2),\n                     Grade = c(\"A\", \"B\", \"A+\", \"C\"))\n\nSin embargo, raramente crearemos un data frame manualmente. Normalmente, llamaremos a una instrucción para leer archivos de texto que contengan datos o llamaremos a objetos de datos disponibles en algunos paquetes. Por ejemplo, consideremos el siguiente marco de datos, disponible en el paquete tidyverse (puede que necesites instalar y cargar el paquete):\n\nstarwars\n\n# A tibble: 87 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 C-3PO       167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n 3 R2-D2        96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n 4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 5 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 7 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 8 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu…\n 9 Biggs D…    183    84 black      light      brown           24   male  mascu…\n10 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n# ℹ 77 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nEste conjunto de datos contiene los nombres y características (nombre, altura, masa, vehículos… hasta 13 variables) de 87 personajes que participan en la saga de Star Wars. Hay columnas numéricas y de caracteres, pero todas las variables tienen 87 elementos.\nPara subconjuntar un marco de datos, podemos utilizar el operador [, pero ahora indicando dos dimensiones: qué fila(s) queremos subconjuntar, y qué columna(s):\n\nstarwars[1,4]\n\n# A tibble: 1 × 1\n  hair_color\n  &lt;chr&gt;     \n1 blond     \n\nstarwars[4,3]\n\n# A tibble: 1 × 1\n   mass\n  &lt;dbl&gt;\n1   136\n\n\nSi nos dejamos una de las dimensiones, obtendremos un mensaje de error. Sin embargo, si dejamos un espacio vacío, R entenderá que queremos mantener todos los elementos de la fila o columna seleccionada:\n\nstarwars[, 3]   # Seleccionará todos los valores de la columna 3\n\n# A tibble: 87 × 1\n    mass\n   &lt;dbl&gt;\n 1    77\n 2    75\n 3    32\n 4   136\n 5    49\n 6   120\n 7    75\n 8    32\n 9    84\n10    77\n# ℹ 77 more rows\n\nstarwars[4, ]   # Seleccionará todas las columnas para la fila 4\n\n# A tibble: 1 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nComo los data frame son una sucesión de vectores con nombre, podemos utilizar el nombre de la columna para extraer las columnas deseadas:\n\nstarwars[ , \"gender\"]\n\n# A tibble: 87 × 1\n   gender   \n   &lt;chr&gt;    \n 1 masculine\n 2 masculine\n 3 masculine\n 4 masculine\n 5 feminine \n 6 masculine\n 7 feminine \n 8 masculine\n 9 masculine\n10 masculine\n# ℹ 77 more rows\n\nstarwars[ , c(\"gender\", \"birth_year\")]\n\n# A tibble: 87 × 2\n   gender    birth_year\n   &lt;chr&gt;          &lt;dbl&gt;\n 1 masculine       19  \n 2 masculine      112  \n 3 masculine       33  \n 4 masculine       41.9\n 5 feminine        19  \n 6 masculine       52  \n 7 feminine        47  \n 8 masculine       NA  \n 9 masculine       24  \n10 masculine       57  \n# ℹ 77 more rows\n\nstarwars[2, \"homeworld\"]\n\n# A tibble: 1 × 1\n  homeworld\n  &lt;chr&gt;    \n1 Tatooine \n\n\nTambién podemos utilizar el operador $ para extraer una columna completa:\n\nstarwars$gender\n\n [1] \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"feminine\"  \"masculine\"\n [7] \"feminine\"  \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"masculine\"\n[13] \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"masculine\" NA         \n[19] \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"masculine\"\n[25] \"masculine\" \"masculine\" \"feminine\"  \"masculine\" \"masculine\" \"masculine\"\n[31] \"masculine\" \"masculine\" \"masculine\" \"feminine\"  \"masculine\" \"masculine\"\n[37] \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"feminine\" \n[43] \"masculine\" \"masculine\" \"feminine\"  \"masculine\" \"masculine\" \"masculine\"\n[49] \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"masculine\" \"feminine\" \n[55] \"masculine\" \"masculine\" \"masculine\" \"masculine\" NA          NA         \n[61] \"masculine\" \"masculine\" \"feminine\"  \"feminine\"  \"feminine\"  \"masculine\"\n[67] \"masculine\" \"masculine\" \"feminine\"  \"masculine\" \"masculine\" \"feminine\" \n[73] \"feminine\"  \"feminine\"  \"masculine\" \"masculine\" \"feminine\"  \"masculine\"\n[79] \"masculine\" \"masculine\" NA          \"masculine\" \"masculine\" \"feminine\" \n[85] \"masculine\" \"masculine\" \"feminine\" \n\n\nAlgunas funciones útiles para utilizar con los marcos de datos son str() para obtener los nombres, tipos y primeros valores de las columnas; y summary() para obtener las estadísticas descriptivas de las variables numéricas.\n\nstr(starwars)\n\ntibble [87 × 14] (S3: tbl_df/tbl/data.frame)\n $ name      : chr [1:87] \"Luke Skywalker\" \"C-3PO\" \"R2-D2\" \"Darth Vader\" ...\n $ height    : int [1:87] 172 167 96 202 150 178 165 97 183 182 ...\n $ mass      : num [1:87] 77 75 32 136 49 120 75 32 84 77 ...\n $ hair_color: chr [1:87] \"blond\" NA NA \"none\" ...\n $ skin_color: chr [1:87] \"fair\" \"gold\" \"white, blue\" \"white\" ...\n $ eye_color : chr [1:87] \"blue\" \"yellow\" \"red\" \"yellow\" ...\n $ birth_year: num [1:87] 19 112 33 41.9 19 52 47 NA 24 57 ...\n $ sex       : chr [1:87] \"male\" \"none\" \"none\" \"male\" ...\n $ gender    : chr [1:87] \"masculine\" \"masculine\" \"masculine\" \"masculine\" ...\n $ homeworld : chr [1:87] \"Tatooine\" \"Tatooine\" \"Naboo\" \"Tatooine\" ...\n $ species   : chr [1:87] \"Human\" \"Droid\" \"Droid\" \"Human\" ...\n $ films     :List of 87\n  ..$ : chr [1:5] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"Revenge of the Sith\" ...\n  ..$ : chr [1:6] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"The Phantom Menace\" ...\n  ..$ : chr [1:7] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"The Phantom Menace\" ...\n  ..$ : chr [1:4] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"Revenge of the Sith\"\n  ..$ : chr [1:5] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"Revenge of the Sith\" ...\n  ..$ : chr [1:3] \"A New Hope\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:3] \"A New Hope\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"A New Hope\"\n  ..$ : chr \"A New Hope\"\n  ..$ : chr [1:6] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"The Phantom Menace\" ...\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"A New Hope\" \"Revenge of the Sith\"\n  ..$ : chr [1:5] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"Revenge of the Sith\" ...\n  ..$ : chr [1:4] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\" \"The Force Awakens\"\n  ..$ : chr \"A New Hope\"\n  ..$ : chr [1:3] \"A New Hope\" \"Return of the Jedi\" \"The Phantom Menace\"\n  ..$ : chr [1:3] \"A New Hope\" \"The Empire Strikes Back\" \"Return of the Jedi\"\n  ..$ : chr \"A New Hope\"\n  ..$ : chr [1:5] \"The Empire Strikes Back\" \"Return of the Jedi\" \"The Phantom Menace\" \"Attack of the Clones\" ...\n  ..$ : chr [1:5] \"The Empire Strikes Back\" \"Return of the Jedi\" \"The Phantom Menace\" \"Attack of the Clones\" ...\n  ..$ : chr [1:3] \"The Empire Strikes Back\" \"Return of the Jedi\" \"Attack of the Clones\"\n  ..$ : chr \"The Empire Strikes Back\"\n  ..$ : chr \"The Empire Strikes Back\"\n  ..$ : chr [1:2] \"The Empire Strikes Back\" \"Return of the Jedi\"\n  ..$ : chr \"The Empire Strikes Back\"\n  ..$ : chr [1:2] \"Return of the Jedi\" \"The Force Awakens\"\n  ..$ : chr \"Return of the Jedi\"\n  ..$ : chr \"Return of the Jedi\"\n  ..$ : chr \"Return of the Jedi\"\n  ..$ : chr \"Return of the Jedi\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"The Phantom Menace\" \"Attack of the Clones\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr [1:2] \"The Phantom Menace\" \"Attack of the Clones\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr [1:2] \"The Phantom Menace\" \"Attack of the Clones\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr \"Return of the Jedi\"\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"The Phantom Menace\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"The Phantom Menace\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"The Phantom Menace\" \"Revenge of the Sith\"\n  ..$ : chr \"The Phantom Menace\"\n  ..$ : chr [1:3] \"The Phantom Menace\" \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"The Phantom Menace\" \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr [1:2] \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr [1:2] \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr [1:2] \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr \"Attack of the Clones\"\n  ..$ : chr [1:2] \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"Revenge of the Sith\"\n  ..$ : chr \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"A New Hope\" \"Revenge of the Sith\"\n  ..$ : chr [1:2] \"Attack of the Clones\" \"Revenge of the Sith\"\n  ..$ : chr \"Revenge of the Sith\"\n  ..$ : chr \"The Force Awakens\"\n  ..$ : chr \"The Force Awakens\"\n  ..$ : chr \"The Force Awakens\"\n  ..$ : chr \"The Force Awakens\"\n  ..$ : chr \"The Force Awakens\"\n $ vehicles  :List of 87\n  ..$ : chr [1:2] \"Snowspeeder\" \"Imperial Speeder Bike\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Imperial Speeder Bike\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Tribubble bongo\"\n  ..$ : chr [1:2] \"Zephyr-G swoop bike\" \"XJ-6 airspeeder\"\n  ..$ : chr(0) \n  ..$ : chr \"AT-ST\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Snowspeeder\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Tribubble bongo\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Sith speeder\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Flitknot speeder\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Koro-2 Exodrive airspeeder\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Tsmeu-6 personal wheel bike\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n $ starships :List of 87\n  ..$ : chr [1:2] \"X-wing\" \"Imperial shuttle\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"TIE Advanced x1\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"X-wing\"\n  ..$ : chr [1:5] \"Jedi starfighter\" \"Trade Federation cruiser\" \"Naboo star skiff\" \"Jedi Interceptor\" ...\n  ..$ : chr [1:3] \"Naboo fighter\" \"Trade Federation cruiser\" \"Jedi Interceptor\"\n  ..$ : chr(0) \n  ..$ : chr [1:2] \"Millennium Falcon\" \"Imperial shuttle\"\n  ..$ : chr [1:2] \"Millennium Falcon\" \"Imperial shuttle\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"X-wing\"\n  ..$ : chr \"X-wing\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Slave 1\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Millennium Falcon\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"A-wing\"\n  ..$ : chr(0) \n  ..$ : chr \"Millennium Falcon\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr [1:3] \"Naboo fighter\" \"H-type Nubian yacht\" \"Naboo star skiff\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Naboo Royal Starship\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Scimitar\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Jedi starfighter\"\n  ..$ : chr(0) \n  ..$ : chr \"Naboo fighter\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"Belbullab-22 starfighter\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr(0) \n  ..$ : chr \"X-wing\"\n  ..$ : chr(0) \n  ..$ : chr(0) \n\nsummary(starwars)\n\n     name               height           mass          hair_color       \n Length:87          Min.   : 66.0   Min.   :  15.00   Length:87         \n Class :character   1st Qu.:167.0   1st Qu.:  55.60   Class :character  \n Mode  :character   Median :180.0   Median :  79.00   Mode  :character  \n                    Mean   :174.6   Mean   :  97.31                     \n                    3rd Qu.:191.0   3rd Qu.:  84.50                     \n                    Max.   :264.0   Max.   :1358.00                     \n                    NA's   :6       NA's   :28                          \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n                                                                        \n  skin_color         eye_color           birth_year         sex           \n Length:87          Length:87          Min.   :  8.00   Length:87         \n Class :character   Class :character   1st Qu.: 35.00   Class :character  \n Mode  :character   Mode  :character   Median : 52.00   Mode  :character  \n                                       Mean   : 87.57                     \n                                       3rd Qu.: 72.00                     \n                                       Max.   :896.00                     \n                                       NA's   :44                         \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n                                                                          \n    gender           homeworld           species         \n Length:87          Length:87          Length:87         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n                                                         \n films.Length  films.Class  films.Mode\n 5          -none-     character      \n 6          -none-     character      \n 7          -none-     character      \n 4          -none-     character      \n 5          -none-     character      \n 3          -none-     character      \n 3          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 6          -none-     character      \n 3          -none-     character      \n 2          -none-     character      \n 5          -none-     character      \n 4          -none-     character      \n 1          -none-     character      \n 3          -none-     character      \n 3          -none-     character      \n 1          -none-     character      \n 5          -none-     character      \n 5          -none-     character      \n 3          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 3          -none-     character      \n 1          -none-     character      \n 3          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 3          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 3          -none-     character      \n 3          -none-     character      \n 3          -none-     character      \n 2          -none-     character      \n 2          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 3          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 2          -none-     character      \n 2          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n 1          -none-     character      \n vehicles.Length  vehicles.Class  vehicles.Mode\n 2          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 2          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 1          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n 0          -none-     character               \n starships.Length  starships.Class  starships.Mode\n 2          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 5          -none-     character                  \n 3          -none-     character                  \n 0          -none-     character                  \n 2          -none-     character                  \n 2          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 3          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n 1          -none-     character                  \n 0          -none-     character                  \n 0          -none-     character                  \n\n\n\n\n2.4.4 Listas\nLas listas, a veces también llamadas vectores recursivos, son objetos similares a los vectores “normales”, con la diferencia de que las listas permiten almacenar valores de distinto tipo. Incluso pueden contener otras listas. Las listas se crean con la función list(valor1, valor2, ...). Por ejemplo:\n\nlist1 &lt;- list(\"Harry\", \"Potter\", \"Wizard\", 24,\"Hogwarts\")\nlist1\n\n[[1]]\n[1] \"Harry\"\n\n[[2]]\n[1] \"Potter\"\n\n[[3]]\n[1] \"Wizard\"\n\n[[4]]\n[1] 24\n\n[[5]]\n[1] \"Hogwarts\"\n\n\n\n2.4.4.1 Submuestreando listas\nPara acceder a los valores almacenados en las distintas posiciones se procede de la misma manera que con los vectores, es decir, nombre[posición]. Sin embargo, [ extrae una sublista, por lo que el resultado será siempre una lista.\n\nlist1[3]\n\n[[1]]\n[1] \"Wizard\"\n\ntypeof(list1[3])\n\n[1] \"list\"\n\n\nA diferencia de [, [[extrae un solo componente de una lista. Elimina un nivel de jerarquía de la lista:\n\nlist1[[3]]\n\n[1] \"Wizard\"\n\ntypeof(list1[[3]])\n\n[1] \"character\"\n\n\nTambién podemos nombrar los elementos de una lista\n\nlist2 &lt;- list(Name = \"Harry\", Surname = \"Potter\", Profession = \"Wizard\", Age = 24,\n              College = \"Hogwarts\")\n\nLas listas son un poco más difíciles de trabajar que los vectores y los data frames. Apenas las utilizaremos en este curso, aunque trabajar con listas puede ser realmente útil y eficiente."
  },
  {
    "objectID": "00_Intro_R.html#gestión-de-objetos",
    "href": "00_Intro_R.html#gestión-de-objetos",
    "title": "2  Introducción a R",
    "section": "2.5 Gestión de objetos",
    "text": "2.5 Gestión de objetos\n\n2.5.1 Creando objetos\nTambién podemos almacenar en un objeto el resultado de cualquier operación, o hacer referencia a otro objeto\n\np &lt;- 10+2\nq &lt;- mean(vector)\n\nWarning in mean.default(vector): argument is not numeric or logical: returning\nNA\n\n\nAlgunas consideraciones a tener en cuenta a la hora de crear objetos o trabajar con R en líneas generales:\n\nR distingue entre mayúsculas y minúsculas por lo que radio ≠ Radio\nSi se asigna un nuevo valor a un objeto, éste se sobrescribe y borra el valor anterior.\nLa información de texto (también conocida como cadena o carácter) se introduce entre comillas, ya sea simple (\"texto\") o doble ('texto').\nSi el valor obtenido de una instrucción no se asigna a un objeto, se mostrará en el terminal, pero NO SE ALMACENARÁ."
  },
  {
    "objectID": "00_Intro_R.html#funciones-y-argumentos",
    "href": "00_Intro_R.html#funciones-y-argumentos",
    "title": "2  Introducción a R",
    "section": "2.6 Funciones y argumentos",
    "text": "2.6 Funciones y argumentos\nHasta aquí hemos visto y ejecutado algunas instrucciones en R, generalmente orientadas a la creación de objetos o realización de operaciones aritméticas sencillas.\nSin embargo, también hemos ejecutado algunas instrucciones de tipo función, como length(). Una función puede definirse como un grupo de instrucciones que toma una entrada, utiliza esta entrada para calcular otros valores y devuelve un resultado o salida. No entraremos en detalles por ahora. Basta con saber que para ejecutar una función basta con invocar la instrucción que llama a la función deseada y especificar las entradas necesarias (argumentos). Los argumentos se incluyen siempre entre los paréntesis de la instrucción, como en length(vector). Si se necesitan varios argumentos los separamos utilizando ,.\nLos argumentos de una función tienen nombre, y podemos indicarlos explícitamente al ejecutar la función. Si no proporcionamos los nombres de los argumentos, R los asignará en orden. Esto significa que\nrnorm(n = 100, mean = 10, sd = 3)\nhará exactamente lo mismo que\nrnorm(100, 10, 3)\nA medida que te familiarices con las funciones, será más frecuente que decidas no escribir el nombre de los argumentos. Ten cuidado, en este caso, de introducir los argumentos en el orden necesario (puedes consultar la ayuda de la función para estar seguro. En este caso help(rnorm))"
  },
  {
    "objectID": "00_Intro_R.html#errores-warnings-y-mensajes",
    "href": "00_Intro_R.html#errores-warnings-y-mensajes",
    "title": "2  Introducción a R",
    "section": "2.7 Errores, warnings y mensajes",
    "text": "2.7 Errores, warnings y mensajes\nUna cosa que intimida a los nuevos usuarios de R y RStudio es cómo informa de los errores, warnings y mensajes. R informa de los errores, las advertencias (warnings) y los mensajes con una fuente roja muy llamativa, lo que hace que parezca que te está regañando. Además, el mensaje de error no siempre es informativo, ya que se centra en decirle lo que ha ido mal, pero a menudo no por qué, ni dice cómo resolverlo. Podemos diferenciar tres mensajes diferentes que puedes obtener en la consola:\n\nErrors: Cuando el texto rojo sea un error legítimo, irá precedido de “Error in…” e intentará explicar qué ha ido mal. Cuando haya un error, el código no se ejecutará.\nWarnings: Cuando el texto rojo es una advertencia, será precedido por “Warning:” y R tratará de explicar por qué hay una advertencia. En general, tu código seguirá funcionando, pero con algunas limitaciones o aspectos a considerar\nMessages: cuando el texto rojo no comienza con “Error” o “Warning”, es sólo un mensaje amistoso. Verás estos mensajes cuando cargues paquetes R o cuando leas datos guardados en archivos de hojas de cálculo. Estos son mensajes de diagnóstico útiles y no impiden que tu código funcione.\n\n\nNota importante: Recibirás Toneladas de mensajes de error de R, especialmente al principio. No te preocupes, esto es normal, y es parte del proceso de aprendizaje. Cada vez que recibas un mensaje de error, no te paralices por el pánico. Trata de entender lo que salió mal, y si no lo sabes, busca en Google el texto del mensaje. Es muy probable que se trate de un error común y que puedas encontrar fácilmente la solución por ti mismo. Si no es así, también puedes consultarlo con tus compañeros. Si no sois capaces de resolverlo por vosotros mismos, podemos ayudaros, pero aprender a recibir ayuda para resolver vuestros propios problemas es una parte capital del aprendizaje de R, así que os animamos a que lo intentéis antes de pedirnos ayuda."
  },
  {
    "objectID": "00_Intro_R.html#para-saber-más",
    "href": "00_Intro_R.html#para-saber-más",
    "title": "2  Introducción a R",
    "section": "2.8 Para saber más",
    "text": "2.8 Para saber más\nPara aprender más sobre algunos de los temas cubiertos en este laboratorio, recomiendo ver el vídeo “Writing code in RStudio”, desarrollado por el equipo de RStudio. Contiene muchos de los conceptos que se tratan aquí, y también algunos consejos más para seguir: [en inglés] https://resources.rstudio.com/wistia-rstudio-essentials-2/rstudioessentialsprogrammingpart1-2"
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#introducción.-objetivo.",
    "href": "00_RMarkdown_Quarto.html#introducción.-objetivo.",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.1 Introducción. Objetivo.",
    "text": "3.1 Introducción. Objetivo.\nEl objetivo de este tutorial es introducirte los fundamentos de RMarkdown y Quarto, y ver cómo los puedes usar para combinar código y texto y crear los informes de las prácticas que realizaremos en el curso."
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#qué-es-quarto-y-rmarkdown",
    "href": "00_RMarkdown_Quarto.html#qué-es-quarto-y-rmarkdown",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.2 ¿Qué es Quarto? ¿Y RMarkdown?",
    "text": "3.2 ¿Qué es Quarto? ¿Y RMarkdown?\nQuarto® es un sistema de publicación científica y técnica de código abierto. Puede combinar texto narrativo y código para producir resultados con un formato elegante en forma de documentos, páginas web, entradas de blog, libros y mucho más. Es un formato dinámico, que combina código, los resultados de ejecutarlo, y texto, en un único documento que admite decenas de formatos de salida, como PDF, archivos de Word, presentaciones y más.\nQuarto es de código 100% abierto, la versión 1.4 de Quarto está licenciada bajo la Licencia MIT. Quarto supone un paso más en el desarrollo de RMarkdown, un formato de fichero que creó la compañía RStudio (ahora Posit) hace casi 10 años para trabajar con código de R. Sin embargo, Quarto va un paso más allá, ya que añade a las funcionalidades que ya tenía RMarkdown, los más de 10 años de experiencia en su uso, y sobre todo la compatibilidad con otros lenguajes de programación como Julia, Python o JavaScript. Esto le ha dado una vuelta de tuerca a su versatilidad.\nRMarkdown, el predecesor de Quarto, fue inicialmente creado para generar documentos que sirvan como registro de los análisis que se ejecutan, un poco como un cuaderno de laboratorio. Así que, en lugar de comentar el código, Quarto lo presenta junto con su salida (figuras, tablas…) y podemos añadir el texto que queramos, e incluso darle formato. Esto puede ser muy interesante en 3 casos:\n\nPara comunicar nuestros resultados a los responsables de la toma de decisiones (gestores, ayuntamientos…), a clientes, socios o al público en general, que estarán interesados en el análisis y las conclusiones, pero no en el código que hay detrás del análisis.\nPara colaborar con otros colegas, incluyendo tu yo futuro, que están interesados tanto en tus conclusiones como en cómo has llegado a ellas (es decir, el código).\nPara registrar los análisis, como una especie de cuadernos de laboratorio en el que se anote no sólo qué análisis se han hecho, sino también los motivos que llevan a ello.\n\nSin embargo, la versatilidad de Quarto hace que se pueda ir más allá, generando todo tipo de documentos: desde páginas web, ficheros pdf, presentaciones, libros online, blogs… De hecho, este documento que estás leyendo se ha generado con Quarto.\n\n\n\nVideo\nAlgunos de los lenguajes soportados por Quarto, y los tipos de ficheros de salida posibles\n\n\nQuarto se basa en el lenguaje Markdown, un lenguaje de código que permite la conversión texto-HTML. Es un lenguaje en realidad muy básico, por lo que necesitas aprender muy poco código para poder escribir en Quarto.\nEn el contexto del curso, usaremos Quarto para generar los informes de prácticas, en los que poder mostrar el código que habéis escrito, su salida, así como vuestra interpretación de los resultados y los motivos para optar por una u otra función.\n\n g){width=100%}"
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#usando-quarto-en-rstudio",
    "href": "00_RMarkdown_Quarto.html#usando-quarto-en-rstudio",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.3 Usando Quarto en RStudio",
    "text": "3.3 Usando Quarto en RStudio\nLos beneficios de Quarto se aprecian mejor cuando se usa en RStudio. Desde allí resulta muy sencillo crear un nuevo documento Quarto, ya que se carga juntamente. Simplemente debemos clicar en el icono “New File” en la esquina superior izquierda del menú, y seleccionar “Quarto document…”.\n\nLa siguiente ventana te pedirá un título, autor, y el formato en el quieras que se genere el documento final. Por defecto hay tres opciones: html, pdf, o word. El más versátil es html, que permite usar plantillas y generar presentaciones, páginas web, etc. De hecho este tutorial está hecho con Quarto. También se pueden usar plantillas con un formato predefinido. Todas estas decisiones se pueden cambiar después. De momento, daremos al documento un título, indicamos el autor, y elijamos “HTML” como formato de salida:\n\n\n\n\nEl nuevo fichero Quarto - que es de hecho un fichero de texto plano con la extensión .qmd se debería abrir en el lado izquierdo, encima del panel de consola.\n\nEl documento ya tiene algo de contenido, que sirve de ejemplo o “plantilla”. Tiene tres partes:\n\nUna cabecera YAML en la parte superior, rodeada de dos líneas de tres guiones (---). Esto controla los metadatos (título, autor, fecha) y el tipo de formato de salida que queremos. Aquí tendremos la información que hayamos introducido antes, y la podremos modificar si queremos hacer cambios a posteriori.\nTrozos de código R rodeado de tres guiones ```. Al ejecutar el documento, se ejecutarán estos trozos de código y se mostrará el resultado debajo.\nTexto al que se puede dar formato, como por ejemplo ponerlo en **negrita** o crear ## cabeceras.\n\nEn un documento .qmd el texto, el código y la salida están intermezclados. Puedes correr cada uno de los trozos de código haciendo click en “Run” (un botón de “play” situado en la parte superior de cada trozo de código), o bien presionando Cmd/Ctrl + Shift + Enter. RStudio ejecutará ese código y mostrará los resultados junto con el código:\n\nPara producir un informe completo que contenga todo el código, texto etc debéis hacer click en “Render” o presionar Cmd/Ctrl + Shift + K. Esto mostrará el informe en el panel de visualización, y creará un archivo - en el formato elegido - con el resultado, que puede ser compartido con otras personas."
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#añadiendo-y-formateando-texto",
    "href": "00_RMarkdown_Quarto.html#añadiendo-y-formateando-texto",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.4 Añadiendo y formateando texto",
    "text": "3.4 Añadiendo y formateando texto\nFormatear texto en Quarto es muy sencillo. Los ficheros .qmd permiten indicar:\n\ntexto en negrita y cursiva\nlistas\nsecciones y cabeceras (títulos de sección)\nenlaces\nimágenes\ny muchos más…\n\nEl texto simple se escribe como cualquier otro documento. Pero formatearlo es igualmente sencillo:\n\nPara insertar un espacio entre párrafos, incluye una línea en blanco.\nPara forzar un salto de línea, pon dos espacios en blanco\nal final de la línea.\nCursiva: pon tu texto entre asteriscos (*texto en cursiva*) o guiones bajos (_Texto en cursiva_).\nNegrita: pon el texto entre dos asteriscos (**ejemplo negrita**) o dos guiones bajos (__texto en negrita__).\nSuperíndice: debes rodear el texto entre ^ como aquí: X^2^.\nTambién podemos hacer que el texto aparezca como código así: code\nCabeceras de sección se pueden añadir poniendo el símbol del hashtag # antes del título (y dejando un espacio). Cuantos más # pongas, menor será el texto (nivel inferior)\n\n # Título nivel 1\n ## Título nivel 2\n ### Título nivel 3\n\nTambién podemos crear listas muy fácilmente. Las listas sin orden se crean con -, * o +, y las listas ordenadas con números.\n\n# Lista sin orden\n- Item 1\n- Item 2\n    - Item 2a\n    - Item 2b\n- Item 3\n\n\n# Lista ordenada\n1. Primer item\n2. Segundo item\n3. Tercer item\n\nLos Enlaces se asocian a un texto poniendo el texto entre corchetes [] y el enlace entre paréntesis ():\n\n\nesto es un [ejemplo](http://ejemplo.com)\n\n\nPara insertar imágenes (no generadas por código) empezaremos con un signo de exclamación ! y luego el pie de foto, y finalmente la ruta a la imagen (respecto al directorio de tu documento .qmd) o la URL en el caso de una imagen externa. Aquí hay dos ejemplos, uno por una imagen local y el otro para una imagen externa\n\n\n![Imagen local](images/02-intro-rmarkdown/etsea.jpg)\n\n![Imagen remota](https://upload.wikimedia.org/wikipedia/commons/b/ba/Sagrada_Familia_nave_roof_detail.jpg)\n\n\n\n\nImagen local\n\n\n\n\n\nImagen remota"
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#documentos-formateados",
    "href": "00_RMarkdown_Quarto.html#documentos-formateados",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.5 Documentos formateados",
    "text": "3.5 Documentos formateados\nPodemos ver un ejemplo de formateado completo:\n\n## Mis series favoritas\nEs muy difícil elegir mis series favoritas, hay tantas para elegir!\nQuizá es más sencillo si las separamos en **dramas** y **comedias**.\n\n### Mis series de darama favoritas\n\n1. Breaking bad\n2. The West Wing\n3. Doctor en Alaska\n4. Better call Saul\n5. The Expanse\n\n### Mis comedias favoritas:\n\nEn el caso de las comedias, se me hace imposible hacer un ránking, pero *entre* mis favoritas estarían seguro:\n\n- Monty Python Flying Circus\n- The Office\n    - The Office versión UK\n    - The Office version americana\n- Seinfeld\n\n### Encontrar nuevas series\nPara encontrar nuevas series, podemos consultar [IMDB](https://www.imdb.com/chart/toptv/)\nEn función de las puntuaciones, esta debería ser la siguiente serie que vea:\n    \n![](images/02-intro-rmarkdown/got.jpg)\nEl resultado de este código sería:\n\n\nEditor Visual de Quarto en RStudio   Cuando abrimos un documento Quarto en RStudio, veremos que arriba se nos muestran 2 pestañas: “Source” y “Visual”. La primera nos permite visualizar el documento con el texto en formato Markdown. Es decir, veremos el texto formateado de la manera que hemos visto hasta ahora, y sólo veremos el resultado cuando ejecutemos el fichero. En la segunda opción, “Visual”, RStudio nos ofrece una interfaz visual WYSIWYG, donde puedes utilizar los botones de la barra de menú para formatar el texto, insertar imágenes, tablas, referencias cruzadas, etc. o puedes utilizar el atajo de teclado ⌘ + / o Ctrl + / para insertar casi cualquier cosa.  \nLo más importante es que, aunque el editor visual muestra el contenido con formato, en realidad guarda el contenido en Markdown sin formato y puedes alternar entre el editor visual y el de código fuente para ver y editar el contenido con cualquiera de las dos herramientas. Aunque al principio es lógico usar el editor visual, mi consejo es acostumbrarse a editar el documento de la forma tradicional, o al menos a alternar ambos, ya que eso nos dará un mayor control sobre lo que hacemos, y nos permitirá aprender el lenguaje Markdown, lo que puede ser útil para otras situaciones.\n\n\nEJERCICIO:\n\nDescargad el fichero comprimido “series.zip”, abrid series.qmd, que contiene el código de arriba, y ejecutadlo. Comprobad que el resultado corresponde con lo que esperabais.\nUsando lo que habéis aprendido hasta ahora, cread un nuevo fichero Quarto, y generad un documento corto que contenga texto formateado, similar a series.qmd. El tema es libre, pero incluid al menos algo de texto en negrita, en cursiva, algunas cabeceras, una lista y un enlace. Guardadlo como ejercicio_quarto.qmd y ejecutadlo."
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#usando-código-en-quarto-chunks",
    "href": "00_RMarkdown_Quarto.html#usando-código-en-quarto-chunks",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.6 Usando código en Quarto (chunks)",
    "text": "3.6 Usando código en Quarto (chunks)\nPara ejecutar código en un documento Quarto, debemos especificar que el texto que viene a continuación es código. Esto lo hacemos creando un trozo de código, también llamado “chunk”, que no es más que un fragmento de código que tiene entidad propia, es decir, que puede ser ejecutado y hace algo. Está precedido por ```{r} debe comenzar en una linea nueva, y acaba con tres “acentos graves``` . El código como tal va en medio. Aquí vemos como ejemplo un código que genera 1000 números aleatorios según una distribución normal de media = 0 y sd = 1, y después genera un histograma con esos números:\n```{r}\nnumbers &lt;- rnorm(1000, mean = 0, sd = 1)\nhist(numbers)\n```\nEste código genera esta salida:\n\n\n\n\n\nFijaos como el código que hemos escrito se incluye en el fichero de salida, con un formato similar al que vemos en R. También se incluye el resultado del código, debajo del mismo. Esto es muy útil porque nos permite ver en un mismo lugar el código que hemos generado, y su resultado.\n\n3.6.1 Crear chunks\nPara ejecutar código dentro de un documento Quarto, debemos incluirlo en un chunk. Hay tres maneras de crear un chunk:\n\nLas teclas Cmd/Ctrl + Alt + I\nEl botón “Insert” en la barra de editor (sólo en la pestaña Visual)\nTecleando a mano los delimitadores ```{r} para comenzar el chunk y ```para cerrarlo.\n\nIndependientemente de cómo lo creemos, tiene este aspecto:\n```{r}\n```\nY una vez creado, podemos teclear dentro el código que queramos:\n```{r}\n norm &lt;- rnorm(100, mean = 0, sd = 1)\n ```\nEs importante señalar que el código dentro de un chunk se comporta como código “normal” de R. Eso quiere decir que cualquier objeto o paquete que sea necesario para ejecutar el código se tendrá que haber cargado en la sesión antes de intentar ejecutarlo. Lo mismo pasa con los datos, que se deben cargar antes de trabajar con ellos.\nEl chunk tiene una cabecera, y dentro de las llaves ({}) es donde se especifica el lenguaje de programación (recuerda que Quarto funciona con R, Python, Julia…). Puedes ejecutar cada chunk individualmente en cualquier momento situando el cursos dentro del mismo y clickando Run &gt; Run Current Chunk (la flecha verde en la parte de arriba a la derecha). La salida se muestra justo debajo del chunk.\n\nTambién podemos ejecutar todos los chunks a la vez. o todos los chunks por encima del actual. En cualquier caso, el código R de cada chunk se evalúa y ejecuta en orden al hacer “Render” en el documento. Si alguno de los chunks produce un error, R nos avisará, y el documento de salida no se generará.\n\n\n3.6.2 Etiquetando los chunks\nComo hemos descrito antes, la cabecera del chunk consiste en ``{r}, seguido por una etiqueta opcional del chunk y varias otras opciones del chunk, cada una en su propia línea, marcada por#|`. Por ejemplo, podemos dar un nombre al chunk:\n\n1 + 1\n\n[1] 2\n\n\nAunque no sea obligatorio, etiquetar los chunks es una buena práctica, ya que nos permite navegar entre los chunks en el menú de la derecha.\n\n\n\n3.6.3 Opciones de los chunks\nEl comportamiento de los chunks se puede personalizar con opciones, que no son más que argumentos que podemos dar en la cabecera del chunk, cada uno en su linea, y empezando con #|. Hay casi 60 opciones diferentes, aquí solo mencionaremos las más importantes. El resto las podéis ver aquí: https://yihui.org/knitr/options/.\nLas opciones más importantes controlan si el código del chunk se ejecuta y si se incluyen o no los resultados:\n\neval: false hace que el código no se evalúe (es decir, que no se ejecute, y por lo tanto no genere resultados). Es una manera cómoda de desactivar trozos largos de código (por ejemplo, análisis que al final descartamos, pero que queremos dejar por si acaso).\ninclude: false hace que ni el código ni el resultado se muestren en el documento final. Sin embargo, sí que ejecuta el código en la sombra, de manera que los resultados se pueden usar por los siguientes chunks. Esto es útil, por ejemplo, para cargar datos y paquetes.\necho: false el resultado aparecerá, pero el código que lo generó no. Es útil para escribir informes destinados a gente que no está interesada en ver el código que hemos usado, pero si los resultados.\nmessage: false o warning: false impide que aparezcan en el resultado final mensajes de error o avisos\n\nCada una de estas opciones de chunk se añade a la cabecera del chunk, siguiendo a #|, por ejemplo, en el siguiente chunk el resultado no se imprime ya que eval: false:\n\n2 * 2"
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#figuras",
    "href": "00_RMarkdown_Quarto.html#figuras",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.7 Figuras",
    "text": "3.7 Figuras\nSi un chunk prodice una figura, esta se mostrará inmediatamente debajo del chunk, y Quarto maximizará su altura, cumpliendo con los márgenes del documento y manteniendo el ratio de altura/anchura. Por lo tanto, algunas figuras pueden resultar enormes en el documento final. Para cambiar manualmente las dimensiones, podemos insertar instrucciones en la cabecera del chunk:\n```{r}\n#|  fig-width: 4\n#|  fig-height: 3\n\nnorm &lt;- rnorm(100, mean = 0, sd = 1)\nhist(rnorm)\n```"
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#tablas",
    "href": "00_RMarkdown_Quarto.html#tablas",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.8 Tablas",
    "text": "3.8 Tablas\nPor defecto, Quarto imprime los data frames y las matrices como las verías en la consola:\n```{r}\niris[1:5, ]\n```\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n\n\npara darles formato adicional, se puede usar la función kable() del paquete knitr()\n\nlibrary(knitr)\nkable(iris[1:5, ], \n      caption = \"Una tabla hecha con knitr. Queda mejor, ¿no?\"\n)\n\n\nUna tabla hecha con knitr. Queda mejor, ¿no?\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n Hay numerosos paquetes destinados a generar tablas de alta calidad con R. Algunos son:\n\nxtable\nstargazer\npander\ntables\nascii\n\n\nEJERCICIO:\nAhora que sabéis como producir un documento Quarto completo, quiero que créeis uno usando el dataset mtcarsque viene cargado por defecto en R. Este dataset contiene datos de consumo de combustible y otras 10 variables de diseño y prestaciones de 32 modelos de coche. Tiene por tanto 32 filas y 11 columnas. Teclea ?mtcars en la consola para saber más del dataset y de las variables que contiene."
  },
  {
    "objectID": "00_RMarkdown_Quarto.html#para-saber-más",
    "href": "00_RMarkdown_Quarto.html#para-saber-más",
    "title": "3  Introducción a Quarto y RMarkdown",
    "section": "3.9 Para saber más",
    "text": "3.9 Para saber más\nQuarto es aún relativamente reciente, pero está creciendo muy muy rápido debido a su versatilidad. El mejor sitio para estar al día de las novedades es su página oficial: https://quarto.org/. Incluye una Guía de Quarto.\nRStudio también produce “chuletas” para la mayoría de sus productos, y Quarto no es una excepción. Incluye las principales funciones en un formato compacto, para tenerlo siempre a mano. Podéis encontrarlo aquí"
  },
  {
    "objectID": "01_RegresionLineal.html#antes-de-ajustar-la-regresión",
    "href": "01_RegresionLineal.html#antes-de-ajustar-la-regresión",
    "title": "4  Regresión lineal en R",
    "section": "4.1 Antes de ajustar la regresión…",
    "text": "4.1 Antes de ajustar la regresión…\nComo hemos visto en teoría, la regresión lineal es el proceso de obtención de una ecuación o fórmula matemática que capture la relación entre una variable respuesta o dependiente y una o varias variables explicativas o independientes. En realidad, esta definición encaja en cualquier tipo de regresión, no sólo la lineal, y la particularidad de la regresión lineal es que asumimos que la relación entre la variable dependiente (que llamaremos y) y la variable explicativa (x) es lineal, es decir, que la ecuación es una recta."
  },
  {
    "objectID": "01_RegresionLineal.html#nuestros-datos",
    "href": "01_RegresionLineal.html#nuestros-datos",
    "title": "4  Regresión lineal en R",
    "section": "4.2 Nuestros datos",
    "text": "4.2 Nuestros datos\nPara esta actividad vamos a trabajar con la tabla (o data frame) llamado meteo, que podemos encontrar en el campus virtual, dentro de la carpeta “Recursos/Datos/meteo”, en un fichero llamado “meteo.txt”. Dicha tabla contiene las siguientes variables climáticas del mes de junio, extraídas de una serie de estaciones meteorológicas en el valle del Ebro:\n\nTavgMAX: temperatura media de las máximas de junio, en ºC\nTavg: temperatura media diaria de junio, en ºC\nd_atl: distancia al océano Atlántico (en m)\nd_medit: distancia al mar Mediterráneo en m\nelevation: altitud sobre el nivel del mar (m)\nlong: longitud en UTM, sistema de referencia EPSG:23030\nlat: latitud en UTM, sistema de referencia EPSG:23030\n\nPara cargar la tabla a nuestra sesión de R debemos guardarla en el ordenador, y después podemos usar el menú “Import Dataset” o copiar y ejecutar el siguiente código:\n\nlibrary(tidyverse)\nmeteo &lt;- read_delim(\"./data/meteo/meteo.txt\",  # cambia la ruta según el caso!!!!\n                     \"\\t\", locale = locale(date_names = \"es\", \n                                           decimal_mark = \",\", \n                                           grouping_mark = \".\"))\n\nUna vez el data frame está cargado, podemos echar un vistazo a las variables (y su tipo) tecleando head() o summary():\n\nhead(meteo)\n\n# A tibble: 6 × 7\n  TavgMAX  Tavg   long  d_atl d_medit     lat elevation\n    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1    20.3  14.6 614350 305753  152147 4489750      1423\n2    23.8  16.1 593950 271251  183121 4522150      1100\n3    24.4  18.2 567250 279823  204123 4512650      1229\n4    20.1  14.0 609150 319257  150357 4475450      1610\n5    20.3  13.8 629450 306673  138390 4491350      1402\n6    21.9  16.2 666750 317312  103530 4489850      1022\n\n\n\nsummary(meteo)\n\n    TavgMAX           Tavg            long            d_atl       \n Min.   :18.20   Min.   :13.85   Min.   :566050   Min.   : 43783  \n 1st Qu.:23.00   1st Qu.:16.80   1st Qu.:628925   1st Qu.:132564  \n Median :25.05   Median :18.80   Median :690750   Median :211925  \n Mean   :24.79   Mean   :18.64   Mean   :687373   Mean   :216455  \n 3rd Qu.:26.90   3rd Qu.:20.55   3rd Qu.:738600   3rd Qu.:293938  \n Max.   :30.50   Max.   :23.50   Max.   :817550   Max.   :425054  \n    d_medit            lat            elevation     \n Min.   :   670   Min.   :4399050   Min.   :   2.0  \n 1st Qu.: 92912   1st Qu.:4539325   1st Qu.: 302.0  \n Median :159376   Median :4638550   Median : 505.5  \n Mean   :159368   Mean   :4615250   Mean   : 575.7  \n 3rd Qu.:227630   3rd Qu.:4700250   3rd Qu.: 813.8  \n Max.   :325945   Max.   :4757850   Max.   :1610.0  \n\n\nEl primer paso antes de realizar un análisis de regresión - o de ajustar cualquier modelo - entre dos o más variables es realizar un análisis exploratorio de los datos: podemos, por ejemplo, representar un histograma o boxplot de las variables, para comprobar que no hay valores aberrantes, y es muy recomendable también realizar un gráfico de dispersión (o scatterplot, en inglés) para ver la pinta que tiene la relación entre ellas.\nEn este caso, nos interesa saber la relación que hay entre la elevación (elevation) y la temperatura media del mes de junio (Tavg), veamos la distribución que siguen ambas variables:\n\nhist(meteo$Tavg)\n\n\n\nhist(meteo$elevation)\n\n\n\n\nAparentemente, no presentan problemas. Ambas siguen distribuciones bastante normales, sin presencia de valores anómalos, o distribuciones sesgadas. También podemos analizar su distribución mediante boxplots:\n\nboxplot(meteo$Tavg)\n\n\n\nboxplot(meteo$elevation)\n\n\n\n\nY finalmente, veamos la magnitud de la relación entre ambas a través de su coeficiente de correlación. Para calcularlo usaremos la función cor() de R:\n\ncor(meteo$elevation, meteo$Tavg)\n\n[1] -0.8629255\n\n\nTambién es siempre recomendable evaluar la forma de la relación entre ambas a través de un gráfico de dispersión o scatterplot, para detectar posibles tendencias no lineales:\n\nplot(x = meteo$elevation, y = meteo$Tavg)\n\n\n\n\nParece que sí puede haber una relación, y que efectivamente tiene aspecto de ser lineal. Vamos a ajustar la regresión para comprobarlo:"
  },
  {
    "objectID": "01_RegresionLineal.html#la-regresión-lineal-en-r",
    "href": "01_RegresionLineal.html#la-regresión-lineal-en-r",
    "title": "4  Regresión lineal en R",
    "section": "4.3 La regresión lineal en R",
    "text": "4.3 La regresión lineal en R\nR tiene incluidas una serie de funciones estadísticas, las principales, que se incluyen en el paquete stats, que viene por defecto instalado en R (no hace falta instalarlo). Para ajustar, o calibrar, regresiones lineales, utilizaremos la función lm. Podemos teclear help(\"lm\") para ver cómo funciona y qué argumentos requiere esta función:\n\nhelp(\"lm\")\n\n\nlm(formula, data, subset, weights, na.action, method = \"qr\", model = TRUE, x = FALSE, \n   y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset)\n\nVemos que hay numerosos argumentos, pero la mayoría no son necesarios a no ser que queramos una configuración particular. En realidad sólo necesitamos dos:\n\nformula: aquí especificamos qué variables, de las incluidas en nuestra tabla, usaremos para ajustar la regresión. Además, al contrario que en la correlación, debemos definir cuál es la variable dependiente, y cuál o cuales son las variables independientes. Una fórmula tiene este aspecto:\nvar_dep ~ v_indep_1 + v_indep_2 + v_indep_3 +\n\nComo vemos, la var. dependiente y la/s independiente/s se separan por el operador ~\n\ndata: especifica el objeto que contiene las variables. Todas las variables definidas en la fórmula deben estar incluidas en data"
  },
  {
    "objectID": "01_RegresionLineal.html#regresión-lineal-simple",
    "href": "01_RegresionLineal.html#regresión-lineal-simple",
    "title": "4  Regresión lineal en R",
    "section": "4.4 Regresión lineal simple",
    "text": "4.4 Regresión lineal simple\nVamos a ajustar una regresión simple (llamada así porque sólo contiene una variable independiente), en la que evaluaremos el papel de la altitud (elevation) en la temperatura media (Tavg), usando el data frame meteo que hemos cargado antes. Para ello especificamos la fórmula:\n\nlm(Tavg ~ elevation, data = meteo)\n\n\nCall:\nlm(formula = Tavg ~ elevation, data = meteo)\n\nCoefficients:\n(Intercept)    elevation  \n  21.923433    -0.005711  \n\n\n\nEs importante tener claro que en el caso de una regresión lineal, tendremos una variable que queremos predecir (variable dependiente, Tavg) y otra a partir de la que obtendremos las predicciones (var. independiente, elevation). Es decir, queremos predecir la temperatura a partir de la elevación. Debemos tener eso en cuenta a la hora de definir la fórmula.\n\nEjecutando el código de arriba obtenemos la lista de los coeficientes de regresión (\\(\\beta_0\\) y \\(\\beta_1\\)), que son útiles para construir la ecuación de la recta de regresión. Un coeficiente positivo indica que la relación entre la variable dependiente y la variable independiente es positiva, y al contrario. En este caso, el resultado nos dice que, cada metro que subimos en altitud, la temperatura baja de media 0.0057 grados. O lo que es lo mismo, cada 100 m que subimos, baja 0.57 grados la temperatura Por otro lado, el coeficiente del intercepto puede interpretarse como \\(\\beta_0\\), el valor de temperatura cuando la altitud es igual a 0.\nSin embargo, si ejecutamos lm (o cualquier otra función) sin guardar el resultado, se imprime en la consola pero no se guarda. Para guardarlo, le asignaremos un nombre, el que queramos:\n\nmod_lm &lt;- lm(Tavg ~ elevation, data = meteo)\n\nAhora lo guarda, pero no imprime nada. Si tecleamos el nombre del objeto, lo imprime, y obtenemos lo mismo que antes:\n\nmod_lm\n\n\nCall:\nlm(formula = Tavg ~ elevation, data = meteo)\n\nCoefficients:\n(Intercept)    elevation  \n  21.923433    -0.005711  \n\n\nO aún mejor, podemos usar la función summary(), que proporciona mucha más información:\n\nsummary(mod_lm)\n\n\nCall:\nlm(formula = Tavg ~ elevation, data = meteo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7830 -0.7583 -0.0210  0.8804  3.4625 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 21.9234334  0.1481962  147.94   &lt;2e-16 ***\nelevation   -0.0057107  0.0002196  -26.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.184 on 232 degrees of freedom\nMultiple R-squared:  0.7446,    Adjusted R-squared:  0.7435 \nF-statistic: 676.5 on 1 and 232 DF,  p-value: &lt; 2.2e-16\n\n\nVeamos que podemos obtener de summary():\n\nEl grado de ajuste (o bondad de ajuste) del modelo (R-squared), calculada a través del estadístico \\(F\\), y su significación\nLos cuartiles de los residuos, que nos dan una idea de si los residuos se encuentran simétricamente distribuidos a ambos lados del 0 - lo que sería deseable - o no.\nLa estimación de los coeficientes del modelo, tanto el intercepto como cada una de las variables explicativas. Estos números son los que forman parte de la fórmula de regresión.\nLa significación de los coeficientes: junto con la estmación del coeficiente, se nos da el cálculo del error estándar y del estadístico \\(t\\), que se usa para evaluar el p-valor, representado aquí por la columna Pr(&gt;|t|)\n\n\n4.4.1 Visualizando la regresión\nComo hemos guardado el resultado de la regresión en un objeto (que hemos llamado mod_lm), podemos usarlo, por ejemplo, para hacer gráficas.\nEmpecemos por plotear como antes la elevación y la temperatura:\n\nplot(meteo$elevation, meteo$Tavg)\n\n\n\n\nahora podemos añadir la ecuación de regresión usando la función abline(). Esta función tiene como argumento un objeto de regresión, y nos devuelve la linea recta calculada mediante la regresión:\n\nplot(meteo$elevation, meteo$Tavg) +\n    abline(mod_lm)\n\n\n\n\ninteger(0)\n\n\nEn contra de lo que cabría esperar, si ploteamos directamente el objeto de la regresión no nos dará la gráfica de arriba, sino que nos da una serie de gráficos sobre los residuos, que veremos más adelante.\n\nplot(mod_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSobre la visualización de los datos   Ya hemos comentado varias veces la importancia de visualizar nuestros datos antes de extraer ninguna conclusión de ellos. Hay una cierta tendencia a considerar que una simple visualización no aporta demasiado, ya que sólo podemos llegar a conclusiones cualitativas, mientras que un análisis de correlación o regresión es estadística y por tanto nos proporcionan información numérica que podemos cuantificar (¿es la variable significativa?). Sin embargo, no debemos NUNCA interpretar los resultados de un análisis sin visualizar los datos.  Un ejemplo de esto es el cuarteto de Anscombe, creado en 1973 por el estadístico británico Francis Anscombe. Se trata de cuatro datasets que contienen cada uno una variable x y una y. Podemos acceder a ellos mediante el paquete datasets, con la instrucción library(datasets) y tecleando a continuación anscombe Para comprobar qué tiene de particular este dataset, realizad lo siguiente:  1. Calculad la media y desviación típica de todas las x, y de todas las y  2. Calculad la correlación entre x e y para los cuatro datasets  3. Ajustad un modelo lineal para cada par de x e y  4. Representad visualmente cada pareja de x e y  ¿Qué observamos?   \n\n\n\n4.4.2 Haciendo predicciones a partir de nuestro modelo\nUno de los objetivos principales de la regresión es conocer la ecuación que relaciona la variable dependiente con la independiente, de manera que podamos predecir, para cualquier valor de \\(x\\), cual sería el valor de \\(y\\) esperado.\nPara hacer predicciones, podríamos simplemente construir una nueva variable usando los coeficientes obtenidos de la regresión:\n\ncoef(mod_lm)\n\n (Intercept)    elevation \n21.923433399 -0.005710663 \n\npredicciones &lt;- 21.923433 - 0.005711*meteo$elevation\npredicciones\n\n  [1] 13.79668 15.64133 14.90461 12.72872 13.91661 16.08679 16.88633 17.19472\n  [9] 14.45344 15.15019 18.55965 18.94229 21.24382 21.79779 21.79779 21.46655\n [17] 21.80350 17.26326 21.78637 14.19645 15.37863 16.06395 16.25241 16.44658\n [25] 14.29925 14.53340 19.54195 20.82121 15.44716 20.51282 20.43286 21.91201\n [33] 21.72355 21.84919 21.02109 21.80921 21.42658 15.36149 21.28951 19.43344\n [41] 20.31293 18.97085 16.97771 17.33179 18.63961 19.58192 19.48484 20.30151\n [49] 14.99028 15.16732 16.52083 16.84635 16.82351 16.93202 17.31466 17.34321\n [57] 16.11535 16.27525 17.50312 17.92573 17.82294 19.15360 19.42773 17.78867\n [65] 19.02796 18.31979 19.31922 18.59392 16.05824 17.88004 18.26268 18.91374\n [73] 19.19357 19.47341 18.45115 18.95942 19.80465 20.25582 18.37690 18.37690\n [81] 18.77096 19.02224 18.78809 19.38775 18.61105 18.91945 18.94229 19.06793\n [89] 19.15360 16.85206 16.92060 20.05594 20.20442 20.33006 20.43286 20.31864\n [97] 20.43286 20.31864 17.86291 19.57050 19.94743 20.30722 19.30208 19.69043\n[105] 19.69043 20.62704 17.38890 19.45628 20.35291 17.61734 19.48484 20.31864\n[113] 19.44486 20.71841 17.67445 15.60136 17.75440 18.43972 16.13819 14.49913\n[121] 15.13876 14.82466 17.60021 19.47912 16.99484 18.52539 19.73041 19.95314\n[129] 18.51397 20.60419 18.39403 20.74126 20.73554 14.29925 15.90975 17.09193\n[137] 16.99484 17.53167 16.82922 18.03424 18.99369 19.17073 18.78238 18.73669\n[145] 19.73041 17.49741 19.75896 19.86747 19.71328 20.41573 20.53566 20.68415\n[153] 19.75896 19.74183 21.05536 17.12619 17.02911 18.77667 16.50369 16.51512\n[161] 18.62247 20.14731 20.33577 20.70699 18.47970 14.69331 15.68702 16.09250\n[169] 14.95601 18.19415 19.31922 20.15873 21.16958 21.09534 20.39860 18.97656\n[177] 19.98740 20.79265 20.86119 20.31864 15.74413 18.97656 18.89660 19.05651\n[185] 18.69101 12.87150 19.12504 18.26839 18.50825 19.45628 20.05022 20.00454\n[193] 20.07307 17.66874 20.51282 20.56993 19.26782 19.74754 18.83378 20.52995\n[201] 20.52995 18.88518 16.08679 19.42773 19.86747 19.85034 20.18158 19.75896\n[209] 19.81036 19.81036 20.09591 20.55850 20.15873 20.34720 21.15816 19.23355\n[217] 17.84578 18.93087 20.23298 19.04509 20.87261 19.39346 21.75210 19.10220\n[225] 21.73497 19.86176 20.64417 20.23298 21.60933 15.29296 16.12106 16.07537\n[233] 16.19530 15.47571\n\n\nSin embargo, R incluye la función predict() que hace esto por nosotros automáticamente, lo cual es muy útil sobre todo en el caso de regresiones múltiples. predict() necesita que le demos dos inputs:\n\nun objeto de regresión (en este caso mod_lm)\nuna tabla o data frame que contenga todas y cada una de las variables explicativas usadas para ajustar el modelo\n\nLo que hace predict() es, para cada fila de la tabla que le indiquemos, calcular el valor de \\(y\\) usando los valores de las diferentes \\(x\\) para esa fila y los coeficientes estimados por el modelo. En el caso de la regresión simple, mod_lm calculará el valor de temperatura media para cada valor de altitud que contenga la tabla:\n\npredict(mod_lm, meteo)\n\n       1        2        3        4        5        6        7        8 \n13.79716 15.64170 14.90503 12.72927 13.91708 16.08714 16.88663 17.19500 \n       9       10       11       12       13       14       15       16 \n14.45389 15.15059 18.55985 18.94247 21.24386 21.79780 21.79780 21.46658 \n      17       18       19       20       21       22       23       24 \n21.80351 17.26353 21.78638 14.19691 15.37901 16.06429 16.25275 16.44691 \n      25       26       27       28       29       30       31       32 \n14.29970 14.53384 19.54209 20.82128 15.44754 20.51290 20.43295 21.91201 \n      33       34       35       36       37       38       39       40 \n21.72356 21.84919 21.02115 21.80922 21.42661 15.36188 21.28955 19.43358 \n      41       42       43       44       45       46       47       48 \n20.31303 18.97102 16.97800 17.33206 18.63980 19.58206 19.48498 20.30161 \n      49       50       51       52       53       54       55       56 \n14.99069 15.16772 16.52115 16.84665 16.82381 16.93231 17.31493 17.34348 \n      57       58       59       60       61       62       63       64 \n16.11569 16.27559 17.50338 17.92597 17.82318 19.15376 19.42787 17.78891 \n      65       66       67       68       69       70       71       72 \n19.02813 18.32001 19.31937 18.59412 16.05858 17.88028 18.26290 18.91391 \n      73       74       75       76       77       78       79       80 \n19.19374 19.47356 18.45135 18.95960 19.80478 20.25592 18.37711 18.37711 \n      81       82       83       84       85       86       87       88 \n18.77115 19.02242 18.78828 19.38790 18.61125 18.91962 18.94247 19.06810 \n      89       90       91       92       93       94       95       96 \n19.15376 16.85236 16.92089 20.05605 20.20452 20.33016 20.43295 20.31874 \n      97       98       99      100      101      102      103      104 \n20.43295 20.31874 17.86315 19.57064 19.94754 20.30732 19.30224 19.69056 \n     105      106      107      108      109      110      111      112 \n19.69056 20.62711 17.38917 19.45643 20.35300 17.61759 19.48498 20.31874 \n     113      114      115      116      117      118      119      120 \n19.44501 20.71848 17.67470 15.60173 17.75465 18.43993 16.13853 14.49957 \n     121      122      123      124      125      126      127      128 \n15.13917 14.82508 17.60046 19.47927 16.99513 18.52559 19.73054 19.95325 \n     129      130      131      132      133      134      135      136 \n18.51417 20.60427 18.39424 20.74133 20.73562 14.29970 15.91011 17.09221 \n     137      138      139      140      141      142      143      144 \n16.99513 17.53193 16.82952 18.03447 18.99386 19.17089 18.78257 18.73688 \n     145      146      147      148      149      150      151      152 \n19.73054 17.49767 19.75909 19.86759 19.71341 20.41582 20.53574 20.68422 \n     153      154      155      156      157      158      159      160 \n19.75909 19.74196 21.05541 17.12648 17.02940 18.77686 16.50401 16.51544 \n     161      162      163      164      165      166      167      168 \n18.62267 20.14742 20.33587 20.70706 18.47990 14.69373 15.68739 16.09285 \n     169      170      171      172      173      174      175      176 \n14.95642 18.19437 19.31937 20.15884 21.16963 21.09539 20.39869 18.97673 \n     177      178      179      180      181      182      183      184 \n19.98752 20.79272 20.86125 20.31874 15.74450 18.97673 18.89678 19.05668 \n     185      186      187      188      189      190      191      192 \n18.69120 12.87203 19.12521 18.26861 18.50846 19.45643 20.05034 20.00465 \n     193      194      195      196      197      198      199      200 \n20.07318 17.66899 20.51290 20.57001 19.26798 19.74767 18.83396 20.53003 \n     201      202      203      204      205      206      207      208 \n20.53003 18.88536 16.08714 19.42787 19.86759 19.85046 20.18168 19.75909 \n     209      210      211      212      213      214      215      216 \n19.81049 19.81049 20.09602 20.55858 20.15884 20.34729 21.15820 19.23371 \n     217      218      219      220      221      222      223      224 \n17.84602 18.93105 20.23308 19.04526 20.87267 19.39361 21.75211 19.10237 \n     225      226      227      228      229      230      231      232 \n21.73498 19.86188 20.64424 20.23308 21.60935 15.29335 16.12140 16.07571 \n     233      234 \n16.19564 15.47609 \n\n\nIncluso podemos guardar estas predicciones como una columna más de meteo:\n\nmeteo$pred &lt;-  predict(mod_lm, meteo)\n\nhead(meteo)\n\n# A tibble: 6 × 8\n  TavgMAX  Tavg   long  d_atl d_medit     lat elevation  pred\n    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1    20.3  14.6 614350 305753  152147 4489750      1423  13.8\n2    23.8  16.1 593950 271251  183121 4522150      1100  15.6\n3    24.4  18.2 567250 279823  204123 4512650      1229  14.9\n4    20.1  14.0 609150 319257  150357 4475450      1610  12.7\n5    20.3  13.8 629450 306673  138390 4491350      1402  13.9\n6    21.9  16.2 666750 317312  103530 4489850      1022  16.1\n\n\nAhora podríamos hacer un gráfico que compare los valores predichos y los observados:\n\nplot(meteo$Tavg, meteo$pred)\n\n\n\n\nLo interesante de la función predict() es que no hace falta aplicarla a la misma tabla de datos que hemos usado para ajustar el modelo, sino que si tenemos una serie de datos nueva (de otras estaciones, u otras fechas) también podemos calcular el valor predicho por el modelo. En este caso, para cualquier punto del que tengamos la altitud, podemos determinar la temperatura media. Abramos el otro fichero que teníamos disponible en el campus virtual, llamado meteo_nuevo.txt:\n\nmeteo2 &lt;- read_delim(\"./data/meteo/meteo_nuevo.txt\", \"\\t\")\n\nRows: 100 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\ndbl (2): elevation, d_medit\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeteo2\n\n# A tibble: 100 × 2\n   elevation d_medit\n       &lt;dbl&gt;   &lt;dbl&gt;\n 1      793.  204153\n 2      864.  193620\n 3      939.  209678\n 4      706.  221949\n 5      787.  210552\n 6      934.  188943\n 7      802.  222480\n 8     1061.  203576\n 9      836.  219916\n10      735.  202829\n# ℹ 90 more rows\n\n\nVemos que es una tabla que contiene valores de altitud y distancia al mediterráneo, pero no contiene de hecho valores de temperatura. En base al modelo que ajustamos antes, podemos generarlos con predict():\n\nmeteo2$temp &lt;- predict(mod_lm, meteo2)\nmeteo2\n\n# A tibble: 100 × 3\n   elevation d_medit  temp\n       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1      793.  204153  17.4\n 2      864.  193620  17.0\n 3      939.  209678  16.6\n 4      706.  221949  17.9\n 5      787.  210552  17.4\n 6      934.  188943  16.6\n 7      802.  222480  17.3\n 8     1061.  203576  15.9\n 9      836.  219916  17.1\n10      735.  202829  17.7\n# ℹ 90 more rows\n\n\nEsta opción es muy interesante, ya que cuando generamos una ecuación de regresión, raramente queremos aplicarla sobre los datos ya observados, sino que querremos usarla para predecir valores en aquellos lugares donde no tengamos medidas.\n\nConsejo:Debemos ser responsables, sin embargo, de no extrapolar más allá de lo lógico: si el modelo de regresión se ha ajustado con datos del valle del Ebro, ¿tiene sentido aplicarlos en Galicia?"
  },
  {
    "objectID": "01_RegresionLineal.html#regresión-lineal-múltiple",
    "href": "01_RegresionLineal.html#regresión-lineal-múltiple",
    "title": "4  Regresión lineal en R",
    "section": "4.5 Regresión lineal múltiple",
    "text": "4.5 Regresión lineal múltiple\nDe la misma manera que ajustamos una regresión lineal simple, podemos ajustar una múltiple, simplemente añadiendo más variables independientes a la derecha de la fórmula, después del ~:\n\nmod_mult &lt;- lm(Tavg ~ d_atl + d_medit + elevation, data = meteo)\nmod_mult\n\n\nCall:\nlm(formula = Tavg ~ d_atl + d_medit + elevation, data = meteo)\n\nCoefficients:\n(Intercept)        d_atl      d_medit    elevation  \n  2.156e+01    3.749e-06   -3.393e-06   -5.545e-03  \n\n\nA efectos prácticos, el modelo múltiple y el simple son prácticamente iguales, aunque en este caso la función summary nos da la significación de cada una de las variables:\n\nsummary(mod_mult)\n\n\nCall:\nlm(formula = Tavg ~ d_atl + d_medit + elevation, data = meteo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8514 -0.5623  0.0526  0.6173  3.1647 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.156e+01  9.105e-01  23.676   &lt;2e-16 ***\nd_atl        3.749e-06  2.404e-06   1.560    0.120    \nd_medit     -3.393e-06  2.846e-06  -1.192    0.235    \nelevation   -5.545e-03  2.136e-04 -25.959   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.982 on 230 degrees of freedom\nMultiple R-squared:  0.8257,    Adjusted R-squared:  0.8235 \nF-statistic: 363.3 on 3 and 230 DF,  p-value: &lt; 2.2e-16\n\n\nVemos que la R2 del modelo ha mejorado de forma sustancial. Pero recordemos que se considera el efecto de una variable como no significativo si el p-valor asociado a ella es mayor de 0.05. Eso quiere decir que el riesgo de rechazar la hipótesis nula (el riesgo de asumir una relación cuando no la hay) es demasiado alto, y por tanto no la rechazamos. En este caso, vemos que ni la distancia al Mediterráneo ni la distancia al Atlántico resultan significativas. Según lo visto en clase, sería mejor eliminarlas, pero por otro lado nos hacen subir el R2 de manera muy clara. Probemos a quitar sólo una de ellas:\n\nmod_mult2 &lt;- lm(Tavg ~ d_medit + elevation, data = meteo)\nsummary(mod_mult2)\n\n\nCall:\nlm(formula = Tavg ~ d_medit + elevation, data = meteo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.7490 -0.5785  0.0227  0.5727  3.3712 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.296e+01  1.595e-01  143.88   &lt;2e-16 ***\nd_medit     -7.675e-06  7.528e-07  -10.20   &lt;2e-16 ***\nelevation   -5.378e-03  1.856e-04  -28.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.985 on 231 degrees of freedom\nMultiple R-squared:  0.8239,    Adjusted R-squared:  0.8224 \nF-statistic: 540.3 on 2 and 231 DF,  p-value: &lt; 2.2e-16\n\n\n¡Ahora sí que la distancia al Mediterráneo resulta significativa, y la R2 del modelo (0.82) sigue siendo muy superior a la del modelo simple (0.74). Lo curioso es que si hubiéramos eliminado d_medit, también sería significativa d_atl (podéis hacer la prueba) ¿Qué puede estar pasando?\nLo que estamos viendo es un ejemplo de multicolinealidad. Como la distancia al Mediterráneo y al Atlántico están muy relacionadas (si aumenta una, disminuye la otra), si introducimos las dos en el modelo este no es capaz de distinguir el efecto de cada una de ellas, y concluye que no tienen efecto. De hecho, veamos como de correlacionadas están estas dos variables:\n\ncor(meteo$d_atl, meteo$d_medit)\n\n[1] -0.9525821\n\n\nPor tanto, dejaremos sólo una de ellas en el modelo, en este caso la distancia al Mediterráneo. Lo interesante es que podemos predecir temperaturas en nuestra tabla de nuevos valores, usando el modelo de regresión múltiple:\n\npredict(mod_mult2, meteo2)\n\n       1        2        3        4        5        6        7        8 \n17.12514 16.82208 16.29817 17.45700 17.10434 16.48407 16.93618 15.68594 \n       9       10       11       12       13       14       15       16 \n16.76974 17.44436 18.06764 16.64387 17.27120 16.09408 16.66035 17.05316 \n      17       18       19       20       21       22       23       24 \n16.14305 14.78709 15.94748 15.39889 20.87385 16.08418 16.61257 17.58826 \n      25       26       27       28       29       30       31       32 \n16.22689 16.74222 17.28661 14.11201 17.53732 19.11453 14.50081 14.66675 \n      33       34       35       36       37       38       39       40 \n18.31549 18.71684 13.93286 18.06864 17.19598 19.16897 15.03308 16.40134 \n      41       42       43       44       45       46       47       48 \n16.58971 16.81448 17.25677 16.16466 16.32135 16.86009 15.64677 17.75046 \n      49       50       51       52       53       54       55       56 \n14.12446 17.88584 14.74712 16.78598 17.13428 16.43328 18.71701 16.22936 \n      57       58       59       60       61       62       63       64 \n16.38941 18.04153 17.36000 18.77970 15.24015 17.34046 17.37639 13.99712 \n      65       66       67       68       69       70       71       72 \n14.95117 18.21192 18.30910 18.33676 16.91608 18.87682 17.01177 15.09166 \n      73       74       75       76       77       78       79       80 \n18.54233 19.18103 13.98042 17.05097 15.85675 18.48408 17.58232 16.75660 \n      81       82       83       84       85       86       87       88 \n16.20362 12.84291 16.13229 19.39104 18.98500 17.45716 15.43576 18.05760 \n      89       90       91       92       93       94       95       96 \n15.81553 17.08892 17.60376 18.81896 15.97251 16.41554 16.04488 17.89542 \n      97       98       99      100 \n15.21175 17.32653 18.20423 16.26098 \n\n\nEsto funcionará siempre que la tabla que proporcionemos contenga todas y cada una de las variables explicativas del modelo. Si intentamos predecir con el modelo que contiene d_atl, recibiremos este mensaje de error:\n\npredict(mod_mult, meteo2)\n\nError in eval(predvars, data, env): objeto 'd_atl' no encontrado"
  },
  {
    "objectID": "01_RegresionLineal.html#testando-las-asunciones-del-modelo",
    "href": "01_RegresionLineal.html#testando-las-asunciones-del-modelo",
    "title": "4  Regresión lineal en R",
    "section": "4.6 Testando las asunciones del modelo",
    "text": "4.6 Testando las asunciones del modelo\nHemos visto que los modelos lineales deben cumplir básicamente cuatro criterios:\n\n4.6.1 Linealidad\nla linealidad entre predictores y variable dependiente se puede evaluar gráficamente. En este caso, la relación entre la cota y la temperatura parece claramente lineal, como ya habíamos visto antes:\n\nplot(meteo$elevation, meteo$Tavg)\n\n\n\n\n\n\n4.6.2 Independencia\nLas observaciones deben ser independientes unas de otras (por eso se llaman variables independientes). Aunque una parte importante de la evaluación de la independencia la podemos inferir si conocemos bien la muestra, la gráfica de predichos y residuos nos puede dar también información importante. Ambos los podemos extraer del objeto lm que hayamos guardado, usando las funciones fitted() y residuals(), respectivamente:\n\npredichos &lt;- fitted(mod_lm)\nresiduos &lt;- residuals(mod_lm)\n\nplot(predichos, residuos)\n\n\n\n\nNo parece presentar mayores problemas.\n\n\n4.6.3 Homocedasticidad\nOtro importante criterio que debe seguir un modelo lineal es el de ser homocedástico. Esto quiere decir que los residuos son independientes a los valores de la variable explicativa. O dicho de otra manera, que la varianza del error es constante a lo largo de las observaciones. Lo podemos ver con la misma gráfica de antes:\n\nplot(predichos, residuos)\n\n\n\n\n\n\n4.6.4 Normalidad\nPara evaluar la normalidad de los residuos podemos usar varias gráficas:\n\nHistogramas\n\nUsaremos la función hist(), sobre los residuos del modelo (que se obtienen con la función residuals()):\n\nhist(residuals(mod_lm))\n\n\n\n\n\nBoxplot\n\nMediante la función boxplot() podemos construir un diagrama de cajas con cualquier variable (en este caso, recordad que se debe hacer sobre los residuos):\n\nboxplot(residuals(mod_lm), col = \"steelblue\")\n\n\n\n\n\nQQplot\n\n\nqqnorm(residuals(mod_lm), pch = 1, frame = FALSE)\nqqline(residuals(mod_lm), col = \"steelblue\", lwd = 2)\n\n\n\n\nTodas estas gráficas parecen estar razonablemente bien. Si queremos una evaluación más cuantitativa, también podemos usar tests para saber si los residuos están normalmente distribuidos o no. Un ejemplo es el test de Shapiro-Wilk:\n\nshapiro.test(residuals(mod_lm))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(mod_lm)\nW = 0.99415, p-value = 0.4982\n\n\nEn este caso, la hipótesis nula del test de Shapiro-Wilk es que la distribución de la variable testada es normal. Por lo tanto, si el resultado del test es no significativo quiere decir que no podemos rechazar la hipótesis nula, es decir, que no podemos rechazar que la distribución sea normal (en definitiva, que sí que es normal).\nPor supuesto, esta lógica funciona al contrario: si el resultado del test de Shapiro-Wilk es significativo, quiere decir que la variable que estamos testando (en este caso los residuos), no siguen una distribución normal.\n\nSobre los tests de normalidad  Además del test de Shapiro-Wilk existen otros tests para evaluar de manera estadística si una variable sigue una distribución normal. Aunque se pueden usar para tomar decisiones respecto a un modelo, hay que hacerlo sabiendo que la mayoría de estos tests son muy estrictos. Es decir, que incluso una ligera desviación respecto de la normalidad resultará en significación del test. Debemos tener sentido común para decidir si esto invalida nuestro modelo o no, como hemos visto durante las clases teóricas:\n\nPor otro lado, como hemos indicado antes, algunas de las gráficas de evaluación de los supuestos del modelo nos los da directamente R mediante el ploteo del objeto lm:\n\nplot(mod_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn concreto nos interesan los dos primeros: un scatterplot de residuos vs. predichos, y un qqplot con los residuos. Con ellos podemos testar al menos 3 de las 4 asunciones."
  },
  {
    "objectID": "01_RegresionLineal.html#regresión-usando-variables-espacialmente-continuas",
    "href": "01_RegresionLineal.html#regresión-usando-variables-espacialmente-continuas",
    "title": "4  Regresión lineal en R",
    "section": "4.7 Regresión usando variables espacialmente continuas",
    "text": "4.7 Regresión usando variables espacialmente continuas\nHemos visto que la función predict() permite calcular la variable dependiente en función de las variables explicativas. Pero aún más, si tenemos un mapa continuo con los valores de las variables explicativas, predict() nos permitirá generar un raster continuo de predicciones espacializadas. Veamos un ejemplo.\nEn este caso, tenemos una serie de rasters de una zona de estudio, y que corresponden con las variables que hemos usado antes para ajustar el modelo: altitud, distancia al Atlántico y distancia al Mediterráneo. Lo primero es cargar los tres rasters, para lo que necesitaremos la librería terra y su función rast():\n\nlibrary(terra)\n\nterra 1.7.78\n\n\n\nAdjuntando el paquete: 'terra'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nelevation &lt;- rast(\"./data/meteo/meteo_espacial/rasters_meteo/elevation.txt\")\nd_atl &lt;- rast(\"./data/meteo/meteo_espacial/rasters_meteo/d_atl.txt\")\nd_medit &lt;- rast(\"./data/meteo/meteo_espacial/rasters_meteo/d_medit.txt\")\n\nPodemos visualizarlos de manera sencilla con plot():\n\nplot(elevation)\n\n\n\nplot(d_atl)\n\n\n\nplot(d_medit)\n\n\n\n\nAhora vamos a guardar esos 3 rasters en un único objeto, como si fuera un raster multibanda. Este objeto se conoce como stack. Para crearlo usaremos la función c():\n\nrasters &lt;- c(elevation, d_atl, d_medit)\n\nComo los componentes del stack tienen los mismos nombres que usamos para ajustar el modelo, podemos realizar predicciones usando los valores continuos de los rasters. Cuando tecleemos predict() R reconocerá que el input son rasters, y usará la función predict() del paquete terra. La función predict()del paquete terrase diferencia en el número y orden de los argumentos. Primero hay que proporcionarle el SpatRaster que contiene las variables, y después el modelo ajustado - al revés de lo que hacíamos antes.\n\npred_continua &lt;- predict(rasters, mod_lm)\n\nAhora ya podemos representar las predicciones, que en este caso, como el input era un raster, será también un raster:\n\nplot(pred_continua)\n\n\n\n\nPor supuesto, el procedimiento funcionaría exactamente igual con un modelo de regresión múltiple:\n\npred_cont_multiple &lt;- predict(rasters, mod_mult2)\nplot(pred_cont_multiple)"
  },
  {
    "objectID": "02_GLM.html#introducción-los-modelos-lineales-generalizados-glms",
    "href": "02_GLM.html#introducción-los-modelos-lineales-generalizados-glms",
    "title": "5  Regresión lineal generalizada (GLM) en R",
    "section": "5.1 Introducción: los modelos lineales generalizados (GLMs)",
    "text": "5.1 Introducción: los modelos lineales generalizados (GLMs)\nYa hemos visto en las clases teóricas que la regresión lineal generalizada (o modelos lineales generalizados, GLM) son una alternativa sólida a los casos en los que nuestra variable dependiente no sigue una distribución normal, y por tanto, los residuos de la regresión lineal no cumplirán los supuestos de la misma. Los GLM abordan estos problemas flexibilizando la distribución de la variable respuesta, y conectándola con un predictor lineal a través de una función de enlace (link function). Vamos a ver ahora ejemplos con algunas de las distribuciones más habituales - más allá de la normal:"
  },
  {
    "objectID": "02_GLM.html#regresión-de-conteos-la-distribución-de-poisson",
    "href": "02_GLM.html#regresión-de-conteos-la-distribución-de-poisson",
    "title": "5  Regresión lineal generalizada (GLM) en R",
    "section": "5.2 Regresión de conteos: la distribución de Poisson",
    "text": "5.2 Regresión de conteos: la distribución de Poisson\nUno de los casos más habituales en los que debemos usar los GLM es cuando nuestra variable dependiente son conteos. En este caso seguirán una distribución de Poisson, que se caracteriza como el número de veces que un determinado evento ocurrirá en un intervalo de tiempo. Si es un conteo de abundancia, por ejemplo, la variable dependiente será el número de plantas (eventos) en un muestreo. La distribución de Poisson tiene un sólo parámetro \\(\\lambda\\), que es la media de eventos esperada. Así, si generamos una serie de 100 observacions con \\(\\lambda\\) = 5:\n\npoisson &lt;- rpois(500,5)\nhist(poisson, breaks = 20, main = \"Histograma de dist. Poisson de media 5\", xlab = \"Número de eventos\")\n\n\n\n\nvemos que todos los valores son números enteros, ya que no puede haber, lógicamente, valores como 3,56 plantas.\nPara ajustar cualquier GLM usaremos la función glm, que viene cargada por defecto en R y que tiene tres argumentos principales:\n\nFormula: la ecuación que define la variable dependiente y las independientes. Es igual que en la regresión lineal.\ndata: el data frame que contiene las variables\nfamily: una descripción de la distribución que sigue el error y la función de enlace a usar. En el caso de conteos debe tomar el valor \"poisson\"\n\nVamos a ajustar una sencilla regresión Poisson usando datos de:\nhttps://stats.idre.ucla.edu/stat/data/poisson_sim.csv\nEn este ejemplo, num_awards es el número de premios ganados por los alumnos de un instituto en un año, math es una variable continua que representa la nota obtenida por los estudiantes en el examen final de matemáticas, y prog es una variable categórica con tres niveles que indica el tipo de programa en el que están matriculados: 1 = “General”, 2 = “Academic” y 3 = “Vocational”.\nComo siempre, carguemos los datos y echémosles un vistazo:\n\npremios &lt;- read.csv('https://stats.idre.ucla.edu/stat/data/poisson_sim.csv')\nstr(premios)\n\n'data.frame':   200 obs. of  4 variables:\n $ id        : int  45 108 15 67 153 51 164 133 2 53 ...\n $ num_awards: int  0 0 0 0 0 0 0 0 0 0 ...\n $ prog      : int  3 1 3 3 3 1 3 3 3 3 ...\n $ math      : int  41 41 44 42 40 42 46 40 33 46 ...\n\n\n\nhead(premios)\n\n   id num_awards prog math\n1  45          0    3   41\n2 108          0    1   41\n3  15          0    3   44\n4  67          0    3   42\n5 153          0    3   40\n6  51          0    1   42\n\n\nAhora podemos ajustar un modelo de Poisson. Para ello:\n\nmod.poisson &lt;- glm(num_awards ~ math + prog,  data = premios, family = \"poisson\")\nsummary(mod.poisson)\n\n\nCall:\nglm(formula = num_awards ~ math + prog, family = \"poisson\", data = premios)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -5.578057   0.676823  -8.242   &lt;2e-16 ***\nmath         0.086121   0.009586   8.984   &lt;2e-16 ***\nprog         0.123273   0.163261   0.755     0.45    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 287.67  on 199  degrees of freedom\nResidual deviance: 203.45  on 197  degrees of freedom\nAIC: 385.51\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n5.2.1 Interpretando los resultados de un GLM de Poisson\nLa salida de resultados cuando ejecutamos la orden summary() en un GLM es muy parecida al de los modelos de regresión lineal, aunque con algunos matices. Por ejemplo, ahora no nos proporciona el R2 del modelo, ya que su cálculo no es posible. Además, si bien la significación de los coeficientes estimados tiene la misma interpretación que en modelos lineales (si p&lt; 0.05 podemos rechazar que esa variable no tenga un efecto), los valores de los coeficientes no pueden interpretarse de manera directa.\nPor ejemplo, en el modelo ajustado más arriba vemos que, cuanto mayor es la nota en matemáticas, más premios han recibido, ya que el coeficiente de math es positivo y altamente significativo. Pero no podemos concluir que por cada punto que suba la nota de mates, se aumente en 0.086 el número de premios.\nLa manera de intepretar la salida es la siguiente: cuando \\(x=0\\), entonces el valor esperado es la media de \\(y\\) y toma una valor de \\(e^\\alpha\\), donde \\(\\alpha\\) es el intercepto. Con cada unidad de incremento en \\(x\\), el valor predicho tiene un efecto multiplicativo de \\(e^\\beta\\) en la media de \\(y\\), por lo tanto \\(y=e^\\alpha*e^{\\beta*X}\\), y si \\(X = 0\\) entonces \\(y = e^\\alpha\\)\nEn el ejemplo de arriba, el número medio de premios esperados es \\(e^{-5.578057} = 0.00378\\), y con cada punto de más que el alumno obtiene en mates, este número esperado de premios aumenta \\(e^{0.086121} = 1.08\\) veces, es decir, aumenta un 8%.\n\n\n5.2.2 Haciendo predicciones con GLMs de Poisson\nIgual que hicimos con la regresión lineal, podemos obtener los valores predichos por el modelo, exactamente de la misma manera, con la función predict(). La única salvedad es que aquí tenemos que especificar el tipo de respuesta que queremos, con el argumento type. Esto es porque la función predict(), cuando el modelo es de tipo GLM, nos permite obtener el valor predicho para la variable respuesta (type = \"response\") o el valor del predictor lineal que nos servía de enlace (type = \"link\"). En este caso - y casi siempre - nos interesa el primero, así que:\n\npredict(mod.poisson, premios, type = 'response')\n\n        1         2         3         4         5         6         7         8 \n0.1868820 0.1460475 0.2419764 0.2036898 0.1714611 0.1591828 0.2874596 0.1714611 \n        9        10        11        12        13        14        15        16 \n0.0938323 0.2874596 0.1714611 0.1275925 0.2419764 0.1324219 0.1714611 0.1229392 \n       17        18        19        20        21        22        23        24 \n0.1734994 0.1443317 0.2331516 0.1573126 0.1591828 0.2637393 0.1714611 0.1714611 \n       25        26        27        28        29        30        31        32 \n0.1962612 0.3290378 0.1891036 0.2246485 0.2541208 0.1652079 0.1591828 0.3133132 \n       33        34        35        36        37        38        39        40 \n0.1962612 0.3290378 0.1714611 0.1573126 0.3722052 0.1800664 0.1734994 0.1652079 \n       41        42        43        44        45        46        47        48 \n0.5793276 0.3586309 0.2139126 0.1573126 0.4260411 0.1868820 0.1573126 0.1229392 \n       49        50        51        52        53        54        55        56 \n0.4819345 0.3018867 0.2331516 0.1714611 0.2246485 0.3586309 0.1962612 0.1734994 \n       57        58        59        60        61        62        63        64 \n0.5061220 0.1591828 0.2637393 0.4474233 0.3133132 0.2331516 0.1962612 0.1714611 \n       65        66        67        68        69        70        71        72 \n0.4819345 0.4819345 0.2061113 0.3290378 0.4643584 0.4474233 0.3586309 0.3018867 \n       73        74        75        76        77        78        79        80 \n0.3908855 0.1460475 0.4421668 0.2246485 0.6240131 0.2246485 0.8175828 0.2331516 \n       81        82        83        84        85        86        87        88 \n0.5725215 0.5061220 0.3908855 0.2908769 0.6801357 0.4643584 0.2908769 0.5793276 \n       89        90        91        92        93        94        95        96 \n0.1591828 0.2874596 0.2637393 0.4876638 0.3133132 0.3586309 0.1868820 0.3766300 \n       97        98        99       100       101       102       103       104 \n0.6553312 0.5252789 0.4421668 0.5793276 0.3908855 0.1714611 0.4056806 0.7413059 \n      105       106       107       108       109       110       111       112 \n0.0871130 0.3290378 0.3170378 0.4876638 0.3018867 0.4260411 0.4643584 0.7785107 \n      113       114       115       116       117       118       119       120 \n1.4225834 0.6553312 0.5061220 0.7413059 0.5061220 0.5061220 0.5061220 0.3290378 \n      121       122       123       124       125       126       127       128 \n0.4421668 0.7142705 0.8485286 0.3908855 1.0986822 0.3586309 0.4643584 0.4643584 \n      129       130       131       132       133       134       135       136 \n0.5516417 0.6012554 0.3290378 0.9248437 0.2908769 0.6553312 1.4225834 0.5315234 \n      137       138       139       140       141       142       143       144 \n0.8485286 0.6553312 0.7785107 0.7142705 0.6553312 1.1974957 0.7501185 0.4474233 \n      145       146       147       148       149       150       151       152 \n0.9248437 0.6314313 0.5315234 0.7501185 0.5516417 0.6553312 1.0080225 0.6012554 \n      153       154       155       156       157       158       159       160 \n0.3908855 0.6801357 0.8175828 1.0986822 0.9248437 1.5505280 0.3018867 0.9248437 \n      161       162       163       164       165       166       167       168 \n0.5793276 0.2668747 1.3051964 1.0080225 0.9248437 0.5252789 0.6314313 1.1974957 \n      169       170       171       172       173       174       175       176 \n1.3051964 0.5315234 0.9712600 0.6553312 2.3850033 1.6092159 1.0080225 0.7142705 \n      177       178       179       180       181       182       183       184 \n1.0986822 1.1974957 2.3850033 1.1974957 1.8419734 2.0076372 1.4225834 0.6314313 \n      185       186       187       188       189       190       191       192 \n1.0080225 1.5505280 1.1974957 1.0986822 1.6899797 3.0881232 1.8419734 1.3051964 \n      193       194       195       196       197       198       199       200 \n2.1882005 2.1882005 0.8485286 2.1882005 3.4932624 2.1882005 2.3850033 2.5995063 \n\n\nY como hicimos con la regresión lineal, podemos guardar estos datos como una columna en nuestro data frame premios:\n\npremios$pred &lt;-  predict(mod.poisson, premios, type = 'response')\nhead(premios)\n\n   id num_awards prog math      pred\n1  45          0    3   41 0.1868820\n2 108          0    1   41 0.1460475\n3  15          0    3   44 0.2419764\n4  67          0    3   42 0.2036898\n5 153          0    3   40 0.1714611\n6  51          0    1   42 0.1591828\n\n\nY ahora podríamos generar una figura de valores predichos vs. observados\n\nplot(num_awards ~ pred, data = premios, pch = 19) \n\n\n\n\nVemos que el ajuste no parece demasiado bueno. Esto nos indica que, si bien la nota de matemáticas es un buen predictor del número de premios obtenido, no parece que sea el único factor a tener en cuenta (lo cual es lógico)."
  },
  {
    "objectID": "02_GLM.html#regresión-de-eventos-binomiales-regresión-logística",
    "href": "02_GLM.html#regresión-de-eventos-binomiales-regresión-logística",
    "title": "5  Regresión lineal generalizada (GLM) en R",
    "section": "5.3 Regresión de eventos binomiales: regresión logística",
    "text": "5.3 Regresión de eventos binomiales: regresión logística\nVamos ahora a trabajar con la regresión logística, que es aquella que se usa cuando la variable respuesta es binomial, es decir, que sólo puede tomar valores 0 y 1. En este caso trabajaremos con el fichero logit.csv que incluye datos sobre incendios en España, y posibles factores causantes, entre 1988 y 2008. El fichero lo podéis encontrar en el campus virtual, y contiene las siguientes variables:\n\ndatos_iiff &lt;- read.csv2(\"./data/glm/iiff_logit.csv\")\n\n\nlogit_1_0: la variable dependiente, codificada como 1 (fuego) y 0 (no fuego)\nCattle: el número de cabezas de ganado ovino\nProt_area: el area (en m^2) cubierta por figuras de protección\nPowerlines: área cubierta por líneas de alta tensión a menos de 200 m de zonas de bosque\nRailroads: area (en m^2) cubierta por líneas de ferrocarril a menos de 200 m de zonas boscosas\nWAI: Wildland-Agricultural interface es el área (en m^2) cubierta por la frontera entre bosques y cultivos.\nWGI: Wildland-Grassland interface es el área (en m^2) cubierta por la frontera entre bosques y pastos.\nWUI: Wildland-Urban Interface es el área (en m^2) cubierta por la frontera entre bosques y asentamientos urbanos\nMachinery: densidad de maquinaria agrícola\nTracks: area cubierta por caminos a menos de 200 m de zonas boscosas.\nChange_pop: cambio relativo de población entre 1990 y 2010\n\nEn principio, todos estos factores deberían tener un efecto positivo, es decir, cuanto mayor su valor, mayor probabilidad de ocurrencia de incendio - con la excepción probablemente de Prot_area.\nAjustemos por tanto el modelo de regresión. En realidad tenemos ya todo lo que necesitamos, excepto conocer la función de enlace a usar. En el caso de una regresión de este tipo, donde la variable respuesta es binomial, el argumento family debe tomar el valor family = \"binomial\".\n\nmod.logit &lt;- glm(logit_1_0 ~ ., data = datos_iiff, family = binomial)\nsummary(mod.logit)\n\n\nCall:\nglm(formula = logit_1_0 ~ ., family = binomial, data = datos_iiff)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.528e+00  9.995e-02 -15.290  &lt; 2e-16 ***\nCattle       1.114e-05  9.975e-06   1.117  0.26407    \nProt_area   -1.502e-07  1.335e-07  -1.125  0.26056    \nPowerlines   2.070e-06  1.299e-06   1.593  0.11113    \nRailroads    1.900e-06  5.890e-07   3.226  0.00125 ** \nWAI          1.466e-05  5.627e-07  26.060  &lt; 2e-16 ***\nWGI         -1.567e-06  2.404e-07  -6.520 7.02e-11 ***\nWUI          2.698e-06  1.058e-06   2.550  0.01078 *  \nMachinery   -2.646e-02  1.796e-02  -1.474  0.14059    \nFAPU         3.445e-07  1.887e-07   1.825  0.06794 .  \nTracks       8.281e-07  3.520e-07   2.353  0.01863 *  \nChange_pop  -2.010e+00  3.959e-01  -5.077 3.84e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4852.9  on 3581  degrees of freedom\nResidual deviance: 2534.2  on 3570  degrees of freedom\nAIC: 2558.2\n\nNumber of Fisher Scoring iterations: 6\n\n\nVemos aquí qué variables efectivamente tienen un efecto significativo. ¿Es en todos los casos en el sentido esperado?\n\n5.3.1 Interpretando los resultados de un GLM logístico\nIgual que hemos comentado antes, los p-valores de las variables, así como el signo del coeficiente, tienen una interpretación directa. Sin embargo, el valor del coeficiente es más complejo de interpretar. En el caso de una regresón logística, la interpretación es similar a la regresión de Poisson. Cada aumento en una unidad de una variable \\(x\\) multiplica la media predicha por \\(e^\\beta\\), donde \\(\\beta\\) es el coeficiente de dicha variable explicativa. En el ejemplo de arriba, si aumenta el cambio de población en una unidad, el valor de probabilidad esperado se multiplicará por \\(e^{-2.010} = 0.134\\), es decir que la probabilidad de incendio disminuirá un \\(1-0.134 = 0.86 = 86\\%\\) respecto la media En el caso de los ferrocarriles, un aumento en la superficie de ferrocarril de 1m2 generará un cambio de \\(e^{2.070e-06}= 1.000002076\\) en la probabilidad de incendio media. Como vemos, a pesar de que la variable es significativa, las magnitudes son pequeñas - lo cual es lógico si pensamos que la variable explicativa representa la superficie de ferrocarril en m2, no es esperable que un metro cuadrado de más aumente de manera brusca el riesgo de incendio.\n\n\n5.3.2 Haciendo predicciones con GLM logístico\nLa manera de realizar las predicciones es la misma que hemos visto en el modelo de Poisson, con una salvedad:\n\nmod.logit.pred &lt;- predict(mod.logit, datos_iiff, type = 'response')\n\nPuesto que la variable respuesta era binomial, lo que cabría obtener son predicciones binarias, es decir, que sólo tomen valores de 0 o 1. Sin embargo, las predicciones son continuas. Esto es así porque lo que calcula es una probabilidad de que esa observación haya sufrido o no un incendio. Cuanto más cerca de uno, mayor es la probabilidad. Esta distribución se llama distribución logística, y por ello la regresión de eventos de salida binaria (si/no, hombre/mujer, etc.) a menudo se llama regresión logística. No obstante, si el modelo es bueno, la mayoría de los valores predichos deberían estar cerca de 0 o cerca de 1:\n\nhist(mod.logit.pred, col='steelblue',breaks = 15, xlab = 'Predicted probability')\n\n\n\n\nGuardemos las predicciones como una columna de nuestra tabla de datos:\n\ndatos_iiff$predicted &lt;- predict(mod.logit, datos_iiff, type = 'response')\n\nAhora podríamos, por ejemplo, ver la distribución de valores predichos (que son continuos) respecto a los observados (que son binarios).\n\nboxplot(predicted ~ logit_1_0, data = datos_iiff, col = c(\"darkgreen\", \"darkred\"), xlab= \"Observados\")\n\n\n\n\nVemos que en general, los casos donde no ha habido incendio (logit_1_0 = 0) tienen predicciones más bajas, lo que sugiere que el modelo ha funcionado bastante bien. Una opción de determinar el grado de acierto del modelo (ya que aquí no tenemos R^2) es calcular una tabla de contingencia, que es una tabla de aciertos y errores. Para ello debemos convertir nuestras predicciones en una variable binaria, definiendo un umbral o punto de corte, que por lógica podemos establecer en 0.5. De esta manera, todos los casos en los que la probabilidad predicha sea &gt; 0.5, los asignaremos a una predicción de que sí ha habido incendio, y al contrario:\n\ndatos_iiff$pred_bin = ifelse(test = datos_iiff$predicted &gt; 0.5,\n                             yes = 1, \n                             no = 0)\n\nAhora podemos construir una tabla de contingencia, usando la función table():\n\naccuracy &lt;- table(datos_iiff$logit_1_0, datos_iiff$pred_bin)\nprint(accuracy)\n\n   \n       0    1\n  0 2044   64\n  1  375 1099\n\n\nY calcular el porcentaje de aciertos como la suma de la diagonal de esta tabla dividida entre el total de casos:\n\ncorrectos &lt;- sum(diag(accuracy))\ntotal &lt;- sum(accuracy)\n\nporc_correctos &lt;- 100*correctos/total\nporc_correctos\n\n[1] 87.74428\n\n\nEn este caso hemos obtenido un 88% de aciertos, es decir que el modelo clasifica bien el 88% de los eventos. Esta medida no se puede interpretar de la misma manera que un coeficiente de determinación (R2) pero sí nos da una idea de la bondad de nuestro modelo."
  },
  {
    "objectID": "02_GLM.html#conclusiones",
    "href": "02_GLM.html#conclusiones",
    "title": "5  Regresión lineal generalizada (GLM) en R",
    "section": "5.4 Conclusiones",
    "text": "5.4 Conclusiones\nHemos visto como el ajuste de un modelo lineal generalizado en R no presenta mayor dificultad respecto a los modelos lineales. Sin embargo, hay que tener cuidado con la interpretación, que no es tan directa. Igualmente, cuando generemos predicciones debemos tener siempre en cuenta de indicar type = \"response\" para obtener los valores predichos para la variable dependiente. Aquí hemos visto cómo ajustar modelos de Poisson y logísticos, que son los más habituales, pero los GLMs incluyen otros como Gamma, Gaussiano, etc. Para saber más sobre GLMs y R os invito a consultar esta web: https://rpubs.com/JessicaP/459130"
  },
  {
    "objectID": "03_DatosEspaciales.html#introducción",
    "href": "03_DatosEspaciales.html#introducción",
    "title": "6  Trabajando con datos espaciales en R",
    "section": "6.1 Introducción",
    "text": "6.1 Introducción\nEl objetivo de este \\(lab\\) es familiarizarse con el uso y representación de información espacial en \\(R\\). Además de las funciones estadísticas que ya hemos visto, existen en \\(R\\) miles de paquetes, cada uno con un propósito específico. Varios de ellos permiten interactuar con datos espaciales, tanto en formato vectorial como raster. Los principales paquetes “espaciales” son:\n\nrgdal\nsf\nterra\nstars\ntmap\n\nEstas librerías (paquetes) permiten leer y gestionar objetos espaciales, ya sea en formato vectorial o ficheros raster como ASCII o cualquier otro formato soportado por GDAL. Estos paquetes funcionan como un GIS, permitiéndonos realizar la mayoría de geoprocesos (intersecciones, uniones, etc.), así como procesos geoestadísticos avanzados y crear mapas.\nDurante años, tres de los paquetes más populares para trabajar con datos espaciales en R han sido rgdal, raster y sp, que se convirtieron prácticamente en un estandard. Sin embargo, por diversos problemas, en 2022 se decidió deprecarlos, es decir, dejar de darles soporte, y se recomendó sustituirlos por sus “equivalentes”: terray sf. Desde octubre de 2023, aún pueden usarse las funciones de sp y raster, pero rgdal ha sido retirado, por lo que nos centraremos en conocer las funcionalidades de terray sf.\nObviamente, no podremos profundizar en toda la potencialidad de estos dos paquetes, que cada vez más logran sustituir perfectamente a un GIS de escritorio, pero sí veremos algunas de sus opciones más básicas."
  },
  {
    "objectID": "03_DatosEspaciales.html#trabajando-con-vectores",
    "href": "03_DatosEspaciales.html#trabajando-con-vectores",
    "title": "6  Trabajando con datos espaciales en R",
    "section": "6.2 Trabajando con vectores",
    "text": "6.2 Trabajando con vectores\n\n6.2.1 Cargar información vectorial\nSabemos que los archivos shapefile de ESRI, que son casi un estándar en el mundo del SIG, son en realidad un conjunto de varios ficheros. Pero para cargarlos en \\(R\\), al igual que hacemos en ArcMap, basta con cargar el que tiene extensión .shp, ya que el resto van asociados a él. Sin embargo, si queremos copiar o cortar nuestros “shapes” en otra carpeta debemos tener cuidado de copiar todos los ficheros.\nVeamos un ejemplo, importando las capas estaciones_meteo.shp y provincias.shp, que se encuentran en la carpeta datos/shapes, dentro de la sección “Recursos” del campus virtual de la asignatura. Estas capas contiene la información espacial de parte de las estaciones meteorológicas de las que extrajimos la información para ajustar la regresión lineal, así como los límites de todas las provincias de España.\nPara leerlos en R podemos usar la función st_read() del paquete sf, por lo que antes que nada, instalamos y cargamos el paquete sf:\n\n# install.packages('sf')\nlibrary(sf)\n\nY posteriormente cargamos los ficheros, especificando la ruta al archivo .shp y asignándoles un nombre:\n\nestaciones &lt;- st_read('data/meteo/meteo_espacial/estaciones_meteo.shp') \n\nReading layer `estaciones_meteo' from data source \n  `C:\\Users\\Usuari\\OneDrive - udl.cat\\Teaching\\EFCN_Geoestadística\\Labs_Geoestadistica_Forestal\\data\\meteo\\meteo_espacial\\estaciones_meteo.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 90 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 574966 ymin: 4514365 xmax: 818327 ymax: 4635648\nProjected CRS: ETRS89 / UTM zone 30N\n\n\nVemos que, al leer los ficheros, la consola nos informa sobre el nuevo objeto que estamos creando. Identifica que el fichero de origen es un shapefile de ESRI, y nos informa de que se convertirá en un objeto “simple feature” con 90 observaciones de tipo “punto” y 13 campos. También nos informa sobre el bounding box del objeto espacial (el rectángulo que lo contiene) y su sistema de referencia de coordenadas o CRS.\nUn objeto simple feature es el método que ha elegido sf para lidiar con información espacial. Los objetos espaciales almacenan tanto información relativa a las características espaciales (sistema de referencia, extensión, coordenadas de los objetos…) como a los atributos de cada uno de los objetos (en este caso, la información meteorológica). La ventaja de sf es que lo hace de manera muy lógica y sencilla. Vemos en el panel de Environment que estaciones aparece como un data frame normal. Y es que de hecho es un data frame normal, pero ahora es a la vez más cosas:\n\nclass(estaciones)\n\n[1] \"sf\"         \"data.frame\"\n\n\nLa diferencia es que contiene, además de los atributos que veríamos en ArcMap, una columna llamada geometry con las coordenadas de cada una de las observaciones. La ventaja de esto es que el objeto espacial es un data frame, y por lo tanto podemos procesarlo con normalidad, filtrando, creando nuevas variables o modificando valores, igual que hacemos con los data frames. Al cargar estaciones nos informaba de que se traba de un objeto espacial de puntos. Por tanto cada punto contendrá las coordenadas x e y de ese punto según el CRS del objeto espacial:\n\nestaciones\n\nSimple feature collection with 90 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 574966 ymin: 4514365 xmax: 818327 ymax: 4635648\nProjected CRS: ETRS89 / UTM zone 30N\nFirst 10 features:\n   OBJECTID FID_weathe INDICATIVO AÃ_O MES                    NOMBRE ALTITUD\n1         1         12      9382E 2012   6         PANCRUDO (D.G.A.)    1285\n2         2         85      9987N 2012   6   DELTEBRE (PARC NATURAL)       4\n3         3         11      9377E 2012   6               EL PEDREGAL     985\n4         4         50      9567U 2012   6           EJULVE (D.G.A.)    1095\n5         5         39      9530V 2012   6         UTRILLAS (D.G.A.)     960\n6         6          0       3013 2012   6          MOLINA DE ARAGON    1063\n7         7         70      9939A 2012   6        FUENTESPALDA (DGA)     720\n8         8         40      9531X 2012   6    MONTALBAN 'AUTOMATICA'     885\n9         9         84      9981A 2012   6 TORTOSA (OBSER. DEL EBRO)      48\n10       10         89       9999 2012   6                      ODON    1110\n   T_MAX_abs T_MIN_abs TMed_MAX TMed_MIN Tmed_MES   Provincia\n1       29.5       3.0     22.0      9.6    15.80      Teruel\n2       32.0      10.0     27.5     17.4    22.45   Tarragona\n3       31.0       3.5     21.5     10.2    15.85 Guadalajara\n4       30.0       5.0     21.9     11.5    16.70      Teruel\n5       32.5       3.5     23.7     10.8    17.25      Teruel\n6       32.8       3.2     23.8      8.4    16.10 Guadalajara\n7       32.0       5.0     24.4     13.2    18.80      Teruel\n8       31.2       5.4     23.0     11.0    17.00      Teruel\n9       34.4      13.0     29.3     17.1    23.20   Tarragona\n10      32.0       4.0     22.4     10.2    16.30      Teruel\n                 geometry\n1  POINT (666121 4514365)\n2  POINT (814489 4514857)\n3  POINT (620767 4515276)\n4  POINT (705449 4516865)\n5  POINT (681326 4520030)\n6  POINT (593975 4522166)\n7  POINT (758868 4522277)\n8  POINT (686217 4522281)\n9  POINT (794466 4524785)\n10 POINT (620133 4526863)\n\n\nVamos a cargar ahora la capa provincias:\n\nprovincias &lt;- st_read('data/meteo/meteo_espacial/provincias_spain.shp') \n\nReading layer `provincias_spain' from data source \n  `C:\\Users\\Usuari\\OneDrive - udl.cat\\Teaching\\EFCN_Geoestadística\\Labs_Geoestadistica_Forestal\\data\\meteo\\meteo_espacial\\provincias_spain.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 51 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -14129.47 ymin: 3892590 xmax: 1126923 ymax: 4859517\nProjected CRS: ETRS89 / UTM zone 30N\n\n\nEl proceso es idéntico, pero ahora nos dice que el objeto creado contiene una geometría tipo multipolygon, es decir, que es un fichero vectorial de polígonos. Ahora, por lo tanto, el campo geometry contendrá, para cada observación, el conjunto de coordenadas que define los vértices del polígono:\n\nprovincias\n\nSimple feature collection with 51 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -14129.47 ymin: 3892590 xmax: 1126923 ymax: 4859517\nProjected CRS: ETRS89 / UTM zone 30N\nFirst 10 features:\n   OBJECTID                INSPIREID COUNTRY\n1         1 ES.IGN.BDDAE.34160100000      ES\n2         2 ES.IGN.BDDAE.34080200000      ES\n3         3 ES.IGN.BDDAE.34100300000      ES\n4         4 ES.IGN.BDDAE.34010400000      ES\n5         5 ES.IGN.BDDAE.34070500000      ES\n6         6 ES.IGN.BDDAE.34110600000      ES\n7         7 ES.IGN.BDDAE.34040700000      ES\n8         8 ES.IGN.BDDAE.34090800000      ES\n9         9 ES.IGN.BDDAE.34070900000      ES\n10       10 ES.IGN.BDDAE.34111000000      ES\n                                                                        NATLEV\n1  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n2  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n3  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n4  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n5  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n6  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n7  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n8  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n9  https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n10 https://inspire.ec.europa.eu/codelist/AdministrativeHierarchyLevel/3rdOrder\n   NATLEVNAME     NATCODE         NAMEUNIT CODNUT1 CODNUT2 CODNUT3 Shape_Leng\n1   Provincia 34160100000      Araba/Álava     ES2    ES21    &lt;NA&gt;   639475.2\n2   Provincia 34080200000         Albacete     ES4    ES42    &lt;NA&gt;   770993.4\n3   Provincia 34100300000 Alacant/Alicante     ES5    ES52    &lt;NA&gt;   583497.3\n4   Provincia 34010400000          Almería     ES6    ES61    &lt;NA&gt;   632690.0\n5   Provincia 34070500000            Ávila     ES4    ES41    &lt;NA&gt;   630836.7\n6   Provincia 34110600000          Badajoz     ES4    ES43    &lt;NA&gt;  1136844.0\n7   Provincia 34040700000    Illes Balears     ES5    ES53    &lt;NA&gt;  1459098.3\n8   Provincia 34090800000        Barcelona     ES5    ES51    &lt;NA&gt;   850790.3\n9   Provincia 34070900000           Burgos     ES4    ES41    &lt;NA&gt;  1138046.5\n10  Provincia 34111000000          Cáceres     ES4    ES43    &lt;NA&gt;   965487.3\n    Shape_Area                       geometry\n1   3035458537 MULTIPOLYGON (((519021.3 47...\n2  14920858305 MULTIPOLYGON (((539277 4215...\n3   5820590272 MULTIPOLYGON (((697663 4195...\n4   8767315137 MULTIPOLYGON (((496730.8 39...\n5   8047820788 MULTIPOLYGON (((292983.8 44...\n6  21793269761 MULTIPOLYGON (((165751.6 42...\n7   5018967692 MULTIPOLYGON (((868245.7 43...\n8   7762160343 MULTIPOLYGON (((898327 4573...\n9  14279022189 MULTIPOLYGON (((419298.4 46...\n10 19885694014 MULTIPOLYGON (((172175.6 43...\n\nprovincias$geometry[1]\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 476582.6 ymin: 4702304 xmax: 562700.7 ymax: 4784934\nProjected CRS: ETRS89 / UTM zone 30N\n\n\nMULTIPOLYGON (((519021.3 4717987, 518976.3 4717...\n\n\n\n\n6.2.2 Representando gráficamente información vectorial\nEvidentemente, cuando trabajamos con datos espaciales una de las acciones más interesantes es representarlos gráficamente. Para ello basta con usar la función plot() y el nombre del objeto espacial\n\nplot(estaciones)\n\nWarning: plotting the first 9 out of 13 attributes; use max.plot = 13 to plot\nall\n\n\n\n\n\nPor defecto nos ploteará todos los campos. Si queremos visualizar específicamente alguno de ellos debemos indicarlo expresamente, poniendo el nombre del campo entre corchetes []:\n\nplot(estaciones[\"Tmed_MES\"])\n\n\n\n\n\\(R\\) mapea los puntos según su ubicación, y les asigna un color en función de los valores de la variable elegida, pero podemos editar la visualización igual que hacemos con los \\(scatterplot\\) o los \\(plots\\) normales.\nPor ejemplo, podemos cambiar el tipo de símbolo con pch, el color con col o el tamaño con cex.\n\nplot(estaciones[\"Tmed_MES\"], pch = 19)\n\n\n\nplot(estaciones[\"Tmed_MES\"], pch = 21, col='black', bg= 'red')\n\n\n\n\nEn caso de que sólo queremos plotear la geometría del objeto (sin incluir ningún atributo) debemos indicarlo con la función st_geometry()\n\nplot(st_geometry(provincias))\n\n\n\n\n\nplot(st_geometry(provincias), col = \"dark red\")\n\n\n\n\nPodemos también combinar dos capas diferentes mediante el comando add = TRUE:\n\nplot(st_geometry(provincias) )\nplot(estaciones[\"Tmed_MES\"], pch = 19, col = \"red\", cex = 0.5, add = TRUE) \n\n\n\n\n\n6.2.2.1 Visualizando capas vectoriales con tmap\nUn paquete interesante para la visualización de información espacial es tmap. Este paquete funciona de manera diferente, ya que le debemos indicar las diferentes capas a visualizar uniendo las órdenes con el símbolo +. Lo primero es indicar la capa que queremos visualizar mediante el comando tm_shape() y luego especificamos si queremos ver puntos (tm_dots()), los bordes de los polígonos (tm_borders()), o los polígonos con relleno (tm_polygons(), entre otras muchas opciones). De cada uno de los comandos tm_* puede personalizarse el color, forma, tamaño, etc. con valores fijos o en función de alguna columna.\nProbemos a visualizar las estaciones:\n\nlibrary(tmap)\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n\ntm_shape(estaciones) +\n    tm_dots()\n\n\n\n\nLógicamente, podemos cambiar el tamaño de los puntos, su forma, o los colores, haciéndolos depender de la variable Tmed_MES e incluso definir la paleta:\n\ntm_shape(estaciones) +\n    tm_dots(size = 1, shape = 20, col = \"Tmed_MES\", palette = \"viridis\")\n\n\n\n\nCon tmaps podemos visualizar tantas capas como queramos, sólo necesitamos volver a utilizar la función tm_shape() con el nombre de la nueva capa. Eso sí, la extensión del mapa vendrá dada por la primera capa que llamemos. Probemos a visualizar las estaciones sobre las provincias del nordeste:\n\ntm_shape(provincias) +\n    tm_polygons(col = \"lightgrey\") +\n    tm_text(\"NAMEUNIT\") +\ntm_shape(estaciones) +\n    tm_dots(col = \"Tmed_MES\", palette = \"viridis\", size = 0.75)\n\n\n\n\nLa extensión espacial del mapa vendrá determinada por la primera capa o shape que carguemos. Si cargamos primero las estaciones:\n\ntm_shape(estaciones) +\n    tm_dots(col = \"Tmed_MES\", palette = \"viridis\", size = 0.75) +\ntm_shape(provincias) +\n    tm_borders() +\n    tm_text(\"NAMEUNIT\") \n\n\n\n\nLas opciones generales del mapa se pueden personalizar mediante tm_layout():\n\ntm_shape(estaciones) +\n    tm_dots(col = \"Tmed_MES\", palette = \"viridis\", size = 0.75,title = \"T media\") +\ntm_shape(provincias) +\n    tm_borders() +\n    tm_text(\"NAMEUNIT\") +\n    tm_layout(legend.outside = F, bg.color = \"steelblue\",title = \"Estaciones meteorológicas del Nordeste\", title.size = 4)\n\n\n\n\nIncluso podemos definir un fondo basado en un proveedor como Google Maps o OpenStreetMap, con la función tm_basemap() y hacer que el mapa sea interactivo definiendo antes tmap_mode(\"view\"): (una lista de las opciones se puede encontrar aquí)\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(estaciones) +\n    tm_dots(col = \"Tmed_MES\", palette = \"viridis\") +\ntm_shape(provincias) +\n    tm_borders() +\n    tm_text(\"NAMEUNIT\") +\n    tm_basemap(\"OpenStreetMap.Mapnik\")\n\n\n\n\n\n\nPor último, una vez tengamos un mapa que nos guste, podemos exportarlo al formato de nuestra elección:\n\nmapa &lt;- tm_shape(estaciones) +\n    tm_dots(col = \"Tmed_MES\", palette = \"viridis\") +\n    tm_shape(provincias) +\n    tm_borders() +\n    tm_text(\"NAMEUNIT\") +\n    tm_basemap(\"OpenStreetMap.Mapnik\")\n\n## Guardar como imagen (modo \"plot\")\ntmap_save(mapa, filename = \"mapa_estaciones.png\")\n\n## Guardar como HTML file (modo \"view\")\ntmap_save(mapa, filename = \"mapa_estaciones.html\")\n\n\n6.2.2.1.1 Para saber más\nExisten numerosos tutoriales online con las principales funcionalidades del paquete tmap. Algunas de las recomendadas son tmap: get started!, el libro tmap book o el capítulo dedicado a tmap del libro Making maps with R\n\n\n\n\n6.2.3 Seleccionando campos, filtros y observaciones\nPero ¿qué pasa si no queremos trabajar con todos los puntos, o si solo queremos representar una parte de los mismos? Como comentábamos antes, un objeto sf no es más que un data.frame con geometría espacial, por lo que podemos hacer con el todas las operaciones que hacemos con un data frame. Por ejemplo, podemos escoger submuestras basadas en valores determinados mediante la función subset():\n\nbajas &lt;- subset(estaciones, ALTITUD &lt;= 500)\n\ntm_shape(estaciones) +\n    tm_dots(col = \"darkgrey\") +\ntm_shape(bajas) +\n    tm_dots(col= \"Tmed_MES\")\n\n\n\n\n\n\nEste comando lo podemos usar también con caracteres de texto:\n\ncatalunya &lt;- subset(provincias, NAMEUNIT %in% c(\"Lleida\", \"Tarragona\"))\n\ntm_shape(catalunya) +\n    tm_borders(col = \"orange\") +\ntm_shape(estaciones) +\n    tm_dots(col= \"Tmed_MES\")\n\n\n\n\n\n\nSin embargo, hay que tener en cuenta que si lo que hacemos es seleccionar una columna extraeremos los valores de la variable como un vector, pero perderemos la información espacial:\n\nestaciones$Tmed_MES\n\n [1] 15.80 22.45 15.85 16.70 17.25 16.10 18.80 17.00 23.20 16.30 17.45 18.75\n[13] 18.45 16.25 21.75 19.75 17.30 18.75 16.10 19.75 19.00 17.90 19.90 20.35\n[25] 16.50 19.90 20.70 22.75 16.35 18.85 16.15 21.65 20.65 20.80 20.80 22.30\n[37] 19.60 22.05 16.40 22.95 20.60 18.70 18.30 19.60 23.50 23.35 22.15 17.80\n[49] 18.35 21.30 16.80 18.00 17.40 18.00 21.60 19.15 19.35 19.55 21.75 20.85\n[61] 21.00 19.85 20.15 20.90 21.70 18.80 16.95 18.10 22.15 22.15 20.55 22.10\n[73] 21.90 21.75 21.95 20.90 21.00 20.55 21.20 20.70 20.30 19.80 20.00 19.85\n[85] 20.70 20.80 20.70 16.75 22.05 21.50\n\n\n\n\n6.2.4 Operaciones espaciales con sf\nsf también permite realizar todas las operaciones espaciales típicas de un GIS como intersectar capas, unirlas, crear buffers, etc. No vamos a ver todo esto con mucho detalle porque se escapa del objetivo de la asignatura, pero podéis encontrar un tutorial muy extenso aquí.\nDe momento solo veremos un ejemplo de intersección entre dos capas:\n\nestaciones_cat &lt;- st_intersection(catalunya, estaciones)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\ntm_shape(catalunya) +\n    tm_borders(col = \"orange\") +\ntm_shape(estaciones_cat) +\n    tm_dots(col= \"Tmed_MES\")"
  },
  {
    "objectID": "03_DatosEspaciales.html#trabajando-con-rasters",
    "href": "03_DatosEspaciales.html#trabajando-con-rasters",
    "title": "6  Trabajando con datos espaciales en R",
    "section": "6.3 Trabajando con rasters",
    "text": "6.3 Trabajando con rasters\nLa información en formato raster es básicamente una matriz de dos dimensiones, en la que cada una de las celdas o píxeles tiene un valor numérico que representa una variable, numérica o categórica. Este tipo de estructura es muy adecuada para representar información sobre fenómenos continuos, como la temperatura, elevación, distancias…\n\n6.3.1 Cargando rasters\nIgual que hicimos con las capas vectoriales, lo primero de todo es cargar la capa en un objeto de R. En este caso usaremos la funcion rast(), del paquete terra. Vamos a cargar un modelo digital de elevaciones de la zona de estudio de las estaciones meteorológicas que se encuentra en la carpeta “Recursos/data/rasters_meteo” del campus virtual\n\n# install.packages('terra', dep = TRUE)\n\nlibrary(terra)\n\nterra 1.7.78\n\ndem &lt;- rast(\"data/meteo/meteo_espacial/rasters_meteo/elevation.txt\")\ndem\n\nclass       : SpatRaster \ndimensions  : 3598, 2594, 1  (nrow, ncol, nlyr)\nresolution  : 100, 100  (x, y)\nextent      : 561200, 820600, 4398400, 4758200  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource      : elevation.txt \nname        : elevation \n\n\nY podemos visualizarlo de forma sencilla mediante plot():\n\nplot(dem)\n\n\n\n\n\n\n6.3.2 Cargar varias capas raster\nPuede que os hayáis dado cuenta de que la carpeta rasters_meteo contiene más ficheros además del de elevaciones. Gracias a las utilidades del paquete terra podremos cargar varias capas raster a la vez, que quearán almacenadas en lo que se llama stack que no es otra cosa que un objeto que contiene numerosas capas raster que comparten extensión, resolución, sistema de coordenadas… Un ejemplo típico serían las distintas bandas de una imagen de satélite.\nSólo necesitamos una lista que contenga los nombres de los objetos a cargar (rasters). Podemos usar para ello la función list.files():\n\nlista &lt;- list.files('data/meteo/meteo_espacial/rasters_meteo/',full.names = TRUE)\nlista\n\n[1] \"data/meteo/meteo_espacial/rasters_meteo/d_atl.txt\"    \n[2] \"data/meteo/meteo_espacial/rasters_meteo/d_medit.txt\"  \n[3] \"data/meteo/meteo_espacial/rasters_meteo/elevation.txt\"\n[4] \"data/meteo/meteo_espacial/rasters_meteo/lat.txt\"      \n[5] \"data/meteo/meteo_espacial/rasters_meteo/long.txt\"     \n\n\nlist.files devuelve un vector con los nombres de todos los ficheros dentro de una determinda carpeta. Esta función tiene algunos argumentos interesantes:\n\nfull.names: TRUE o FALSE determina si queremos que devuelva sólo el nombre del archivo o mejor la ruta completa a cada uno de ellos.\npattern: parámetro que permite filtrar los objetos por nombre. Por ejemplo, si queremos sólo los ficheros en formato txt:\n\n\nlista &lt;- list.files('data/meteo/meteo_espacial/rasters_meteo/',full.names = TRUE, pattern = 'txt')\nlista\n\n[1] \"data/meteo/meteo_espacial/rasters_meteo/d_atl.txt\"    \n[2] \"data/meteo/meteo_espacial/rasters_meteo/d_medit.txt\"  \n[3] \"data/meteo/meteo_espacial/rasters_meteo/elevation.txt\"\n[4] \"data/meteo/meteo_espacial/rasters_meteo/lat.txt\"      \n[5] \"data/meteo/meteo_espacial/rasters_meteo/long.txt\"     \n\n\nUna vez que tenemos una lista de los rasters a cambiar, podemos cargar la lista con la función rast():\n\nrasters &lt;- rast(lista)\n\nY si ploteammos veremos que hay varios raster (capas) cargadas:\n\nplot(rasters)\n\n\n\n\nPodemos acceder a cada una de las “bandas” del stack con el comando $:\n\nplot(rasters$elevation)"
  },
  {
    "objectID": "03_DatosEspaciales.html#proyección-y-sistema-de-referencia",
    "href": "03_DatosEspaciales.html#proyección-y-sistema-de-referencia",
    "title": "6  Trabajando con datos espaciales en R",
    "section": "6.4 Proyección y sistema de referencia",
    "text": "6.4 Proyección y sistema de referencia\nEl sistema de referencia (CRS) es un elemento clave de la información espacial. Hasta ahora hemos trabajado la información espacial sin prestar atención a este parámetro. Sin embargo, tarde o temprano tendremos que ocuparnos de él. No tenerlo en cuenta nos dará problemas. Por ejemplo, no podremos superponer o combinar capas por la ausencia o diferencia de sistemas de referencia, por lo que tenemos que saber cómo ensamblar o reproyectar una capa a un sistema de referencia diferente.\n\n6.4.1 Asignar un sistema de referencia de coordenadas (CRS)\nUn CRS sólo deber asignarse a una capa cuando esta carezca de esta información de manera explícita. Lo primero es comprobar por tanto qué CRS tienen las capas con las que estamos trabajando:\n\ncrs(rasters)\n\n[1] \"\"\n\ncrs(estaciones)\n\n[1] \"PROJCRS[\\\"ETRS89 / UTM zone 30N\\\",\\n    BASEGEOGCRS[\\\"ETRS89\\\",\\n        ENSEMBLE[\\\"European Terrestrial Reference System 1989 ensemble\\\",\\n            MEMBER[\\\"European Terrestrial Reference Frame 1989\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 1990\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 1991\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 1992\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 1993\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 1994\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 1996\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 1997\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 2000\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 2005\\\"],\\n            MEMBER[\\\"European Terrestrial Reference Frame 2014\\\"],\\n            ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,\\n                LENGTHUNIT[\\\"metre\\\",1]],\\n            ENSEMBLEACCURACY[0.1]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4258]],\\n    CONVERSION[\\\"UTM zone 30N\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",-3,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",500000,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"(E)\\\",east,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        AXIS[\\\"(N)\\\",north,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n    USAGE[\\n        SCOPE[\\\"Engineering survey, topographic mapping.\\\"],\\n        AREA[\\\"Europe between 6°W and 0°W: Faroe Islands offshore; Ireland - offshore; Jan Mayen - offshore; Norway including Svalbard - offshore; Spain - onshore and offshore.\\\"],\\n        BBOX[35.26,-6,80.49,0.01]],\\n    ID[\\\"EPSG\\\",25830]]\"\n\n\nEn este caso, los rasters que hemos cargado no tienen asignado ningún CRS, así que debemos asignarle uno. Para ello podemos comprobar la lista de los diferentes CRS - y manera de codificarlo - en esta web. EN este caso sabemos que el CRS correcto es EPSG: 23030 - UTM ED50 30N, que en el codificado “proj4” es:\n+proj=utm +zone=30 +ellps=intl +units=m +no_defs\nY lo asignamos como:\n\ncrs(rasters)&lt;- \"+proj=utm +zone=30 +ellps=intl +units=m +no_defs\"\n\nAhora podemos comprobar CRS otra vez:\n\ncrs(rasters)\n\n[1] \"PROJCRS[\\\"unknown\\\",\\n    BASEGEOGCRS[\\\"unknown\\\",\\n        DATUM[\\\"Unknown based on International 1924 (Hayford 1909, 1910) ellipsoid\\\",\\n            ELLIPSOID[\\\"International 1924 (Hayford 1909, 1910)\\\",6378388,297,\\n                LENGTHUNIT[\\\"metre\\\",1,\\n                    ID[\\\"EPSG\\\",9001]]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8901]]],\\n    CONVERSION[\\\"UTM zone 30N\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",-3,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",500000,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]],\\n        ID[\\\"EPSG\\\",16030]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"(E)\\\",east,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1,\\n                ID[\\\"EPSG\\\",9001]]],\\n        AXIS[\\\"(N)\\\",north,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1,\\n                ID[\\\"EPSG\\\",9001]]]]\"\n\n\n\n\n6.4.2 Proyectar a otro CRS\nEs común que, cuando descargamos cartografía de diversas fuentes, cada una tenga su propio CRS. Esto nos trae problemas en cuanto a la visualización, pero también si queremos hacer operaciones espaciales (intersects, buffers…). Para solventarlo, debemos proyectar alguna de las capas, de manera que estén todas en la misma CRS.\nNOTA: es importante tener en cuenta que proyectar una capa a un nuevo CRS no es lo mismo que asignar un CRS. En el primer caso, la capa ya tiene CRS asignado, y lo que hacemos es transformar espacialmente las coordenadas. En el segundo (asignar) las coordenadas están, pero no está definido que CRS usar para representar.\n\nnuevo_provincias &lt;- st_transform(provincias, \"+proj=utm +zone=31 +ellps=intl +units=m +no_defs\")\n\nplot(st_geometry(nuevo_provincias))\nplot(estaciones[\"Tmed_MES\"], pch = 19, col = \"red\", cex = 0.5, add = TRUE) \n\n\n\n\nSin embargo, el mismo mapa con tmaps sí que funcionará:\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(nuevo_provincias)+\n    tm_borders()+\n    tm_shape(estaciones)+\n    tm_dots()\n\n\n\n\nEsto es porque tmaps implementa, igual que ArcMap la llamada proyección on-the-fly, es decir que transforma automáticamente los CRS de las capas al CRS definido al principio (fijaos que las provincias salen ahora giradas respecto a la visualización original)."
  },
  {
    "objectID": "03_DatosEspaciales.html#visualización-de-mapas-combinados-de-rasters-y-shapefiles",
    "href": "03_DatosEspaciales.html#visualización-de-mapas-combinados-de-rasters-y-shapefiles",
    "title": "6  Trabajando con datos espaciales en R",
    "section": "6.5 Visualización de mapas combinados de rasters y shapefiles",
    "text": "6.5 Visualización de mapas combinados de rasters y shapefiles\nAl tener asignado correctamente el CRS; ahora podemos plotear las diferentes capas a la vez usando las funciones de tmap:\n\n# tmap_mode(\"plot\")\n\ntm_shape(rasters$elevation) +\n    tm_raster() +\ntm_shape(provincias) +\n    tm_borders() +\ntm_shape(estaciones) + \n    tm_dots( col=\"Tmed_MES\", size = 0.5, palette= \"viridis\") +\n    tm_layout(legend.outside = T)"
  },
  {
    "objectID": "03_DatosEspaciales.html#para-saber-más-1",
    "href": "03_DatosEspaciales.html#para-saber-más-1",
    "title": "6  Trabajando con datos espaciales en R",
    "section": "6.6 Para saber más",
    "text": "6.6 Para saber más\nDesde luego, esto sólo es una introducción al uso de \\(R\\) como entorno de procesado y visualización SIG. Hay mucho más, y para profundizar os recomiendo consultar los siguientes recursos:\n\nVisualización con tmap:\n\nElegant and informative maps with tmap\ntmap: get started!\n\n\nweb de R Spatial (https://rspatial.org/#google_vignette) o la web Introduction to GIS with R"
  },
  {
    "objectID": "04_AutocorrelacionEspacial.html#introducción",
    "href": "04_AutocorrelacionEspacial.html#introducción",
    "title": "7  Autocorrelación espacial en ArcGIS y R",
    "section": "7.1 Introducción",
    "text": "7.1 Introducción\nEn este tutorial vamos a ver cómo llevar a cabo un análisis de autocorrelación espacial usando tanto R como ArcGIS Pro y QGis.\nEsto nos permitirá comparar las diferentes herramientas, analizar en qué difieren y en qué se parecen, y tendremos por tanto un mayor abanico de opciones para realizar este tipo de análisis.\nEn teoría hemos visto que la autocorrelación espacial no es más que el grado de correlación de una variable consigo misma a través del espacio. Para poder calcularla necesitamos por tanto: 1) observaciones de una variable, y 2) la ubicación espacial de dichas observaciones. Todo ello nos lo proporciona cualquier fichero de información espacial (shapefiles de ESRI, geopackages, u objetos de R de clase sf, como vimos en el tutorial “Accediendo a datos espaciales en R”).\nPor ello, lo primero que vamos a hacer es cargar el fichero de datos espaciales que vamos a analizar, que no es otro que el shapefile con los valores de estaciones meteorológicas que usamos en la unidad sobre regresión lineal. También necesitamos cargar el paquete sfdep, que contienen funciones específicas para análisis espaciales en R. Por último, cargaremos el shapefile de provincias para mejorar nuestra visualización:\n\n# Cargamos las librerías que necesitamos\nlibrary(sf)\n# library(spdep)\nlibrary(sfdep) \n\n# Cargamos el fichero de datos (en este caso, un shapefile)\n\nestaciones &lt;- st_read('data/meteo/meteo_espacial/estaciones_meteo.shp')\n\nReading layer `estaciones_meteo' from data source \n  `C:\\Users\\Usuari\\OneDrive - udl.cat\\Teaching\\EFCN_Geoestadística\\Labs_Geoestadistica_Forestal\\data\\meteo\\meteo_espacial\\estaciones_meteo.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 90 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 574966 ymin: 4514365 xmax: 818327 ymax: 4635648\nProjected CRS: ETRS89 / UTM zone 30N\n\nprovincias &lt;- st_read('data/meteo/meteo_espacial/provincias_spain.shp')\n\nReading layer `provincias_spain' from data source \n  `C:\\Users\\Usuari\\OneDrive - udl.cat\\Teaching\\EFCN_Geoestadística\\Labs_Geoestadistica_Forestal\\data\\meteo\\meteo_espacial\\provincias_spain.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 51 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -14129.47 ymin: 3892590 xmax: 1126923 ymax: 4859517\nProjected CRS: ETRS89 / UTM zone 30N"
  },
  {
    "objectID": "04_AutocorrelacionEspacial.html#definiendo-vecinos",
    "href": "04_AutocorrelacionEspacial.html#definiendo-vecinos",
    "title": "7  Autocorrelación espacial en ArcGIS y R",
    "section": "7.2 Definiendo vecinos",
    "text": "7.2 Definiendo vecinos\nHemos visto en la parte de teoría que uno de los pasos críticos en un análisis de autocorrelación es decidir qué observaciones consideramos como vecinas de un determinado punto. Hay varias manera de definirlo, pero las más importantes son definir los vecinos con criterios de contigüidad (en el caso de polígonos o raster), seleccionar los \\(k\\) puntos más cercanos, o definir el vecindario en función de la distancia entre los elementos. Métodos más complejos permiten también asignar pesos a los vecinos en función de diversos criterios, entre los que destaca asignarlos de manera inversa a la distancia entre puntos.\n\n7.2.1 Vecinos contiguos\nSi tenemos un fichero de polígonos, podemos definir la vecindad como aquellos polígonos contiguos a cada uno, mediante la función st:contiguity() del paquete sfdep. La opción queen = TRUE determina cómo vecinos de un polígono todos aquellos que coincidan en un sólo punto de sus límites. Si queen = FALSE sólo son vecinos aquellos que compartan al menos dos puntos (vecindad de Rook)\n\nveins_cont &lt;- st_contiguity(provincias, queen = FALSE)\nveins_cont\n\nNeighbour list object:\nNumber of regions: 51 \nNumber of nonzero links: 222 \nPercentage nonzero weights: 8.535179 \nAverage number of links: 4.352941 \n4 regions with no links:\n7 49 50 51\n5 disjoint connected subgraphs\n\n\nAhora podemos plotear este objeto para ver las conexiones entre polígonos:\n\nplot(st_geometry(provincias))\nplot(veins_cont, coords = st_coordinates(st_centroid(provincias)), add = TRUE, col = \"red\")\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\n\n\n\n\nNOTA: este método sólo funciona para archivos espaciales de polígonos. Si tratáramos de aplicarlos con puntos obtendríamos un error, ya que los puntos no pueden tener puntos de contacto entre ellos.\n\n\nNOTA (2): aunque la opción “queen” permite definir el criterio de selección de vecinos, en el caso de polígonos complejos como el del fichero provincias lo más normal es que no haya diferencias entre queen = TRUE o queen = FALSE\n\n\n\n7.2.2 \\(k\\) vecinos más próximos\nUn método alternativo consiste en elegir como vecinos los \\(k\\) puntos más cercanos, lo que se adapta a toda la zona de estudio, teniendo en cuenta las diferencias en las densidades de las entidades de área. En este caso tan sólo debemos definir el valor de \\(k\\), y la función buscará automáticamente los k puntos más próximos de cada punto. Usaremos para ello la función st_knn():\n\nveins_k &lt;- st_knn(estaciones, k = 8)\nveins_k\n\nNeighbour list object:\nNumber of regions: 90 \nNumber of nonzero links: 720 \nPercentage nonzero weights: 8.888889 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nAhora podemos plotearlo como antes:\n\nplot(veins_k, coords = st_coordinates(estaciones), col = \"red\")\n\n\n\n\n\nEn el caso de esta metodología, puede utilizarse también con polígonos. Sin embargo requiere que trabajemos con los centroides de cada polígono, que serán los que nos permitan determinar la distancia entre polígonos:\n\n\nveins_prov_k &lt;- st_knn(st_centroid(provincias), k = 4)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\nplot(st_geometry(provincias))\nplot(veins_prov_k, coords = st_coordinates(st_centroid(provincias)),\n     col = \"red\", add = TRUE)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\n\n\n\n\n\n7.2.3 Vecinos basados en intervalos de distancia\nPara definir los vecinos en base a una distancia podemos usar la función st_dist_band() en la que debemos definir la distancia mínima (lower) y máxima (upper) para seleccionar un vecino. La función determinará que todos los puntos que estén entre estas dos distancias serán vecinos:\n\nveins_dist &lt;- st_dist_band(estaciones, lower = 0, upper = 30000)\nplot(veins_dist, coords = st_coordinates(estaciones), col = \"red\")\n\n\n\n\n\nIgual que antes, si queremos usar este método con polígonos, debemos hacerlo con los centroides de los polígonos."
  },
  {
    "objectID": "04_AutocorrelacionEspacial.html#asignando-pesos-a-los-vecinos",
    "href": "04_AutocorrelacionEspacial.html#asignando-pesos-a-los-vecinos",
    "title": "7  Autocorrelación espacial en ArcGIS y R",
    "section": "7.3 Asignando pesos a los vecinos",
    "text": "7.3 Asignando pesos a los vecinos\nOtra opción muy interesante, y que suele aplicarse en muchos casos, es no sólo definir cuáles consideraremos como vecinos de cada observación, sino darles un peso determinado según la distancia a la que estén del punto analizado. Este método se conoce como weighting.\nAunque existen varias opciones para dar pesos, veremos las dos más comunes: asignar el mismo peso a todos los vecinos de un punto (función st_weights()) o asignar mayor peso a los vecinos que estén más cerca, lo que se conoce como inverse distance weighting (idw) (función st_inverse_distance()).\n\nPara evitar que la función calcule las distancias entre todos los puntos dos a dos - lo que podría colapsar la memoria del ordenador - las dos funciones se aplican sobre un objeto de vecinos ya creado, en el que le digamos cuáles son los vecinos de cada punto. En este caso, usaremos el que acabamos de crear (veins_dist):\n\n\nveins_w_dist &lt;- st_weights(veins_dist)\nveins_w_dist\n\n[[1]]\n[1] 0.5 0.5\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[4]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[5]]\n[1] 0.25 0.25 0.25 0.25\n\n[[6]]\n[1] 0.3333333 0.3333333 0.3333333\n\n[[7]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[8]]\n[1] 0.25 0.25 0.25 0.25\n\n[[9]]\n[1] 0.25 0.25 0.25 0.25\n\n[[10]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[11]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[12]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[13]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[14]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[15]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[16]]\n [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n[[17]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[18]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[19]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[20]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[21]]\n [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n[[22]]\n [1] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n [7] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n\n[[23]]\n [1] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n [7] 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333 0.08333333\n\n[[24]]\n [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n[[25]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[26]]\n [1] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n [7] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n\n[[27]]\n [1] 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n [7] 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308 0.07692308\n[13] 0.07692308\n\n[[28]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[29]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[30]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[31]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[32]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[33]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[34]]\n [1] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n [7] 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n\n[[35]]\n [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n[[36]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[37]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[38]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[39]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[40]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[41]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[42]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[43]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[44]]\n[1] 0.25 0.25 0.25 0.25\n\n[[45]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[46]]\n [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n[[47]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[48]]\n[1] 0.25 0.25 0.25 0.25\n\n[[49]]\n[1] 0.25 0.25 0.25 0.25\n\n[[50]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[51]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[52]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[53]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[54]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[55]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[56]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[57]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[58]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[59]]\n [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n[[60]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[61]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[62]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[63]]\n[1] 1\n\n[[64]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[65]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[66]]\n [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n[[67]]\n[1] 0.25 0.25 0.25 0.25\n\n[[68]]\n[1] 0.25 0.25 0.25 0.25\n\n[[69]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[70]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[71]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[72]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[73]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[74]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[75]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[76]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[77]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[78]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n[[79]]\n[1] 0.25 0.25 0.25 0.25\n\n[[80]]\n[1] 0.3333333 0.3333333 0.3333333\n\n[[81]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\n[[82]]\n[1] 0.3333333 0.3333333 0.3333333\n\n[[83]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[84]]\n[1] 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111 0.1111111\n[8] 0.1111111 0.1111111\n\n[[85]]\n[1] 0.25 0.25 0.25 0.25\n\n[[86]]\n[1] 0.3333333 0.3333333 0.3333333\n\n[[87]]\n[1] 0.3333333 0.3333333 0.3333333\n\n[[88]]\n[1] 0.25 0.25 0.25 0.25\n\n[[89]]\n[1] 0.3333333 0.3333333 0.3333333\n\n[[90]]\n[1] 0.5 0.5\n\nattr(,\"mode\")\n[1] \"binary\"\nattr(,\"W\")\n[1] TRUE\nattr(,\"comp\")\nattr(,\"comp\")$d\n [1]  2  1  5  6  4  3  7  4  4  7  7  8  8  6  8 10  6  9  7  9 10 12 12 10  7\n[26] 11 13  5  9  9  5  5  9 11 10  7  6  7  7  9  5  7  9  4  5 10  7  4  4  8\n[51]  8  9  9  9  9  7  9  8 10  7  7  6  1  7  6 10  4  4  8  8  6  7  6  7  8\n[76]  6  5  8  4  3  7  3  6  9  4  3  3  4  3  2\n\nveins_idw &lt;- st_inverse_distance(veins_dist, estaciones)\nveins_idw\n\n[[1]]\n[1] 0.006162935 0.004629866\n\n[[2]]\n[1] 0.004474438\n\n[[3]]\n[1] 0.003614838 0.008617471 0.005888738 0.004308553 0.004246341\n\n[[4]]\n[1] 0.004110196 0.005004989 0.005892665 0.005059494 0.003855733 0.003525225\n\n[[5]]\n[1] 0.006162935 0.004110196 0.018573094 0.004219539\n\n[[6]]\n[1] 0.003614838 0.003762743 0.003742014\n\n[[7]]\n[1] 0.010436978 0.003739723 0.007476455 0.005599893 0.003835977 0.004550622\n[7] 0.004013768\n\n[[8]]\n[1] 0.004629866 0.005004989 0.018573094 0.005150181\n\n[[9]]\n[1] 0.004474438 0.003358967 0.003759661 0.004728103\n\n[[10]]\n[1] 0.008617471 0.003762743 0.012830421 0.006860108 0.008371453 0.004122217\n[7] 0.003432164\n\n[[11]]\n[1] 0.005892665 0.035738305 0.006207863 0.003753747 0.007777664 0.003519870\n[7] 0.003568408\n\n[[12]]\n[1] 0.010436978 0.003358967 0.011589005 0.012081789 0.005989138 0.005008006\n[7] 0.006173371 0.003603735\n\n[[13]]\n[1] 0.005059494 0.035738305 0.007278701 0.003583814 0.009221188 0.003575821\n[7] 0.003899278 0.003683868\n\n[[14]]\n[1] 0.005888738 0.012830421 0.014673056 0.009628569 0.004394696 0.004420994\n\n[[15]]\n[1] 0.003739723 0.006207863 0.007278701 0.003904562 0.006026709 0.005189466\n[7] 0.005225900 0.005394335\n\n[[16]]\n [1] 0.007476455 0.011589005 0.003904562 0.008790135 0.004959863 0.008764587\n [7] 0.007545888 0.004368521 0.003813779 0.004515097\n\n[[17]]\n[1] 0.004308553 0.006860108 0.014673056 0.007949523 0.004408820 0.005841640\n\n[[18]]\n[1] 0.005599893 0.003759661 0.012081789 0.008790135 0.011061750 0.004623875\n[7] 0.010092823 0.004479795 0.003718229\n\n[[19]]\n[1] 0.004246341 0.008371453 0.009628569 0.007949523 0.003721542 0.007871388\n[7] 0.005058706\n\n[[20]]\n[1] 0.003835977 0.004728103 0.005989138 0.004959863 0.011061750 0.003403491\n[7] 0.007795531 0.004218550 0.004983057\n\n[[21]]\n [1] 0.003855733 0.004219539 0.005150181 0.003753747 0.003583814 0.003795294\n [7] 0.003713069 0.004750135 0.003414890 0.004118014\n\n[[22]]\n [1] 0.003525225 0.007777664 0.009221188 0.006026709 0.003795294 0.003402316\n [7] 0.004575316 0.005373133 0.005561090 0.004853792 0.004557856 0.003879382\n\n[[23]]\n [1] 0.004550622 0.005008006 0.005189466 0.008764587 0.004623875 0.003403491\n [7] 0.003402316 0.005418191 0.008705479 0.006739940 0.004848548 0.003681319\n\n[[24]]\n [1] 0.004013768 0.006173371 0.007545888 0.010092823 0.007795531 0.005418191\n [7] 0.003636457 0.008045509 0.004538472 0.003611401\n\n[[25]]\n[1] 0.003742014 0.003721542 0.005031876 0.004780327 0.003337743 0.004294985\n[7] 0.003475826\n\n[[26]]\n [1] 0.003575821 0.005225900 0.004368521 0.004575316 0.008705479 0.003636457\n [7] 0.026493047 0.004075294 0.003516125 0.003962043 0.004654760\n\n[[27]]\n [1] 0.003519870 0.003899278 0.005394335 0.003813779 0.005373133 0.006739940\n [7] 0.026493047 0.003516832 0.003571777 0.004019564 0.004558003 0.003638788\n[13] 0.004400688\n\n[[28]]\n[1] 0.023162289 0.003507235 0.004820755 0.003749024 0.004364900\n\n[[29]]\n[1] 0.004122217 0.004394696 0.004408820 0.007871388 0.005031876 0.005210361\n[7] 0.004499440 0.004485682 0.003400160\n\n[[30]]\n[1] 0.003432164 0.004420994 0.005841640 0.005058706 0.005210361 0.003436339\n[7] 0.005719380 0.003931030 0.003448073\n\n[[31]]\n[1] 0.003713069 0.007232551 0.006956508 0.005500667 0.004358544\n\n[[32]]\n[1] 0.023162289 0.003505615 0.005370645 0.004124959 0.005333420\n\n[[33]]\n[1] 0.003568408 0.003683868 0.004750135 0.005561090 0.003516832 0.012147185\n[7] 0.003587408 0.007556955 0.007787294\n\n[[34]]\n [1] 0.003603735 0.004515097 0.004479795 0.004218550 0.004848548 0.008045509\n [7] 0.004075294 0.003571777 0.004457251 0.005070455 0.004870103\n\n[[35]]\n [1] 0.003718229 0.004983057 0.004538472 0.003507235 0.003505615 0.004457251\n [7] 0.006659033 0.006156431 0.006765926 0.003536958\n\n[[36]]\n[1] 0.003414890 0.004853792 0.003516125 0.004019564 0.012147185 0.019100230\n[7] 0.018443203\n\n[[37]]\n[1] 0.004118014 0.007232551 0.003587408 0.004689643 0.011410470 0.004002355\n\n[[38]]\n[1] 0.004557856 0.003962043 0.004558003 0.007556955 0.019100230 0.018040963\n[7] 0.003398533\n\n[[39]]\n[1] 0.003436339 0.006956508 0.004689643 0.005252977 0.009941154 0.004210954\n[7] 0.005292588\n\n[[40]]\n[1] 0.004820755 0.005370645 0.006659033 0.016418318 0.004811032 0.006453718\n[7] 0.004859959 0.004620294 0.003536070\n\n[[41]]\n[1] 0.003879382 0.003638788 0.007787294 0.018443203 0.018040963\n\n[[42]]\n[1] 0.004780327 0.004499440 0.003967366 0.003735427 0.010401674 0.012143919\n[7] 0.003705614\n\n[[43]]\n[1] 0.004485682 0.005719380 0.003967366 0.003765583 0.006117359 0.004333852\n[7] 0.004748846 0.004193798 0.003862178\n\n[[44]]\n[1] 0.005500667 0.011410470 0.005252977 0.005241227\n\n[[45]]\n[1] 0.003681319 0.004654760 0.004400688 0.005070455 0.003398533\n\n[[46]]\n [1] 0.003749024 0.004124959 0.006156431 0.016418318 0.005868575 0.006075711\n [7] 0.006788932 0.005458624 0.004345378 0.003370678\n\n[[47]]\n[1] 0.003611401 0.004870103 0.006765926 0.004811032 0.005868575 0.004925559\n[7] 0.003394432\n\n[[48]]\n[1] 0.003337743 0.003735427 0.005663043 0.003707812\n\n[[49]]\n[1] 0.004294985 0.010401674 0.005663043 0.010005842\n\n[[50]]\n[1] 0.004364900 0.005333420 0.006453718 0.006075711 0.004509175 0.007420818\n[7] 0.004023550 0.004513244\n\n[[51]]\n[1] 0.004358544 0.004002355 0.009941154 0.005241227 0.005155981 0.007888297\n[7] 0.003451690 0.003391276\n\n[[52]]\n[1] 0.003475826 0.003400160 0.012143919 0.003765583 0.003707812 0.010005842\n[7] 0.004611517 0.003773790 0.003696297\n\n[[53]]\n[1] 0.003931030 0.004210954 0.006117359 0.005155981 0.013964334 0.004101068\n[7] 0.007014490 0.005723988 0.005219137\n\n[[54]]\n[1] 0.003448073 0.005292588 0.004333852 0.007888297 0.013964334 0.005808662\n[7] 0.004894253 0.004986876 0.003720591\n\n[[55]]\n[1] 0.003536958 0.004859959 0.006788932 0.004925559 0.004509175 0.007608761\n[7] 0.010541089 0.004673287 0.004478467\n\n[[56]]\n[1] 0.004620294 0.005458624 0.007420818 0.007608761 0.008415016 0.008783083\n[7] 0.003614692\n\n[[57]]\n[1] 0.003705614 0.004748846 0.004611517 0.004101068 0.005811761 0.006178186\n[7] 0.004559716 0.004588461 0.004121207\n\n[[58]]\n[1] 0.004193798 0.003451690 0.007014490 0.005808662 0.005811761 0.030537597\n[7] 0.015206835 0.004123002\n\n[[59]]\n [1] 0.003536070 0.004345378 0.003394432 0.004023550 0.010541089 0.008415016\n [7] 0.006892460 0.004938095 0.004549184 0.004713823\n\n[[60]]\n[1] 0.003862178 0.005723988 0.004894253 0.006178186 0.030537597 0.017182885\n[7] 0.004091558\n\n[[61]]\n[1] 0.003370678 0.004513244 0.004673287 0.008783083 0.006892460 0.005466388\n[7] 0.004309843\n\n[[62]]\n[1] 0.005219137 0.004986876 0.004559716 0.015206835 0.017182885 0.005361710\n\n[[63]]\n[1] 0.004029734\n\n[[64]]\n[1] 0.003500060 0.003645244 0.005738888 0.003351490 0.005768619 0.003500076\n[7] 0.003407870\n\n[[65]]\n[1] 0.004478467 0.004938095 0.004029734 0.003357246 0.004378309 0.003531956\n\n[[66]]\n [1] 0.003391276 0.003720591 0.004123002 0.004091558 0.005361710 0.005095665\n [7] 0.004811194 0.007141728 0.004621374 0.003354525\n\n[[67]]\n[1] 0.003773790 0.004588461 0.035889025 0.003398814\n\n[[68]]\n[1] 0.003696297 0.004121207 0.035889025 0.003489890\n\n[[69]]\n[1] 0.003500060 0.005095665 0.079968735 0.010158248 0.027584200 0.008114575\n[7] 0.007090058 0.003383981\n\n[[70]]\n[1] 0.003645244 0.004811194 0.079968735 0.009066521 0.027098256 0.008602432\n[7] 0.007182009 0.003501714\n\n[[71]]\n[1] 0.005738888 0.011110630 0.005299489 0.005785850 0.004056352 0.003574184\n\n[[72]]\n[1] 0.003614692 0.004549184 0.005466388 0.003357246 0.011662586 0.007968841\n[7] 0.004110888\n\n[[73]]\n[1] 0.007141728 0.010158248 0.009066521 0.010301497 0.005602327 0.006286845\n\n[[74]]\n[1] 0.004713823 0.004309843 0.004378309 0.011662586 0.010048597 0.003970192\n[7] 0.003596182\n\n[[75]]\n[1] 0.003351490 0.004621374 0.027584200 0.027098256 0.010301497 0.010704627\n[7] 0.009532459 0.003679035\n\n[[76]]\n[1] 0.005768619 0.011110630 0.004069532 0.003852847 0.005600518 0.006262039\n\n[[77]]\n[1] 0.005299489 0.004069532 0.007636479 0.007900458 0.009344532\n\n[[78]]\n[1] 0.003500076 0.008114575 0.008602432 0.005602327 0.010704627 0.003852847\n[7] 0.016374081 0.005518690\n\n[[79]]\n[1] 0.007968841 0.010048597 0.004385258 0.005127903\n\n[[80]]\n[1] 0.010997655 0.003568856 0.004974987\n\n[[81]]\n[1] 0.003354525 0.007090058 0.007182009 0.006286845 0.009532459 0.016374081\n[7] 0.004673300\n\n[[82]]\n[1] 0.007636479 0.004542729 0.011909997\n\n[[83]]\n[1] 0.005785850 0.005600518 0.007900458 0.004542729 0.004200314 0.006786618\n\n[[84]]\n[1] 0.003407870 0.003383981 0.003501714 0.004056352 0.003679035 0.006262039\n[7] 0.005518690 0.004673300 0.004200314\n\n[[85]]\n[1] 0.003574184 0.009344532 0.011909997 0.006786618\n\n[[86]]\n[1] 0.003531956 0.003970192 0.004385258\n\n[[87]]\n[1] 0.010997655 0.004585941 0.004477688\n\n[[88]]\n[1] 0.003398814 0.003489890 0.003568856 0.004585941\n\n[[89]]\n[1] 0.004110888 0.003596182 0.005127903\n\n[[90]]\n[1] 0.004974987 0.004477688\n\n\nAl imprimir el resultado vemos que, mientras en veins_dist_w() todos los vecinos de una observación tienen el mismo peso, en veins_idw los pesos varían entre los vecinos."
  },
  {
    "objectID": "04_AutocorrelacionEspacial.html#autocorrelació-global-i-de-moran",
    "href": "04_AutocorrelacionEspacial.html#autocorrelació-global-i-de-moran",
    "title": "7  Autocorrelación espacial en ArcGIS y R",
    "section": "7.4 Autocorrelació Global: I de Moran",
    "text": "7.4 Autocorrelació Global: I de Moran\nLa I global de Moran determina el grado de autocorrelación de una muestra en su conjunto. Valores positivos indican autocorrelación positiva (los valores más próximos entre sí muestran valores más similares), valores negativos muestran lo contrario, y valores cercanos a 0, ausencia de autocorrelación espacial.\n\n7.4.1 I global de Moran con R\nEn R podemos determinar la I de Moran con la función global_moran_test() que necesita como argumentos: (1) la variable que queremos analizar (en este caso será la temperatura media del mes, Tmed_MES); (2) un objeto neighbor que identifique los vecinos de cada observación; y (3) un objeto de pesos. Por lo tanto los pasos a seguir son:\n\nIdentificar los vecinos de cada observación\nAsignar los pesos mediante la opción st_weights() o st_inverse_distance()\nCalcular la I de Moran\n\nAunque ya tenemos los objetos resultantes de los pasos 1 y 2, vamos a repasar todo el proceso para tener todos los pasos juntos:\n\n7.4.1.1 I global de Moran en base a los k vecinos más próximos\nComo hemos visto antes, en el caso de usar los k vecinos más próximos, usaremos las funciones st_knn() y st_weights():\n\n# 1. Identificar los vecinos de cada observación en un objeto neighbour (nb)\nveins_k &lt;- st_knn(estaciones, k = 8)\n\n# 2. Asignar los pesos de cada observación (en este caso, pesos iguales)\nveins_w_k &lt;- st_weights(veins_k)\n\n# 3. Calcular la I de Moran para la variable Tmed_MES\nglobalMoran_k &lt;- global_moran_test(x = estaciones$Tmed_MES, nb = veins_k, wt = veins_w_k)\nglobalMoran_k\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 12.934, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.607761749      -0.011235955       0.002290385 \n\n\nVemos que el valor de la I de Moran es 0.6077, lo que indica autocorrelación espacial positiva. El valor esperado si los datos se distribuyeran aleatoriamente sería de -0.011. Por último, también sabemos que la probabilidad de que los valores de temperatura observados estén distribuidos al azar es de 2.2e-16, con lo que claramente rechazaremos la hipótesis nula (es decir, rechazamos que no haya autocorrelación). En definitiva, que sí que hay autocorrelación espacial.\n\n\n7.4.1.2 I global de Moran en base a la distancia entre vecinos\nEn este caso reconoceremos como vecinos aquellos dentro de un intervalo de distancias, y asignaremos el mismo peso a todos:\n\n# 1. Identificar los vecinos de cada observación en un objeto neighbour (nb)\nveins_dist &lt;- st_dist_band(estaciones, lower = 0, upper = 30000)\n\n# 2. Asignar los pesos de cada observación (en este caso, pesos iguales)\nveins_w_dist &lt;- st_weights(veins_dist)\n\n# 3. Calcular la I de Moran\nglobalMoran_dist &lt;- global_moran_test(x = estaciones$Tmed_MES, nb = veins_dist, wt = veins_w_dist)\nglobalMoran_dist\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 11.134, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.664310960      -0.011235955       0.003681663 \n\n\nVemos que el valor cambia respecto al calculado antes (0.664),ya que la definición de cuáles son los vecinos ha cambiado mucho. Sin embargo, la conclusión sigue siendo la misma (hay bastante autocorrelación)\n\n\n7.4.1.3 I Global de Moran en base a IDW\nAhora identificaremos los vecinos en base a la franja de distancias, pero les asignaremos un peso inversamente proporcional a la distancia con el punto analizado:\n\n# 1. Identificar los vecinos de cada observación en un objeto neighbour (nb)\nveins_dist &lt;- st_dist_band(estaciones, lower = 0, upper = 30000)\n\n# 2. Asignar los pesos de cada observación (en este caso, pesos iguales)\nveins_idw &lt;- st_inverse_distance(veins_dist, estaciones)\n\n# 3. Calcular la I de Moran\nglobalMoran_idw &lt;- global_moran_test(x = estaciones$Tmed_MES, nb = veins_dist, wt = veins_idw)\nglobalMoran_idw\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 8.7647, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.663803406      -0.011235955       0.005931776 \n\n\nAunque el resultado es parecido al de globalMoran_dist, hay pequeñas diferencias debidas a los pesos asignados. En función del dataset concreto las diferencias pueden ser más o menos grandes.\n\n\n\n7.4.2 I Global de Mo#ran con ArcGis Pro\nDeterminar la I global de Moran con ArcGIS es también muy sencillo. En primer lugar, debemos cargar la capa estaciones_meteo.shp, y tenemos que buscar la función Spatial Autocorrelation (Global Moran’s I), que podemos encontrar dentro de las herramientas de Geoprocessing\n\nUna vez seleccionada la función, tenemos que indicar la capa que queremos analizar, la variable de interés, y cómo determinaremos el peso de los vecinos.\n\nLos resultados se muestran en la pestaña Results de ArcGIS, que si no tenemos visible, podemos activar yendo a Geoprocessing/Results. Si además hemos seleccionado que queremos que genere un informe, este estará disponible como html, produciendo una salida visualmente muy informativa.\n &gt; ** Ejercicio** Prueba a modificar la manera de definir los pesos de cada observación, verás que los resultados de ArcGIS son los mismos que obtenemos en R.\n\n\n7.4.3 I Global de Moran con QGis y Geoda\n\n7.4.3.1 Presentando GeoDa\nPor supuesto, QGis tiene funcionalidades parecidas a las de ArcGis, mediante un plugin llamado Spatial Analysis Toolbox. Sin embargo, a día de hoy (julio de 2024), este plugin no funciona, así que veremos una alternativa muy interesante, el software GeoDa.\nGeoDa es un software de escritorio gratuito y de código abierto, desarrollado por el equipo del Dr. Luc Anselin, profesor de la Universidad de Chicago y uno de los grandes pioneros en el análisis espacial y la econometría. Podemos descargar gratuitamente GeoDa aquí.\nUna vez descargado, si lo abrimos nos pedirá que carguemos los datos: podemos cargar capas y objetos espaciales en multitud de formatos. En este caso, vamos a cargar el fichero estaciones_meteo.shp.\n\nUna vez cargados los datos, el aspecto es el de un SIG convencional, con la tabla de contenidos a la izquierda, la visualización a la derecha, y arriba veremos el menú con diversas opciones.\n\n\n\n7.4.3.2 Calculando vecinos y pesos en GeoDa\nPara poder calcular la I de Moran, GeoDa nos exige que calculemos los pesos. Para ello debemos acceder al menú Weights Manager caracterizado por una gran W morada. El menú del Weights manager nos resultará familiar, ya que nos da la opción de definir los vecinos por contiguidad (según el criterio de Rooke o de Queen) o por distancia (y en este caso podremos elegir por banda de distancia, k vecinos más próximos o mediante un kernel, que no lo hemos visto). En caso de elegir los vecinos por distancia, nos preguntará si queremos usar el inverso de la distancia como peso (es decir, un idw):\n Una vez decidido el criterio que queramos, guardamos el fichero de pesos en disco, con el nombre que queramos y la extensión .gwd. Una de las funcionalidades más interesantes de GeoDa es que nos permite visualizar, una vez seleccionado el fichero de pesos que queramos, los vecinos de un punto sobre el que pongamos el cursos, además de permitirnos ver gráficos de vecindad interactivos:\n\nPodemos probar a crear un fichero con knn (8 vecinos), otro con los vecinos entre 0 y 30.000 metros, y otro con los mismos vecinos pero pesos inversos a la distancia, como hicimos en R.\n\n\n7.4.3.3 Calculando la I de Moran con GeoDa\nUna vez definidos los vecinos, podemos calcular fácilmente la I global de Moran, seleccionando el comando Univariate Moran's I del menú Space. Para ello sólo debemos indicar la variable de interés (Tmed_MES) y el fichero de vecinos deseado:"
  },
  {
    "objectID": "04_AutocorrelacionEspacial.html#autocorrelación-local-i-de-anselin",
    "href": "04_AutocorrelacionEspacial.html#autocorrelación-local-i-de-anselin",
    "title": "7  Autocorrelación espacial en ArcGIS y R",
    "section": "7.5 Autocorrelación Local (I de Anselin)",
    "text": "7.5 Autocorrelación Local (I de Anselin)\nPara poder calcular la I local de Moran (también llamada I de Anselin), necesitaremos, igual que antes, conocer la variable a utilizar, la identificación de los vecinos, y los pesos. Vamos a trabajar, por simplicidad, con uno de los casos (idw), pero funcionaría igual con el resto:\n\nlocalMoran &lt;- local_moran(x = estaciones$Tmed_MES, nb = veins_dist, wt = veins_idw)\n\nVemos que en este caso el objeto generado contiene el valor calculado de I (ii), el valor esperado (eii), la varianza (var_ii), el z-score (z_ii) y el p-valor (p_ii) de cada observación de la muestra, entre otros campos\n\nhead(localMoran)\n\n          ii           eii       var_ii     z_ii         p_ii p_ii_sim\n1 0.02504040 -1.240126e-03 2.145584e-04 1.794161 0.0727875371    0.096\n2 0.01013481  4.419634e-05 3.629683e-05 1.674879 0.0939579963    0.100\n3 0.07910570 -1.612636e-03 5.279889e-04 3.512852 0.0004433249    0.004\n4 0.03636902  5.256534e-04 2.594232e-04 2.225381 0.0260556745    0.032\n5 0.05093252  2.016048e-05 5.892954e-04 2.097281 0.0359686814    0.032\n6 0.03242147  1.667611e-04 1.122603e-04 3.044248 0.0023326282    0.004\n  p_folded_sim    skewness    kurtosis     mean   median     pysal\n1        0.048  0.22413422 -0.45466255  Low-Low  Low-Low   Low-Low\n2        0.054 -0.23127189 -0.91338204 High-Low High-Low High-High\n3        0.002  0.25155287 -0.08314579  Low-Low  Low-Low   Low-Low\n4        0.016  0.10151188 -0.06217115  Low-Low  Low-Low   Low-Low\n5        0.016  0.20330568 -0.73921216  Low-Low  Low-Low   Low-Low\n6        0.002 -0.00244472 -0.61948853  Low-Low  Low-Low   Low-Low\n\n\n\n7.5.1 LISA (Local indicators of spatial association) - Agrupaciones espaciales\nUn análisis muy interesante cuando trabajamos con autocorrelación espacial local es el de identificar aquellas observaciones en las que se cumplen una serie de condiciones. Este análisis fue desarrollado en 1995 por Luc Anselin, y recibe el nombre de LISA (local indicators of spatial association). Se compone de varios elementos:\n\n7.5.1.1 Scatterplot de Anselin\nSi queremos producir un scatterplot con los valores positivamente y negativamente autocorrelacionados, podemos usar la función moran.plot(), del paquete spdep. Por desgracia, aún no existe una versión de esta función para sfdep, por lo que nos vemos obligados a definir los pesos de los vecinos usando la función nb2listw() (en caso de querer aplicar pesos iguales), o la función nb2listwdist() si queremos aplicar un idw.\n\nlibrary(spdep)\n\nCargando paquete requerido: spData\n\n\nTo access larger datasets in this package, install the spDataLarge\npackage with: `install.packages('spDataLarge',\nrepos='https://nowosad.github.io/drat/', type='source')`\n\nmoran.plot(x = estaciones$Tmed_MES, nb2listw(veins_dist))\n\n\n\nmoran.plot(x = estaciones$Tmed_MES, nb2listwdist(veins_dist, estaciones))\n\n\n\n\nVemos que los valores de las esquinas inferior izquierda y superior derecha son los que tienen autocorrelación positiva, y los de las esquinas contrarias, autocorrelación negativa.\n\n\n7.5.1.2 Mapa de valores de I\nTambién podemos usar la función tm_shape() y tm_dots() del paquete tmap para visualizar espacialmente los valores locales de I de Moran. Primero debemos unir los cálculos de I local al objeto espacial que tenemos, usando cbind().\n\nlisa &lt;- cbind(estaciones, localMoran)\n\nDespués podemos crear la representación espacial de la siguiente manera:\n\nlibrary(tmap)\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n\ntm_shape(lisa) +\n    tm_dots(col = \"ii\", size = 0.75) +\ntm_shape(provincias) +\n    tm_borders()\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n7.5.1.3 Mapa de agrupaciones cluster\nConsiste en identificar las observaciones que cumplen estos criterios:\n\nAlto valor de la variable y vecinos con alto valor (High-high)\nBajo valor de la variable y vecinos con bajo valor (Low-Low)\nAlto valor de la variable y vecinos con bajo valor (High-Low)\nBajo valor de la variable y vecinos con alto valor (Low-High)\n\nLos dos primeros se suelen colorear de color rojo y azul intenso, respectivamente, y corresponden a las observaciones que contribuyen significativamente a la autocorrelación espacial global positiva. Los otros dos se suelen representar con colores pálidos, y son las observaciones que contribuyen a una autocorrelación negativa. Las observaciones con valores no significativos no suelen colorearse.\nLa función localMoran ya nos ofrece una clasificación en estos cuatro grupos, a la que podemos acceder de la siguiente manera:\n\nlocalMoran$mean\n\n [1] Low-Low   High-Low  Low-Low   Low-Low   Low-Low   Low-Low   Low-Low  \n [8] Low-Low   High-Low  Low-Low   Low-High  Low-High  Low-High  Low-Low  \n[15] High-Low  High-High Low-Low   Low-High  Low-Low   High-High Low-Low  \n[22] Low-High  High-High High-High Low-Low   High-High High-High High-Low \n[29] Low-Low   Low-Low   Low-Low   High-High High-High High-High High-High\n[36] High-High Low-Low   High-High Low-Low   High-High High-High Low-Low  \n[43] Low-Low   Low-Low   High-Low  High-High High-Low  Low-Low   Low-Low  \n[50] High-High Low-Low   Low-Low   Low-High  Low-High  High-High Low-High \n[57] Low-Low   Low-High  High-High High-High High-Low  High-High High-Low \n[64] High-Low  High-Low  Low-High  Low-Low   Low-Low   High-High High-High\n[71] High-Low  High-Low  High-High High-High High-High High-Low  High-Low \n[78] High-High High-Low  High-Low  High-High High-Low  High-Low  High-Low \n[85] High-Low  High-Low  High-Low  Low-Low   High-Low  High-Low \nLevels: Low-Low High-Low Low-High High-High\n\n\nComo antes hemos unido los resultados de localMoran a nuestra tabla estaciones también tendremos esta información en el objeto moran.map\nSi definimos un nivel de significación, podemos clasificar las observaciones según el grupo al que pertenezcan y su significación. Indiquemos que los valores no significativos tengan un valor de “NS”\n\n# llindar de significacion\nsignif &lt;- 0.1 \n\nlisa$mean &lt;- ifelse(lisa$p_ii &gt; signif,  \"NS\", as.character(lisa$mean))\nlisa\n\nSimple feature collection with 90 features and 25 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 574966 ymin: 4514365 xmax: 818327 ymax: 4635648\nProjected CRS: ETRS89 / UTM zone 30N\nFirst 10 features:\n   OBJECTID FID_weathe INDICATIVO AÃ_O MES                    NOMBRE ALTITUD\n1         1         12      9382E 2012   6         PANCRUDO (D.G.A.)    1285\n2         2         85      9987N 2012   6   DELTEBRE (PARC NATURAL)       4\n3         3         11      9377E 2012   6               EL PEDREGAL     985\n4         4         50      9567U 2012   6           EJULVE (D.G.A.)    1095\n5         5         39      9530V 2012   6         UTRILLAS (D.G.A.)     960\n6         6          0       3013 2012   6          MOLINA DE ARAGON    1063\n7         7         70      9939A 2012   6        FUENTESPALDA (DGA)     720\n8         8         40      9531X 2012   6    MONTALBAN 'AUTOMATICA'     885\n9         9         84      9981A 2012   6 TORTOSA (OBSER. DEL EBRO)      48\n10       10         89       9999 2012   6                      ODON    1110\n   T_MAX_abs T_MIN_abs TMed_MAX TMed_MIN Tmed_MES   Provincia           ii\n1       29.5       3.0     22.0      9.6    15.80      Teruel 0.0250404031\n2       32.0      10.0     27.5     17.4    22.45   Tarragona 0.0101348145\n3       31.0       3.5     21.5     10.2    15.85 Guadalajara 0.0791057035\n4       30.0       5.0     21.9     11.5    16.70      Teruel 0.0363690201\n5       32.5       3.5     23.7     10.8    17.25      Teruel 0.0509325181\n6       32.8       3.2     23.8      8.4    16.10 Guadalajara 0.0324214727\n7       32.0       5.0     24.4     13.2    18.80      Teruel 0.0006529013\n8       31.2       5.4     23.0     11.0    17.00      Teruel 0.0515590522\n9       34.4      13.0     29.3     17.1    23.20   Tarragona 0.0048631840\n10      32.0       4.0     22.4     10.2    16.30      Teruel 0.1221026551\n             eii       var_ii      z_ii         p_ii p_ii_sim p_folded_sim\n1  -1.240126e-03 2.145584e-04 1.7941606 0.0727875371    0.096        0.048\n2   4.419634e-05 3.629683e-05 1.6748789 0.0939579963    0.100        0.054\n3  -1.612636e-03 5.279889e-04 3.5128517 0.0004433249    0.004        0.002\n4   5.256534e-04 2.594232e-04 2.2253810 0.0260556745    0.032        0.016\n5   2.016048e-05 5.892954e-04 2.0972813 0.0359686814    0.032        0.016\n6   1.667611e-04 1.122603e-04 3.0442479 0.0023326282    0.004        0.002\n7  -1.191728e-04 4.568722e-05 0.1142251 0.9090593525    0.916        0.458\n8  -1.541596e-04 7.247982e-04 1.9208478 0.0547508938    0.068        0.034\n9  -9.059528e-04 1.992059e-04 0.4087519 0.6827217648    0.716        0.358\n10 -1.976345e-03 1.113684e-03 3.7180670 0.0002007530    0.004        0.002\n      skewness    kurtosis     mean   median     pysal               geometry\n1   0.22413422 -0.45466255  Low-Low  Low-Low   Low-Low POINT (666121 4514365)\n2  -0.23127189 -0.91338204 High-Low High-Low High-High POINT (814489 4514857)\n3   0.25155287 -0.08314579  Low-Low  Low-Low   Low-Low POINT (620767 4515276)\n4   0.10151188 -0.06217115  Low-Low  Low-Low   Low-Low POINT (705449 4516865)\n5   0.20330568 -0.73921216  Low-Low  Low-Low   Low-Low POINT (681326 4520030)\n6  -0.00244472 -0.61948853  Low-Low  Low-Low   Low-Low POINT (593975 4522166)\n7   0.17087867 -0.31646450       NS  Low-Low   Low-Low POINT (758868 4522277)\n8   0.27739685 -0.58833401  Low-Low  Low-Low   Low-Low POINT (686217 4522281)\n9  -0.20533533 -0.18335013       NS High-Low High-High POINT (794466 4524785)\n10  0.17227708 -0.13938989  Low-Low  Low-Low   Low-Low POINT (620133 4526863)\n\n\nPor último, ploteamos la figura con tmap, tm_shape() y tm_dots():\n\n# plot dels resultats\n\ntm_shape(lisa) +\n    tm_dots(col = \"mean\",\n          style = \"cat\",\n          palette= c(\"NS\"=\"grey\",\n                     \"Low-Low\" = \"blue\",        # Low-Low\n                     \"Low-High\" = \"lightblue\",  # Low-High \n                     \"High-Low\"= \"sienna1\",     # High-low\n                     \"High-High\"=\"red\"),        # High -High\n              size = 0.5) +\ntm_shape(provincias)+\n    tm_borders()\n\n\n\n\n\n\n7.5.1.4 Mapa de significación\nOtro elemento interesante es producir un mapa de significación. Para ello establecemos las categorías de significación que queramos, y ploteamos su distribución espacial. Por ejemplo, vamos a crear 4 categorías:\n\nNo significativo (P &gt; 0.05)\n0.01 &lt; P &lt; 0.05\n0.001 &lt; P &lt; 0.01\nP &lt; 0.001\n\n\nlisa$sign &lt;- ifelse(lisa$p_ii &lt; 0.001, \"p&lt;0.001\",\n                         ifelse(lisa$p_ii &lt; 0.01, \"p&lt;0.01\",\n                                ifelse(lisa$p_ii &lt; 0.05, \"p&lt;0.05\",\n                                \"NS\")))\n\nY creamos el mapa de manera muy similar:\n\ntm_shape(lisa) +\n    tm_dots(col = \"sign\",\n          style = \"cat\",\n          palette= c(\"NS\"=\"grey\",\n                     \"p&lt;0.001\"= \"darkgreen\",\n                     \"p&lt;0.01\" = \"green\",\n                     \"p&lt;0.05\" =  \"lightgreen\"), \n          title = \"Nivel de significación\",\n          size = 0.5) +\n    tm_shape(provincias) +\n    tm_borders()\n\n\n\n\nY como curiosidad, hasta podríamos crear un visor con esta información\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(lisa) +\n    tm_dots(col = \"mean\",\n          style = \"cat\",\n          palette= c(\"NS\"=\"grey\",\n                     \"Low-Low\" = \"blue\",        # Low-Low\n                     \"Low-High\" = \"lightblue\",  # Low-High \n                     \"High-Low\"= \"sienna1\",     # High-low\n                     \"High-High\"=\"red\"),        # High -High\n          title = \"LISA con p &gt; 0.1\") +\n    tm_shape(provincias) +\n    tm_borders(col=\"white\") +\n    tm_basemap(leaflet::providers$Esri.WorldImagery)\n\n\n\n\n\n\n\n\n\n7.5.2 I local de Anselin con ArcGis Pro\nArcMap permite realizar el equivalente a un análisis cluster LISA de Anselin con suma facilidad. Para ello debemos seleccionar la herramienta Cluster and Outlier Analysis (Anselin Local Moran’s I) que se encuentra en el menú Spatial Statistics Tools/Mapping Clusters.\n\nEl proceso que sigue ArcMap es similar: calcula la I local, los z-scores, el p-valor, y finalmente realiza una agrupación en clusters como hemos visto antes:\n\nSin embargo, hay que poner atención en un aspecto: ArcMap identifica los puntos con un sistema de colores inverso al que hemos visto anteriormente. Para ArcMap, los valores High-Low y Low-High son outliers, y por lo tanto los identifica con colores más vivos, mientras que los High-High y Low-Low, que son los que se destacan normalmente en un análisis LISA, aquí se representan con tonos más pálidos.\n\n\n\n7.5.3 I local de Anselin con GeoDa\nIgual que hicimos antes, vamos a ver como realizar un análisis LISA con GeoDa, en lugar de hacerlo con QGis. Como no podía ser de otra manera este es uno de los puntos fuertes de este software, creado por el propio Luc Anselin. Para ello debemos buscar el comando Univariate Local Moran's I, en el menú Space. Seleccionando la variable de interés y el fichero de vecinos, podemos generar todos los elementos del LISA. Uno de los atractivos de GeoDa es que estos gráficos son interactivos y están conectados, de manera que seleccionar unos puntos en uno de ellos resalzará los mismos puntos en el resto de gráficos:\n\nPor supuesto, estas no son las únicas funcionalidades de GeoDa, como veremos más adelante durante el curso."
  },
  {
    "objectID": "05_PatronPuntos.html#introducción",
    "href": "05_PatronPuntos.html#introducción",
    "title": "8  Análisis de patrón de puntos en R",
    "section": "8.1 Introducción",
    "text": "8.1 Introducción\nComo vimos en clase, un conjunto de datos de patrones de puntos contiene una serie de eventos (es decir, objetos de interés) que ocurren en una región de estudio definida. Estos eventos pueden representar cualquier cosa con una ubicación medible, incluyendo árboles, nidos de animales, ubicaciones de estaciones meteorológicas, ocurrencias de delitos, etc. sin que exista necesariamente una variable de interés. Es decir, lo que nos interesa es la ubicación de los eventos más que su valor.\nComo hemos visto, los patrones de puntos tienen propiedades de primer orden, que están relacionadas con la intensidad (es decir, la densidad) de los sucesos en la región de estudio, y propiedades de segundo orden, que están relacionadas con la dependencia espacial (es decir, la disposición espacial) de los sucesos en la zona de estudio.\nObjetivo\nEl objetivo del lab de hoy es aprender algunos enfoques estadísticos espaciales para caracterizar las propiedades de primer y segundo orden de un patrón de puntos.\nDatos y librerías\nPara realizar un análisis de patrón de puntos utilizaremos fundamentalmente el paquete de R spatstat. Lo primero que debemos hacer es instalarlo - a no ser que ya lo tengamos instalado - y cargarlo:\n\n#install.packages(\"spatstat\") (sólo si no está ya instalado)\nlibrary(spatstat)\n\nAdemás, vamos a utilizar tres de los datasets que vienen cargados por defecto por la librería spatstat. El primero, llamado bei, contiene la localización de 3605 árboles en una parcela de bosque tropical. Además, viene acompañado del fichero bei.extra, que contiene información continua acerca de la altitud y la pendiente en la parcela de estudio. El segundo dataset que usaremos se llama longleaf, y es un fichero de patrón de puntos “marcado”, es decir que contiene la localización de una serie de pinos de Virginia (longleaf pine), una especie común en el sudeste de EEUU, pero también contiene su diámetro, por eso decimos que es un fichero “marcado”. Finalmente, el fichero llamado lansing contiene la ubicación de una serie de 5 especies de árboles en una parcela de Lansing, en el estado de Michigan.\n\n\n\n\n\n\n\n\n\n\n\nNOTA: al plotear los ficheros precargados del paquete spatstat podemos definir algunos parámetros de los puntos, como hacemos con un scatterplot normal. En este caso hemos modificado el tipo de puntos, su tamaño y el color, mediante los comandos pch ,cex, y cols, respectivamente. Podéis encontrar más información de como modificar los parámetros de un gráfico aquí"
  },
  {
    "objectID": "05_PatronPuntos.html#familiarizándose-con-los-objetos-ppp",
    "href": "05_PatronPuntos.html#familiarizándose-con-los-objetos-ppp",
    "title": "8  Análisis de patrón de puntos en R",
    "section": "8.2 Familiarizándose con los objetos `ppp`",
    "text": "8.2 Familiarizándose con los objetos `ppp`\nEl paquete spatstat usa una clase específica de objetos de R llamados ppp (planar point pattern). Los datos que vamos a usar, que se cargan automáticamente al instalar spatstat son objetos de esa clase.\nExaminemos el dataset bei. Para ello devemos abrirlo tecleando:\n\ndata(bei)\n\nY podemos ver su contenido tecleando su nombre:\n\nbei\n\nPlanar point pattern: 3604 points\nwindow: rectangle = [0, 1000] x [0, 500] metres\n\n\nVemos que es un archivo de patrón de puntos con 3604 observaciones. El objeto ppp también contiene información sobre la región que contiene los eventos. En este caso, es un rectángulo con un rango de coordenadas \\(x\\) de entre 0 y 1000 , y un rango de \\(y\\) de entre 0 y 500, y las unidades en metros.\nPodemos visualizar el objeto bei escribiendo:\n\nplot(bei)\n\n\n\n\nIgual que hemos hecho hasta ahora, podemos cambiar el color, formato de los puntos, y otras características del plot\n\nplot(bei, pch = 20, cols = \"dark blue\")"
  },
  {
    "objectID": "05_PatronPuntos.html#estadísticas-descriptivas-centrografía",
    "href": "05_PatronPuntos.html#estadísticas-descriptivas-centrografía",
    "title": "8  Análisis de patrón de puntos en R",
    "section": "8.3 Estadísticas descriptivas (centrografía)",
    "text": "8.3 Estadísticas descriptivas (centrografía)\nLos estadísticos centrográficos son estadísticos descriptivos simples que se utilizan a menudo para el análisis exploratorio de datos en la estadística espacial. Los estadísticos centrográficos, como la posición central, la desviación estándar, la elipse de desviación estándar pueden utilizarse para ayudar a la caracterización de la distribución espacial de los conjuntos de datos referenciados espacialmente.\nEn \\(R\\) podemos calcular por ejemplo la posición media y mediana de los puntos, lo haremos con el dataset bei:\n\nx_media &lt;- mean(bei$x)\ny_media &lt;- mean(bei$y)\n\nx_mediana &lt;- median(bei$x)\ny_mediana &lt;- median(bei$y)\n\ny representarlo gráficamente sobre los puntos:\n\nplot(bei, pch = 20, cex = 0.5)\npoints(x_media, y_media, col = \"red\", pch = 3, lwd=2)\npoints(x_mediana, y_mediana, col = \"green\", pch = 4, lwd= 2)\n\n\n\n\nTambién podemos calcular la desviación estándard y usarla para construir un círculo con ese radio:\n\nx_sd &lt;- sd(bei$x)\ny_sd &lt;- sd(bei$y)\n\nsd_bei = mean(x_sd, y_sd)\n\nY plotearlo, pero para dibujar un círculo necesitamos la función draw.circle() del paquete plotrix:\n\nlibrary(plotrix)\nplot(bei, pch = 20, cex = 0.5)\npoints(x_media, y_media, col = \"red\", pch = 3, lwd=2)\ndraw.circle(x= x_media, y = y_media, border = \"red\", \n            radius = sd_bei, lwd = 2)\n\n\n\n\nEn ArcGis Pro y QGis también existen funciones para realizar este tipo de análisis y visualización. En concreto, podemos usar las funciones mean center, o standard distance dentro del toolbox Spatial Statistics. Incluso podemos dibujar la elipse de desviación estandard mediante la función directional distribution."
  },
  {
    "objectID": "05_PatronPuntos.html#análisis-basados-en-densidad",
    "href": "05_PatronPuntos.html#análisis-basados-en-densidad",
    "title": "8  Análisis de patrón de puntos en R",
    "section": "8.4 Análisis basados en densidad",
    "text": "8.4 Análisis basados en densidad\n\n8.4.1 Intensidad global\nComo hemos visto en la teoría, la intensidad de un proceso expresado en patrón de puntos puede calcularse a través de la siguiente ecuación:\n\\(\\lambda = {n}/{a}\\)\ndonde \\(\\lambda\\) es la intensidad, \\(n\\) es el número de observaciones y \\(a\\) la superficie considerada como área de estudio. Conociendo estos dos parámetros podemos calcular la intensidad:\nEl número de observaciones es un parámetro del objeto ppp:\n\nn_obs &lt;- bei$n\n\ny el área lo podemos obtener también de un objeto ppp:\n\nbei$window\n\nwindow: rectangle = [0, 1000] x [0, 500] metres\n\nsuperf &lt;- area(bei$window)\nsuperf\n\n[1] 5e+05\n\n\nPor tanto la intensidad será:\n\nintens_bei &lt;- n_obs / superf\nintens_bei\n\n[1] 0.007208\n\n\nSin embargo, spatstat ya proporciona una función summary() que nos proporciona información de la muestra, entre ella la intensidad:\n\nsummary(bei)\n\nPlanar point pattern:  3604 points\nAverage intensity 0.007208 points per square metre\n\nCoordinates are given to 1 decimal place\ni.e. rounded to the nearest multiple of 0.1 metres\n\nWindow: rectangle = [0, 1000] x [0, 500] metres\nWindow area = 5e+05 square metres\nUnit of length: 1 metre\n\n\nTambién podemos acceder a la intensidad de forma directa:\n\nsummary(bei)$intensity\n\n[1] 0.007208\n\n\n\n\n\n8.4.2 Análisis de cuadrículas\nCalcular la intensidad global de un proceso de puntos puede tener interés para comparar dos muestras diferentes, o cambios temporales, pero para caracterizar de forma más completa la muestra debemos determinar cómo varía la intensidad en el espacio. Una forma sencilla es a través del conteo por cuadrículas. Consiste en dividir el área de estudio en una serie de cuadrículas de tamaño constante, y calcular la intensidad en cada una de ellas. El resultado nos puede ayudar a determinar si el patrón de eventos está distribuido regularmente o de manera agrupada. spatstat contiene una función (quadratcount()) que nos permite calcularlo de manera muy sencilla.\n\nq &lt;- quadratcount(bei, nx= 4, ny = 4)\nq\n\n           x\ny           [0,250) [250,500) [500,750) [750,1e+03]\n  [375,500]     368       506        64         287\n  [250,375)     298       171        66         194\n  [125,250)     324        27        54         178\n  [0,125)       220       138       589         120\n\n\nTambién podemos visualizarlo:\n\nplot(bei, cols = \"gray\", pch = 20, cex = 0.5)\nplot(q, add = T)\n\n\n\n\nEn las sesiones teóricas vimos que la hipótesis nula en el caso de una distrbución de puntos es que estos se encuentran repartidos aleatoriamente en las cuadrículas. Sabiendo la intensidad de la muestra, podemos generar una serie de puntos aleatorios, que sigan una distribución de Poisson. Este numero de eventos, que sería el esperado en una muestra que cumpla la aleatoriedad, se compara con lo que realmente tenemos (observado) mediante un test de Chi-cuadrado, que en spatstat viene implementado en la función quadrat.test(), que se puede usar con el objeto ppp o con el resultado de quadratcount():\n\nquadrat.test(bei, nx= 4, ny = 4)\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  bei\nX2 = 1754.6, df = 15, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 4 by 4 grid of tiles\n\nquadrat.test(q)\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  \nX2 = 1754.6, df = 15, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 4 by 4 grid of tiles\n\n\nEn este caso, vemos que el p-valor es claramente inferior a 0.05, por lo que podemos rechazar la hipótesis nula, y por tanto decidir que los puntos no se distribuyen aleatoriamente. También podemos ver este resultado de manera gráfica:\n\nplot(quadrat.test(bei, nx = 4, ny = 4))\n\n\n\n\nPodemos por supuesto cambiar el número de cuadrículas a nuestro antojo:\n\nQ9 &lt;- quadratcount(bei, nx = 3, ny = 3)\nplot(bei, cex = 0.5, pch = \"+\")\nplot(Q9, add = TRUE, cex = 2)\n\n\n\nquadrat.test(Q9)\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  \nX2 = 1166.1, df = 8, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 3 by 3 grid of tiles\n\nQ24 &lt;- quadratcount(bei, nx = 6, ny = 4)\nplot(bei,  cex = 0.5, pch = \"+\")\nplot(Q24, add = TRUE, cex = 1.5)\n\n\n\nquadrat.test(Q24)\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  \nX2 = 2222, df = 23, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 6 by 4 grid of tiles\n\nQ120 &lt;- quadratcount(bei, nx = 10, ny = 12)\nplot(bei, use.marks = F, cex = 0.5, pch = \"+\")\nplot(Q120, add = TRUE, cex = 0.8)\n\n\n\nquadrat.test(Q120)\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  \nX2 = 3558.8, df = 119, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 10 by 12 grid of tiles\n\n\nTambién podemos calcular la densidad de puntos en cada cuadrado, en vez del número total:\n\nq_dens &lt;- intensity(Q9)\nq_dens\n\n           x\ny            [0,333) [333,667) [667,1e+03]\n  [333,500] 0.017010  0.004230    0.006714\n  [167,333) 0.008478  0.001242    0.004932\n  [0,167)   0.006570  0.008964    0.006732\n\n\nY plotearlo:\n\nplot(intensity(Q9, image=TRUE))  \nplot(bei, use.marks = F, pch=20, add=TRUE)  \n\n\n\n\n\n\n\n8.4.3 Análisis de cuadrículas basadas en covariable\nA menudo, más que dividir el terreno en un número de cuadrículas regulares, nos interesa dividirlo según alguna variable continua de interés, que pensemos que puede explicar la distribución. Ya comentamos que spatstat proporciona, junto con el dataset bei, otro llamado bei.extra que contiene los valores de altitud y pendiente en la misma parcela. Echémosles un vistazo:\n\nbei.extra\n\nList of pixel images\n\nelev:\nreal-valued pixel image\n101 x 201 pixel array (ny, nx)\nenclosing rectangle: [-2.5, 1002.5] x [-2.5, 502.5] metres\n\ngrad:\nreal-valued pixel image\n101 x 201 pixel array (ny, nx)\nenclosing rectangle: [-2.5, 1002.5] x [-2.5, 502.5] metres\n\nplot(bei.extra$elev)\n\n\n\nplot(bei.extra$grad)\n\n\n\n\nVeamos como se distribuyen los puntos en clases de pendiente. Para ello debemos reclasificar el raster de elevaciones en 5 clases: &lt;130, 130 a 140, de 140 a 150, de 150 a 160, y &gt;160. Para ello usaremos la función cut():\n\nplot(bei.extra$elev)\n\n\n\nclases_elev &lt;- cut(bei.extra$elev, breaks = c( -Inf, 130, 140, 150, 160 , Inf), \n              labels=1:5)  # Classify the raster\nplot(clases_elev)\n\nInterpreting pixel values as colours (valuesAreColours=TRUE)\n\n\n\n\n\n\n\n\n\n\nAhora usamos de nuevo la función quadratcount. pero indicando que queremos “teselar” por las clases de elevación:\n\nQ_tes   &lt;- quadratcount(bei, tess = clases_elev)  \nI_tes &lt;- intensity(Q_tes)  # Compute density\nI_tes\n\ntile\n          1           2           3           4 \n0.002415371 0.006514200 0.008701685 0.005409613 \n\n\nEstos números son el número de puntos por metro cuadrado en cada clase de elevación. Podemos visualizarlo como antes:\n\nplot(intensity(Q_tes, image=TRUE))\nplot(bei, pch=20, add=TRUE)\n\n\n\n\nY también podemos realizar un test estadístico de este conteo:\n\nquadrat.test(Q_tes)\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  \nX2 = 232.08, df = 3, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nQuadrats: 4 tiles (levels of a pixel image)\n\n\n\n\n\n8.4.4 Densidad en kernel\nEl recuento de cuadrículas es útil para caracterizar la intensidad de un proceso puntual no homogéneo, pero tiene sus limitaciones:\n\nLa elección del origen, la orientación de las cuadrículas y el tamaño de los mismos afecta a la distribución de frecuencias observada, y no deja de ser una decisión arbitraria.\nSe pierde una cantidad significativa de información de detalle\n\nPara evitar el problema podemos hacer un análisis mediante algoritmos KDE (kernel density estimation), que utilizan un enfoque de ventana móvil para caracterizar la intensidad. Este enfoque tiende a preservar una mayor cantidad de detalles espaciales y no sufre tanto por la elección del origen, la orientación y el tamaño de las cuadrículas.\nEl paquete spatstat tiene una función (density) que calcula un kernel a partir del patrón de puntos, y determina la densidad de puntos de cada celda del área de estudio según ese kernel.\n\nK1 &lt;- density(bei) \nplot(K1)\n\n\n\n\nPara mejorar la visualización podemos añadirles las isolíneas de densidad, y los puntos, para comprobar el resultado:\n\nplot(K1)\ncontour(K1, add=TRUE)\nplot(bei, pch=20, add=TRUE)\n\n\n\n\nEl ancho de banda (es decir, el radio) de la función kernel se define automáticamente en función del área de estudio, pero se puede personalizar también, usando el parámetro sigma:\n\nK2 &lt;- density(bei, sigma=200) \nplot(K2, main=NULL)\ncontour(K2, add=TRUE)\nplot(bei, pch=20, add=TRUE)\n\n\n\n\n\nAntes hemos visto cómo crear cuadrículas en función de los valores de una covariable. Podemos aprovechar las funcionalidades de los cálculos de intensidad con kernel para determinar de manera directa si la intensidad de un proceso de patrón de puntos depende de alguna covariable. Podemos usar la función rhohat(), indicando qué dataset queremos analizar, y con qué variable se quiere evaluar:\n\nrhohat(bei, bei.extra$grad)\n\nIntensity function estimate (class rhohat) for the covariate X\nFunction values are absolute intensities\nType of estimate: Smooth function of covariate\nEstimation method: ratio of fixed-bandwidth kernel smoothers\n    Actual smoothing bandwidth sigma =  0.010347\nPointwise 95% confidence bands for rho(x)\n     based on asymptotic variance of rhohat(x)\nCall: rhohat.ppp(bei, bei.extra$grad)\n\nFunction value object (class 'fv')\nfor the function X -&gt; rho(X)\n...........................................................................\n    Math.label            Description                                      \nX   X                     Covariate X                                      \nrho hat(rho)(X)           Estimated intensity                              \nave bar(rho)              Average intensity                                \nvar bold(Var)~hat(rho)(X) Variance of estimator                            \nhi  rho[hi](X)            Upper limit of pointwise 95%% confidence interval\nlo  rho[lo](X)            Lower limit of pointwise 95%% confidence interval\n...........................................................................\nDefault plot formula:  .~X\nwhere \".\" stands for 'rho', 'ave', 'hi', 'lo'\nColumns 'hi' and 'lo' will be plotted as shading (by default)\nRecommended range of argument X: [0.00086893, 0.32846]\nAvailable range of argument X: [0.00086893, 0.32846]\n\n\nLa salida de la función rhohat() no es muy clara, pero podemos plotearla:\n\nplot(rhohat(bei, bei.extra$grad))\n\n\n\n\nEl plot es una estimación de la intensidad en función de la pendiente del terreno. Indica que es más infrecuente encontrar árboles en terrenos llanos (pendiente &lt; 0.05) que en zonas de pendientes más altas. La linea negra \\(\\rho\\) es la intensidad estimada, mientras que la región en gris representa el intervalo de confianza."
  },
  {
    "objectID": "05_PatronPuntos.html#análisis-basados-en-la-distancia",
    "href": "05_PatronPuntos.html#análisis-basados-en-la-distancia",
    "title": "8  Análisis de patrón de puntos en R",
    "section": "8.5 Análisis basados en la distancia",
    "text": "8.5 Análisis basados en la distancia\nLos análisis basados en la distancia están relacionados con las propiedades de segundo orden de los puntos, es decir, con la dependencia espacial entre ellos. Existen varios métodos, que evaluaremos de nuevo sobre el fichero bei:\n\n8.5.1 Vecinos más próximos (ANN)\nPodemos calcular la distancia entre cada árbol y su vecino más próximo, usando nndist() y fijando k = 1 (para extraer la distancia al más próximo), y calculamos la media de todas las distancias:\n\ndist1 &lt;- nndist(bei, k=1)\nhead(dist1)\n\n[1] 0.2236068 0.9848858 3.3241540 8.0777472 5.8137767 5.9203040\n\nmean(dist1)\n\n[1] 4.329677\n\n\nTambién podemos calcularlo con el segundo vecino de cada árbol, o con el tercero, o el n-ésimo…\n\nmean(nndist(bei, k=2))\n\n[1] 6.473149\n\nmean(nndist(bei, k=3))\n\n[1] 8.120378\n\nmean(nndist(bei, k=15))\n\n[1] 19.64182\n\n\nCon una función podemos calcular NN para cualquier valor de vecino deseado, y luego calcular la media:\n\nANN &lt;- apply(nndist(bei, k=1:200),2,FUN=mean)\n\nDespués ploteamos la distancia media al vecino k-ésimo, que nos da información sobre cómo se distribuyen los puntos.\n\nplot(seq(1:200), ANN)\n\n\n\n\n\n\n8.5.2 Función \\(G\\) y función \\(F\\)\nPodemos realizar un test más formal de cómo varía la distancia al vecino más próximo, usando la función G(r), que calcula la distribución acumulada de la distancia de un punto cualquiera x a su punto más próximo. El valor de \\(G(r)\\) es la proporción de puntos que tienen su vecino más cercano a una distancia igual o inferior a \\(r\\). Esta función viene implementada en spatstat como Gest():\n\nG_bei &lt;- Gest(bei)\nplot(G_bei)\n\n\n\n\nEl comando de arriba produce un gráfico que compara la función G observada o empírica y la esperada si la distribución fuera aleatoria (linea azul). En este caso, los valores empíricos son muy superiores, lo que indica agrupación en los puntos.\nPara poder saber si las diferencias entre la función empírica y la teórica son significativas (es decir, si realmente podemos rechazar que los puntos se distribuyan al azar), podemos usar la función envelope(). Esta función genera un número de muestras con la misma cantidad de puntos pero distribución aleatoria, y compara nuestra muestra a ellas.\n\ng_bei_env &lt;- envelope(bei, Gest, nsim = 100)\n\nGenerating 100 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, \n100.\n\nDone.\n\nplot(g_bei_env)\n\n\n\n\nVemos que ahora se ha representado una banda gris alrededor de la función G teórica, que indica el intervalo de confianza generado a partir de las 100 simulaciones que hemos realizado (nsim = 100)\nDe manera análoga, la función F representa la frecuencia acumulada de la distancia más corta entre un punto y un conjunto de puntos aleatoriamente localizados en el área de estudio:\n\nf_bei_env &lt;- envelope(bei, Fest, nsim = 100)\n\nGenerating 100 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, \n100.\n\nDone.\n\nplot(f_bei_env)\n\n\n\n\nEn este caso, valores más altos que los teóricos indican patrones regulares (mayor distancia entre puntos), mientras que los más bajos indican agrupación. Como la linea observada va muy por debajo de la teórica, podemos concluir que nuestros puntos están agrupados.\n\n\n8.5.3 Función \\(K\\) y función \\(L\\)\nLa función \\(K\\) calcula, para una serie de bandas concéntricas a cada punto de la muestra, el número de puntos que cae dentro de la banda. Esto nos da un valor de \\(K\\) para cada distancia, valor que siempre debe aumentar con la distancia. Para calcular la función \\(K\\) podemos usar la función de R Kest():\n\nK &lt;- Kest(bei)\n\nnumber of data points exceeds 3000 - computing border correction estimate only\n\nplot(K)\n\n\n\n\nEn este caso, la curva por encima de la teórica (Poisson) indica agrupación de puntos. Podemos calcular el intervalo de confianza igual que hemos hecho antes:\n\nk_bei_env &lt;- envelope(bei, Kest, nsim = 30)\n\nGenerating 30 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, \n30.\n\nDone.\n\nplot(k_bei_env)\n\n\n\n\nLa función \\(L\\), que es sólo una modificación de \\(K\\), se calcula fácilmente, casi de la misma manera:\n\nL &lt;- Lest(bei)\n\nnumber of data points exceeds 3000 - computing border correction estimate only\n\nplot(L, . -r ~ r)\n\n\n\nL_bei_env &lt;- envelope(bei, Lest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_bei_env, . -r ~ r)\n\n\n\n\n\n\n8.5.4 Función de correlación de pares\nLa función de correlación de pares no es más que una version modificada de K en la que se hacen bandas anulares concéntricas.\n\npcf_bei  &lt;- pcf(bei)\nplot(pcf_bei)\n\n\n\npcf_bei_env &lt;- envelope(bei, pcf, nsim = 10)\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nplot(pcf_bei_env)"
  },
  {
    "objectID": "05_PatronPuntos.html#análisis-de-patrones-de-puntos-marcados",
    "href": "05_PatronPuntos.html#análisis-de-patrones-de-puntos-marcados",
    "title": "8  Análisis de patrón de puntos en R",
    "section": "8.6 Análisis de patrones de puntos “marcados”",
    "text": "8.6 Análisis de patrones de puntos “marcados”\nComo vimos en la sesión teórica, un dataset de patrón de puntos contiene una serie de eventos, que son los objetos de interés (árboles, muestras de suelo, nidos, crímenes). Sin embargo a menudo estos puntos llevan asociada alguna variable de interés, que puede ser numérica (diámetro, pH del suelo…) o categórica (especie, tipo de suelo…). Estas variables se llaman marcas y los objetos que contienen puntos con marcas asociadas se llaman patrones de puntos marcados.\nRecordemos que los patrones de puntos tienen propiedades de primer orden, relacionadas con la intensidad (o densidad) de eventos a lo largo y ancho del área de estudio, y propiedades de segundo orden, que hacen referencia a la dependencia espacial entre los eventos.\nAl entrar en juego las marcas, el tipo de preguntas que nos podemos hacer cuando tenemos puntos marcados es variado. Por ejemplo: ¿están relacionadas las ocurrencias de un tipo de evento (por ejemplo, una especie) con las de otro? La distribución de uno de los tipos de evento explica la de otro?\nAhora veremos cómo calcular modelos dependientes de la densidad (mediante kernel) para puntos con diferentes marcas, así como las variantes de los principales métodos dependientes de la distancia (funciones \\(F\\), \\(G\\), \\(K\\) y \\(L\\)). Pero antes, veamos algo más sobre los ficheros de patrón de puntos marcados:\n\n8.6.1 Marcas numéricas\nLas marcas de un fichero de patrón de puntos pueden ser de tipo numérico o categórico. Si recordamos del inicio, el fichero longleaf contiene valores de diámetro de los árboles, y R ya nos indica que contiene marcas numéricas:\n\nlongleaf\n\nMarked planar point pattern: 584 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [0, 200] x [0, 200] metres\n\n\nAdemás, ahora podemos acceder a los valores de las marcas dentro de longleaf:\n\n    longleaf$marks\n\n  [1] 32.9 53.5 68.0 17.7 36.9 51.6 66.4 17.7 21.9 25.7 25.5 28.3 11.2 33.8  2.5\n [16]  4.2  2.5 31.2 16.4 53.2 67.3 37.8 49.9 46.3 40.5 57.7 58.0 54.9 25.3 18.4\n [31] 72.0 31.4 55.1 36.0 28.4 24.8 44.1 50.9 47.5 58.0 36.9 65.6 52.9 39.5 42.7\n [46] 44.4 40.3 53.5 44.2 53.8 38.0 48.3 42.9 40.6 34.5 45.7 51.8 52.0 44.5 35.6\n [61] 19.2 43.5 33.7 43.3 36.6 46.3 48.3 20.4 40.5 44.0 40.9 51.0 36.5 42.1 15.6\n [76] 18.5 43.0 28.9 21.3 30.9 42.7 37.6 47.1 44.6 44.3 26.1 25.9 41.4 59.5 26.1\n [91] 11.4 33.4 35.8 54.4 33.6 35.5  7.4 36.6 19.1 34.9 37.3 16.3 39.1 36.5 25.0\n[106] 46.8 18.7 23.2 20.4 42.3 38.1 17.9 39.7 14.5 33.5 56.0 66.1 26.3 44.8 24.2\n[121] 39.0 15.1 35.6 21.6 17.2 22.3 18.2 55.6 23.3 27.0 50.1 45.5 47.2 37.8 31.9\n[136] 38.5 23.8 46.3  2.8  3.2  5.8  3.5  2.3  3.8  3.2  4.4  3.9  7.8  4.7  4.8\n[151] 44.1 51.5 51.6 33.3 13.3  5.7  3.3 45.9 32.6 11.4  9.1  5.2  4.9 42.0 32.0\n[166] 32.8 22.0 20.8  7.3  3.0  2.2  2.2  2.2 59.4 48.1 51.5 50.3  2.9 19.1 15.1\n[181] 21.7 42.4 40.2 37.4 40.1 39.5 32.5 39.5 35.6 44.1 42.2 39.4 35.5 39.1  9.5\n[196] 48.4 31.9 30.7 15.0 24.5 15.0 22.2 27.5 10.8 26.2 10.2 18.9 44.2 13.8 16.7\n[211] 35.7 12.1 35.4 32.7 30.1 28.4 16.5 12.7  5.5  2.5  3.0  3.2  3.2  4.0  3.6\n[226]  3.8  4.3  3.3  6.3 18.4  5.4  5.4 26.0 22.3 35.2 24.1  6.9 61.0 20.6  6.5\n[241]  2.8  4.8  5.4  4.3  4.0  3.2  2.8  4.9  3.5  2.9  2.4  3.3  2.1  2.0  3.9\n[256]  5.0  2.3  2.2 67.7  2.9  2.4 56.3 39.4 59.5 42.4 63.7 66.6 69.3 56.9 23.5\n[271]  9.1 29.9 14.9 38.7 31.5 27.8 28.5 21.6  2.0  2.6  2.3  3.5  3.6  2.6  2.0\n[286]  2.0  2.7  2.6  2.2  2.7 30.1 16.6 10.4 11.8 32.3 33.5 30.5 10.5 13.8 22.8\n[301] 31.7 10.1 14.5 12.0  2.2  2.3  3.2  3.0 50.6  2.6 50.0 52.2  5.2  5.2  6.7\n[316] 14.0 12.7 59.5 52.0 45.9 18.0 43.5  3.3  4.3  7.4 10.1 23.1  8.1  5.7 13.3\n[331] 12.8 11.6  6.3 20.0  8.9 27.6  4.5  9.2  2.3  5.0  4.0 21.8 10.9 14.9 45.0\n[346] 16.4 43.3 55.6 10.6 45.9 45.2 35.5 43.6 44.6 38.8 34.9 17.0 50.4  2.0 33.8\n[361] 51.1 21.8 46.5  5.6 19.6 32.3  3.7  2.7  2.5  2.5  2.4  7.2  7.0 11.8  8.5\n[376]  9.5  7.0 10.5  6.6  6.6  8.8 11.6 48.2 36.2 44.9 43.0 37.5 31.5 39.9 35.5\n[391] 51.7 36.5 40.2  7.8 17.0 36.4 19.6 15.0 28.8 20.1 39.3 37.9 40.6 33.0 35.7\n[406] 20.6 22.0 16.3  5.6  7.4 42.3 43.8 53.0 48.1 41.9 48.0 75.9 40.4 40.9 39.4\n[421] 40.9 17.6 17.8  3.7 19.0 11.2 27.6 14.5 34.4 20.0  2.9  7.3 52.7  8.7  3.6\n[436]  4.6 11.4 11.0 18.7  5.6  2.1  3.3 11.5  2.6  4.4 18.3  7.5 17.2  4.6 32.0\n[451] 56.7 46.0  7.8 54.9 45.5  9.2 13.2 15.3  8.5  2.2 58.8 47.5 52.2 56.3 39.8\n[466] 38.1 38.9  9.7  7.4 22.1 16.9  5.9 10.5  9.5 45.9 11.4  7.8 14.4  8.3 30.6\n[481] 44.4 38.7 41.5 34.5 31.8 39.7 23.3 37.7 43.0 39.2 40.4 36.7 48.4 27.9 46.4\n[496] 38.5 39.4 50.0 51.6 38.7 39.6 29.1 44.0 50.9 50.8 43.0 44.5 29.8 44.3 51.2\n[511] 37.7 36.8 33.6 47.9 32.0 40.3 42.5 59.7 44.2 30.9 39.5 48.7 32.8 47.2 42.1\n[526] 43.8 30.5 28.3 10.4 15.0  7.4 15.3 17.5  5.0 12.2  9.0  2.4 13.7 13.1 12.8\n[541] 27.0  2.6  4.9 35.0 23.7 42.9 14.2  3.3 28.4 10.0  6.4 22.0  4.3 10.0  9.2\n[556]  3.7 66.7 68.0 23.1  5.7 11.7 40.4 43.3 60.2 55.5 54.1 22.3 21.4 55.7 51.4\n[571] 23.9  5.2  7.6 27.8 49.6 51.0 50.7 43.4 55.6  4.3  2.5 23.5  8.0 11.7\n\n\nY si ploteamos:\n\nplot(longleaf)\n\n\n\n\nVemos que por defecto, el tamaño de los círculos es proporcional a la variable de “marca”, en este caso el diámetro. Podemos cambiar este comportamiento por defecto marcando la opción use.marks a FALSE\n\nplot(longleaf, use.marks = FALSE)\n\n\n\n\nAunque se pueden realizar algunos cálculos con ficheros ppp con marcas numéricas, en realidad esto cae más dentro del campo de la autocorrelación espacial, por lo que no lo trataremos aquí.\n\n\n8.6.2 Marcas categóricas\nEl segundo tipo de marcas posible que podemos encontrar son las marcas categóricas. Es el caso del fichero lansing:\n\nlansing\n\nMarked planar point pattern: 2251 points\nMultitype, with levels = blackoak, hickory, maple, misc, redoak, whiteoak \nwindow: rectangle = [0, 1] x [0, 1] units (one unit = 924 feet)\n\nhead(lansing$marks)\n\n[1] blackoak blackoak blackoak blackoak blackoak blackoak\nLevels: blackoak hickory maple misc redoak whiteoak\n\nplot(lansing)\n\n\n\n\nPor defecto nos separa los distintos niveles de la marca (en este caso la especie) mediante símbolos, pero podemos modificarlo:\n\nplot(lansing, cex = 0.7, pch = 21, bg = c(\"red\", \"purple\", \"green\", \"blue\", \"orange\", \"yellow\"))\n\n\n\n\nTambién podemos obviarlo con la opción use.marks = FALSE\n\nplot(lansing, use.marks = FALSE, pch =19, cex = 0.5)\n\n\n\n\n\n\n8.6.3 Crear objetos ppp con marcas\nComo hemos comentado, las funciones con las que trabajaremos no utilizan ninguno de los formatos de ráster o vectorial que conocemos, sino que utilizan objetos de clase ppp (planar point pattern). Los datasets que usaremos ya vienen en este formato, pero esto no es lo habitual, por lo que en esta sección veremos cómo generar objetos de este tipo a partir de datasets normales.\nUn objeto ppp contiene las coordenadas de los puntos y una”ventana” de análisis (área de estudio). Vamos a cargar los datos ya en el formato necesario. En este caso cargaremos los puntos de un fichero separado por comas disponible en el campus virtual, y llamado finland.csv, que contiene la ubicación de árboles de 4 especies en una parcela de 20x20 m en Finlandia.\n\nfinland_trees &lt;- read.csv(\"./data/finland/finland.csv\")\n\nPodemos ver que el objeto finland_trees tiene 3 columnas, una contiene las coordenadas X, otra las Y, y el tercero contiene la especie de cada árbol. Podemos observarlo mediante:\n\nhead(finland_trees)\n\n          x        y species\n1 1.9119408 19.52381    pine\n2 1.1462073 18.29303    pine\n3 0.4761905 16.76923    pine\n4 3.5391237 19.11355    pine\n5 2.7255319 17.82417    pine\n6 2.2469492 16.24175    pine\n\n\nPara crear un objeto ppp necesitamos usar la función ppp(). Si miramos la ayuda de la función (?ppp) vemos que esta función requiere 4 tipos de información: las coordenadas X, las Y, el tamaño de la “ventana” (la región a estudiar) y las marcas, si es que las hay (los valores asociados a cada evento). Vamos a crear un objeto ppp a partir de finland_trees:\n\nfinland &lt;- ppp(x = finland_trees$x, y = finland_trees$y, \n               window = owin(c(0,20), c(0,20), unitname = \"meters\"),\n               marks = factor(finland_trees$species))\n\nCon el código de arriba definimos las coordenadas x e y para el objeto ppp a partir de las columnas del data frame. La parte del código que dice window = owin define el rango de x e y alrededor de los puntos, y el comando marks = define los valores de las marcas, aunque esto último es opcional.\n\n\n8.6.4 Análisis exploratorio/descriptivo\n¿Cuántos eventos tiene el dataset finland? ¿Cuál es el área de estudio? ¿Cuántas especies diferentes contiene la parcela? ¿Cuál es la densidad relativa de cada una de ellas?\nLas dos primeras son preguntas que ya sabemos responder de ejercicios anteriores. Sin embargo ahora vemos que la función summary() nos devuelve información por marcas:\n\nsummary(finland)\n\nMarked planar point pattern:  168 points\nAverage intensity 0.42 points per square meters\n\nCoordinates are given to 15 decimal places\n\nMultitype:\n      frequency  proportion intensity\naspen         1 0.005952381    0.0025\nbirch        17 0.101190500    0.0425\npine        128 0.761904800    0.3200\nrowan        22 0.130952400    0.0550\n\nWindow: rectangle = [0, 20] x [0, 20] meters\nWindow area = 400 square meters\nUnit of length: 1 meters\n\n\nDel mismo modo, el plot “normal” puede resultar confuso, pero podemos pedirle que nos represente la distribución de cada tipo de evento (en este caso, cada especie):\n\nplot(finland)\n\n\n\nplot(split(finland))\n\n\n\n\n\n\n8.6.5 Efectos de primer orden (dependientes de la densidad)\nVamos a ajustar un análisis de densidad en kernel (ventana móvil para las especies diferentes de las contenidas en nuestra muestra). En realidad es muy sencillo, aprovechando la función split() que hemos visto antes:\n\nplot(density(split(finland)))\n\n\n\n\nLa proporción relativa de la intensidad de cada especie se puede calcular, para hacer que las intensidades estén todas en la misma escala y se puedan comparar los valores:\n\nplot(relrisk(finland), zlim = c(0, 1))\n\nWarning: Negative Likelihood Cross-Validation criterion was minimised at\nleft-hand end of interval [0.155, 7.07]; use arguments 'hmin', 'hmax' to\nspecify a wider interval for bandwidth 'sigma'\n\n\nWarning: Numerical underflow detected: sigma is probably too small\n\n\n\n\n\nAhora los valores son más comparables entre especies, y vemos de manera muy clara la abundancia de pinos, y los pocos chopos (aspen) que hay. Basado en los mapas de densidad, ¿véis alguna especie que se asocie con otra? ¿Y algún tipo de proceso de segregación entre especies?\n\n\n8.6.6 Efectos de segundo orden (dependientes de la distancia)\nIgual que en los eventos de puntos sin marcas, podemos testar las asociaciones entre los distintos tipos de eventos de manera más formal mediante las funciones \\(G\\), \\(F\\), \\(K\\) y \\(L\\). Para cada una de las funciones vistas antes (Gest, Fest, Kest y Lest) existe su variante de tipo cruzado (cross-type), que compara las distribuciones para dos valores de la variable de marca.\nPor ejemplo, para correr un análisis de función G y ver si hay indepencia entre las ubicaciones de pinos y abedules podemos hacer:\n\nplot(Gcross(finland, i = \"birch\", j = \"rowan\"))\n\n\n\n\nLa interpretación es similar a la que hemos visto hasta ahora, de manera que los valores por debajo de la curva teórica indica segregación entre las especies, mientras que valores por encima indican agrupación.\nNótese que debemos especificar los niveles de la muestra a comparar, si no tomará por defecto los dos primeros (ya que las comparaciones sólo pueden hacerse dos a dos)\nTambién podemos construir los intervalos de confianza de manera análoga:\n\n G &lt;- envelope(finland, Gcross, i= \"birch\", j = \"rowan\",\n               nsim = 10)\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nplot(G)\n\n\n\n\nEl resto de funciones asociadas a las propiedades de segundo orden pueden construirse de forma análoga:\n\n# Función K\n K &lt;- envelope(finland, Kcross, i= \"birch\", j = \"rowan\",nsim = 10)\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nplot(K)\n\n\n\n# Función L\nL &lt;- envelope(finland, Lcross, i= \"birch\", j = \"rowan\", nsim = 10)\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\nplot(L)\n\n\n\n# Función de correlación de pares\nplot(pcfcross(finland))"
  },
  {
    "objectID": "05_PatronPuntos.html#conclusiones",
    "href": "05_PatronPuntos.html#conclusiones",
    "title": "8  Análisis de patrón de puntos en R",
    "section": "8.7 Conclusiones",
    "text": "8.7 Conclusiones\nHemos visto como analizar patrones de puntos tanto univariantes como multivariantes (con varios niveles), de manera que hemos aprendido a determinar si la distribución de una serie de puntos es aleatoria, agrupada o dispersa, y a comparar las distribuciones de dos especies mediante diversos estadísticos. Por supuesto, esto es sólo la punta del iceberg de la potencialidad de este tipo de análisis, pero supone una buena base que podemos utilizar para analizar diferentes tipos de datos."
  },
  {
    "objectID": "06_InterpolacionEspacial.html#introducción-y-objetivo",
    "href": "06_InterpolacionEspacial.html#introducción-y-objetivo",
    "title": "9  Interpolación espacial en R",
    "section": "9.1 Introducción y objetivo",
    "text": "9.1 Introducción y objetivo\nHasta ahora, hemos trabajado de varias maneras con el fichero de estaciones meteorólogicas del valle del Ebro (estaciones.shp). En primer lugar, extrajimos los valores de temperatura, así como una serie de predictores (elevación, distancia al Atlántico…) para ajustar modelos de regresión lineal. También utilizamos predictores continuos para generar mapas de temperatura espacialmente continuos, más allá de las zonas donde hay estaciones. Ahora haremos algo parecido, pero en vez de usar las variables explicativas (elevación, etc.) como predictores, vamos a utilizar los valores de temperatura medidos, así como su distribución espacial, para generar mapas continuos de temperatura. Es el proceso que se conoce como interpolación espacial, y veremos varios métodos. Pero antes de nada, debemos cargar las librerías y ficheros de datos necesarios. En este caso, además de los paquetes típicos que solemos usar (tmap, sf, terra…) usaremos la librería gstat\n\nlibrary(tmap)\nlibrary(sf)\nlibrary(terra)\nlibrary(gstat)\n\n\nestaciones &lt;- st_read('data/meteo/meteo_espacial/estaciones_meteo.shp')\n\nReading layer `estaciones_meteo' from data source \n  `C:\\Users\\Usuari\\OneDrive - udl.cat\\Teaching\\EFCN_Geoestadística\\Labs_Geoestadistica_Forestal\\data\\meteo\\meteo_espacial\\estaciones_meteo.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 90 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 574966 ymin: 4514365 xmax: 818327 ymax: 4635648\nProjected CRS: ETRS89 / UTM zone 30N\n\n\nY podemos visualizar los datos, como hemos visto en otras unidades:\n\ntm_shape(estaciones) +\n    tm_dots(col=\"Tmed_MES\", size=0.25, title = \"Temp. media (ºC)\") +\n    tm_text(\"Tmed_MES\", just=\"left\", xmod=.5, size = 0.7) +\n    tm_legend(legend.outside=TRUE)\n\n\n\n\nExisten varios métodos de interpolación de información espacial, y se suelen clasificar en métodos determinísticos y métodos geoestadísticos. Los primeros simplemente realizan una inferencia de la información entre dos puntos “suavizando” la diferencia de valores entre ellos, mientras que los métodos geoestadísticos utilizan las propiedades estadísticas de los valores para realizar la interpolación. Veamos en primer lugar los métodos determinísticos:"
  },
  {
    "objectID": "06_InterpolacionEspacial.html#métodos-determinísticos-de-interpolación",
    "href": "06_InterpolacionEspacial.html#métodos-determinísticos-de-interpolación",
    "title": "9  Interpolación espacial en R",
    "section": "9.2 Métodos determinísticos de interpolación",
    "text": "9.2 Métodos determinísticos de interpolación\nExploraremos dos métodos determinísticos: vecino más próximo (aka Thiessen) y técnicas basadas en asignar pesos según el inverso de la distancia (IDW, de las siglas en inglés de inverse distance weighted).\n\n9.2.1 Método de polígonos de Thiessen o Voronoi (nearest neighbor interpolation)\nEs el método más simple (y más antiguo) de interpolación. Lo introdujo Alfred H. Thiessen hace más de un siglo. El procedimiento consiste en asignar, a cada punto del territorio no muestreado (para el que no tenemos información), el valor del punto muestreado más próximo. Esto genera una superficie teselada en el que las lineas que separan las teselas corresponden a la mitad de la distancia entre dos puntos. Estas líneas se conectan, de manera que cada área comprende uno de los puntos de la muestra.\nVeamos como hacerlo en R, usando la función voronoi() de la librería dismo:\n\nlibrary(dismo)\n\nCargando paquete requerido: raster\n\n\nCargando paquete requerido: sp\n\nthiessen &lt;- voronoi(x = st_coordinates(estaciones))\n\nLoading required namespace: deldir\n\n\nVeamos el objeto que ha generado esta función:\n\nplot(thiessen) +\npoints(estaciones, pch = 19)\n\n\n\n\ninteger(0)\n\n\n\nNOTA: ArcMap también ofrece la posibilidad de realizar una interpolación por polígonos de Thiessen, mediante la función Natural neighbor que se encuentra dentro del módulo Spatial Analyst/Interpolation.\n\n\n\n9.2.2 Inverse Distance Weighted (IDW)\nEl método IDW calcula un valor para cada punto sin él usando valores de los vecinos más próximos. Los pesos asignados a cada vecino son proporcionales a su cercanía al punto del que se quiere obtener el valor, y se pueden modular con el parámetro del exponente. Cuanto mayor sea dicho parámetro, más peso tendrán los puntos cercanos.\nPara poder aplicar el idw, debemos, en primer lugar, crear un grid vacío a partir de un raster, al que después asignaremos los valores que determine la función. Para crear dicho grid y raster debemos seguir los siguientes pasos:\n\n# Creamos el raster vacío, con la misma extensión y crs que nuestros datos\nr &lt;- rast(ext(estaciones), crs = crs(estaciones))\n\n# Definimos la resolución de este raster\nres(r) &lt;- 1000\n\n# Lo convertimos a grid mediante la función `st_as_stars()` del paquete `stars`\nlibrary(stars)\n\nCargando paquete requerido: abind\n\ngrid &lt;- st_as_stars(r, na.rm = FALSE)\n\nWarning: [readValues] raster has no values\n\n\nUna vez generado el objeto grid podemos generar la interpolación, usando la función idw(), del paquete gstat(). Esta función tiene una notación parecida a la de la regresión, ya que debemos especificar una fórmula (en este caso Tmed_MES ~ 1), el dataset donde estan los datos (estaciones), y el objeto para el que queremos generar la interpolación (grid)\n\nidw &lt;- idw(formula = Tmed_MES ~ 1, locations = estaciones, newdata = grid)\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\n[inverse distance weighted interpolation]\n\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\nSin embargo, este objeto no tiene el formato SpatRaster, sino que es un objeto de tipo stars que contiene tanto la predicción como la varianza:\n\nidw\n\nstars object with 2 dimensions and 2 attributes\nattribute(s):\n               Min. 1st Qu.   Median     Mean  3rd Qu.     Max.  NA's\nvar1.pred  15.81822 18.2985 19.97745 19.60785 20.73401 23.46503     0\nvar1.var         NA      NA       NA      NaN       NA       NA 29403\ndimension(s):\n  from  to  offset delta                refsys x/y\nx    1 243  574966  1000 ETRS89 / UTM zone 30N [x]\ny    1 121 4635365 -1000 ETRS89 / UTM zone 30N [y]\n\n\nPara poder visualizar el resultado debemos convertirlo a SpatRaster:\n\nidw_raster &lt;- rast(as(idw, \"Raster\"))\n\nAhora podemos visualizar fácilmente los resultados de la interpolación con plot():\n\nplot(idw_raster$var1.pred)\n\n\n\n\nY añadir los puntos observados:\n\nplot(idw_raster$var1.pred)\npoints(estaciones, pch = 19, cex = 0.8) \n\n\n\n#text(estaciones, label= \"Tmed_MES\", cex = 0.8, pos = 2)\n\nCon esto ya habríamos completado la interpolación espacial usando el método IDW. Podríamos jugar con varios de los parámetros de la función: el número máximo de vecinos a considerar (nmax), o el exponente a usar en la fórmula (idp). Por ejemplo, si usamos un exponente alto:\n\nidw_raster2 &lt;- idw(formula = Tmed_MES ~ 1, locations = estaciones, newdata = grid, idp = 15)\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\n[inverse distance weighted interpolation]\n\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\nplot(idw_raster2)\n\n\n\n\nY si usamos uno muy bajo:\n\nidw_raster3 &lt;- idw(formula = Tmed_MES ~ 1, locations = estaciones, newdata = grid, idp = 0.0001)\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\n[inverse distance weighted interpolation]\n\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\nplot(idw_raster3)\n\n\n\n\nEsto es todo lo que necesitamos saber sobre la interpolación mediante IDW. Este es uno de los métodos más usados, debido a que es simple y en la mayor parte de los casos funciona muy bien. Sin embargo, la elección del exponente no deja de ser subjetiva, y como acabamos de ver puede tener un efecto muy grande en las predicciones. Hay un segundo tipo de interpolaciones que usan la información espacial de los puntos (información de 1r y 2º orden) para derivar modelos probabilísticos con los valores predichos. Son los llamados métodos geoestadísticos.\n\nNOTA: ArcGis y QGis también ofrecen la posibilidad de realizar una interpolación por IDW. En ArcGis Pro se puede hacer mediante la función IDW que se encuentra dentro del módulo Spatial Analyst/Interpolation. Esta función nos permite seleccionar el exponente de la ecuación, el radio de búsqueda de vecinos, definir obstáculos… En QGis se puede obtener mediante la herramienta Spatial Analysis/Interpolation."
  },
  {
    "objectID": "06_InterpolacionEspacial.html#métodos-geoestadísticos-kriging",
    "href": "06_InterpolacionEspacial.html#métodos-geoestadísticos-kriging",
    "title": "9  Interpolación espacial en R",
    "section": "9.3 Métodos geoestadísticos (kriging)",
    "text": "9.3 Métodos geoestadísticos (kriging)\nTras aprender cómo interpolar siguiendo dos de los métodos determinísticos más típicos (polígonos de Thiessen e IDW), es el turno de los métodos geoestadísticos, entre los que el kriging es sin duda el más popular. Esta técnica se basa en modelos probabilísticos para calcular el valor de la variable respuesta en cualquier punto. El kriging se basa en el semivariograma de la variable que se quiere interpolar para ajustar y parametrizar un modelo, así que podríamos decir que funciona mejor cuanto mayor sea la autocorrelación espacial de la variable a interpolar. Es un método que además de generar las predicciones, ofrece también una estimación del error cometido en dichas estimación, lo que nos permite evaluar la calidad de la interpolación. Por último, permite un alto grado de personalización, de manera que con un ajuste adecuado de los parámetros se generan predicciones muy buenas.\nEl proceso es similar al que hemos visto en el ejemplo del IDW, Debemos generar un raster en “blanco” al que luego asignaremos los valores resultantes de la interpolación. La diferencia es que la interpolación porkriging se basa en el semivariograma, y por tanto, debemos generarlo. Los pasos a seguir serán por tanto:\n\nObtener el semivariograma empírico a partir de nuestros datos\nDeterminar los parámetros (rank, nugget, sill) del semivariograma teórico\nAjustar el semivariograma teórico\nAjustar el modelo de kriging\n\n\n9.3.1 Crear el semivariograma observado\nPodemos hacerlo directamente a partir de nuestro fichero de puntos, utilizando la función variogram(). Esta función ploteará el semivariograma a partir de los puntos observados, y podremos determinar los parámetros del semivariograma teórico (rank, nugget, sill). La sintaxis de la función variogram() es similar a la que hemos visto en IDW o en los modelos de regresión.\nMediante el argumento formula podemos definir el tipo de kriging a aplicar (los más típicos son ordinary kriging y universal kriging). En este ejemplo implementaremos un ordinary kriging, por lo que la fórmula será del tipo (&lt;variable&gt; ~ 1). No lo veremos aquí, pero en caso de querer interpilar usando el universal kriging la fórmula sería: &lt;variable&gt; ~ x + y.\nCreemos por tanto el variograma empírico:\n\nve &lt;- variogram(Tmed_MES ~ 1, estaciones)\n\nY podemos visualizarlo:\n\nplot(ve, plot.numbers = T)\n\n\n\n\n\n\n9.3.2 Determinar los parámetros del semivariograma teórico\nTambién podemos inspeccionar el objeto ve que acabamos de crear, para determinar los valores de nugget, sill y rank del semivariograma teórico que tendremos que ajustar:\n\nve\n\n    np      dist     gamma dir.hor dir.ver   id\n1   13  4070.885 0.4638462       0       0 var1\n2   39  9498.495 0.3919231       0       0 var1\n3   59 15232.436 1.4343432       0       0 var1\n4   95 21122.346 1.7738026       0       0 var1\n5  102 27317.811 1.5700490       0       0 var1\n6  121 33297.136 2.1739463       0       0 var1\n7  140 39370.461 2.2399821       0       0 var1\n8  144 45611.788 2.6321094       0       0 var1\n9  165 51476.263 3.2751818       0       0 var1\n10 159 57335.944 3.0017846       0       0 var1\n11 168 63491.985 2.6178571       0       0 var1\n12 173 69434.692 2.9230780       0       0 var1\n13 170 75387.154 2.9578529       0       0 var1\n14 175 81904.971 3.3147429       0       0 var1\n15 181 87630.419 3.7498757       0       0 var1\n\n\nEl nugget será el mínimo valor de gamma (en este caso, 0.3919), el sill se alcanza cuando gamma se estabiliza (3.27518), y el range será la distancia a la que se alcanza el sill (51476.26). Estos números los emplearemos en el siguiente paso, cuando ajustemos el semivariograma teórico.\n\n\n9.3.3 Ajustar el semivariograma teórico\nPara este paso debemos modelizar una curva que ajuste lo mejor posible los valores del semivariograma empírico. Para ello, debemos seleccionar la forma que queremos que tenga el semivariograma, y asignarle los parámetros que hemos definido antes. Podemos acceder al catálogo de formas disponibles mediante:\n\nshow.vgms()\n\n\n\n\nEn este caso vamos a seleccionar la curva de tipo “Exp”, y la aplicaremos con la función fit.variogram():\n\nvt &lt;- fit.variogram(ve, vgm(psill = 3.27518, model = \"Exp\", range = 51476.26, nugget = 0.3919))\nvt\n\n  model       psill    range\n1   Nug 0.009002151     0.00\n2   Exp 3.943178089 43441.23\n\n\nAhora podemos plotearlo, a ver si realmente ajusta bien:\n\nplot(ve, pl = T, model = vt)\n\n\n\n\nVemos que, efectivamente, el ajuste es bastante bueno, por lo que nos conformamos con el semivariograma teórico ajustado.\n\n\n9.3.4 Aplicar el modelo de kriging a los datos:\nA partir de aquí el procedimiento es similar al que hemos visto para IDW: debemos crear un raster vacío con la extensión del área a analizar, y después le asignaremos los valores generados por el kriging. Como antes ya hemos generado el objeto grd, no necesitamos volver a hacerlo, y podemos generar la interpolación, de forma similar a la que hemos visto antes, usando la función krige():\n\nk &lt;- krige(Tmed_MES ~ 1, locations = estaciones, newdata = grid, model = vt)\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\n[using ordinary kriging]\n\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\nEl objeto generado (k) contiene mucha información, pero nos interesa los valores de temperatura predichos para cada punto (columna var1.pred), y la varianza (precisión) de las predicciones (columna var1.var). Igual que antes, debemos transformar este objeto a uno de tipo SpatRaster\n\nk2 &lt;- rast(as(k, \"Raster\"))\n\nVeamos el aspecto de la interpolación generada:\n\nplot(k2$var1.pred, main = \"Predicción\")\n\n\n\n\nIncluso podemos representar encima los puntos observados:\n\nplot(k2$var1.pred, main = \"Predicció\")\npoints(estaciones, pch = 19, cex = 0.8) \n\n\n\n\nEchemos ahora un vistazo a la precisión de las predicciones:\n\nplot(k2$var1.var, main = \"Varianza\")\npoints(estaciones, pch = 19, cex = 0.8) \n\n\n\n\nVemos que el error es mínimo en cada una de las observaciones, y mayor en las zonas donde hay espacios grandes sin datos de estaciones.\nExiste una función que automatiza todo el proceso de ajuste del modelo de kriging, de manera que no hay que determinar los parámetros, la forma, etc. manualmente. Si estáis pensando que podía haber explicado este método desde el principio, tened en cuenta que es importante entender cómo se genera el proceso antes de realizarlo de manera automática. La función en cuestión es autoKrige(), del paquete automap:\n\nlibrary(automap)\nautok &lt;- autoKrige(Tmed_MES ~ 1, estaciones,  grid)\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\n[using ordinary kriging]\n\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\nautok$var_model\n\n  model     psill    range kappa\n1   Nug 0.1569758     0.00   0.0\n2   Ste 3.6365982 52150.83   0.7\n\n\nAdemás, nos genera un output muy adecuado con sólo usar la función plot()\n\nplot(autok)\n\n\n\n\n\nNOTA: ArcGIS y QGis también ofrece la posibilidad de realizar una interpolación por kriging, mediante la función Kriging que se encuentra dentro del módulo Spatial Analyst/Interpolation o Spatial Analysis/Interpolation\n\nEsto es todo lo que necesitamos saber de la interpolación mediante kriging. El hecho de que permita optimizar los parámetros y que nos proporciones estimaciones de la precisión hacen sin duda del kriging el método de interpolación más completo y utilizado.\n\n\n9.3.5 Otros ajustes de kriging\nEl modelo de kriging que hemos usado hasta ahora es un kriging ordinario, lo que se indica al ajustar la función krige(), indicando Tmed_MES ~ 1. Para seleccionar otro tipo de kriging, podemos cambiar la notación de esa fórmula, de acuerdo a lo siguiente:\n\nKriging simple: Z ~ 1 (requiere definir el parámetro beta\nKriging ordinario: Z ~ 1\nKriging universal: Z ~ x + y\n\nVeamos por ejemplo cual sería el resultado de un ajuste por kriging universal, el método más común:\n\nestaciones$x &lt;- st_coordinates(estaciones)[,1]\nestaciones$y &lt;- st_coordinates(estaciones)[,2]\n\nuk &lt;- krige(Tmed_MES~ x + y, locations = estaciones, newdata = grid, model = vt)\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\n[using universal kriging]\n\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\nuk2 &lt;- rast(as(uk, \"Raster\"))\n \nplot(uk2$var1.pred, main = \"Predicción por Universal kriging\")\n\n\n\nauto_uk &lt;- autoKrige(Tmed_MES ~ x + y, estaciones,  grid)\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\n\n[using universal kriging]\n\n\nWarning in asMethod(object): complete map seems to be NA's -- no selection was\nmade\n\nplot(auto_uk)"
  },
  {
    "objectID": "06_InterpolacionEspacial.html#validación-y-métricas-de-calidad-de-los-modelos-de-interpolación",
    "href": "06_InterpolacionEspacial.html#validación-y-métricas-de-calidad-de-los-modelos-de-interpolación",
    "title": "9  Interpolación espacial en R",
    "section": "9.4 Validación y métricas de calidad de los modelos de interpolación",
    "text": "9.4 Validación y métricas de calidad de los modelos de interpolación\nTras haber interpolado en base a dos métodos (IDW y kriging) se hace necesario evaluar cómo de buenas son esas interpolaciones. Esto lo haremos mediante una validación cruzada y el cálculo de una serie de métricas de calidad del modelo:\n\n9.4.1 Validación cruzada\nLa validación cruzada consiste en comparar, para cada valor de la muestra (cada observación) la diferencia entre el valor observado y el predicho por el modelo. Sin embargo, no podemos incluir el punto u observación que queremos evaluar, ya que si no la predicción sería exactamente igual a la observación. Por ello, lo que se hace es ir excluyendo una a una las observaciones, y se determina cuál sería el valor predicho para ese punto por un modelo elaborado con todos los demás puntos. Esto se hace de manera repetitiva - iterativa - con todos los puntos de la muestra, y al final tendremos una serie de valores (residuos) de la diferencia entre el valor observado y el predicho.\nR nos pone fácil realizar la validación cruzada, a través de la función krige.cv(), del paquete gstat. Dicha función requiere como entrada un objeto de tipo gstat en el argumento model:\n\nidw_cv &lt;- krige.cv(formula = Tmed_MES ~ 1, locations = estaciones) \n\nUna vez ajustado, podemos acceder a los datos:\n\nidw_cv\n\nSimple feature collection with 90 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 574966 ymin: 4514365 xmax: 818327 ymax: 4635648\nProjected CRS: ETRS89 / UTM zone 30N\nFirst 10 features:\n   var1.pred var1.var observed   residual zscore fold               geometry\n1   18.19902       NA    15.80 -2.3990215     NA    1 POINT (666121 4514365)\n2   20.96552       NA    22.45  1.4844775     NA    2 POINT (814489 4514857)\n3   17.22110       NA    15.85 -1.3711008     NA    3 POINT (620767 4515276)\n4   18.80757       NA    16.70 -2.1075670     NA    4 POINT (705449 4516865)\n5   17.51609       NA    17.25 -0.2660859     NA    5 POINT (681326 4520030)\n6   17.61897       NA    16.10 -1.5189729     NA    6 POINT (593975 4522166)\n7   19.69973       NA    18.80 -0.8997303     NA    7 POINT (758868 4522277)\n8   17.78630       NA    17.00 -0.7862966     NA    8 POINT (686217 4522281)\n9   20.50400       NA    23.20  2.6960017     NA    9 POINT (794466 4524785)\n10  16.83975       NA    16.30 -0.5397491     NA   10 POINT (620133 4526863)\n\n\nY por tanto representar el gráfico de valores observados y predichos:\n\nplot(idw_cv$observed, idw_cv$var1.pred, main = \"Observed vs. predicted for IDW\") +\nabline(0,1)\n\n\n\n\ninteger(0)\n\n\nEsto mismo lo podemos hacer para el modelo de interpolado mediante ordinary kriging:\n\nok_cv &lt;- krige.cv(formula = Tmed_MES ~ 1, locations = estaciones,  model = vt)\nplot(ok_cv$observed, ok_cv$var1.pred, main = \"Observed vs. predicted for Ordinary kriging\") +\nabline(0,1)\n\n\n\n\ninteger(0)\n\n\n… o el de universal kriging\n\nuk_cv &lt;- krige.cv(Tmed_MES~x+y, locations = estaciones,  model = vt)\nplot(uk_cv$observed, uk_cv$var1.pred, main = \"Observed vs. predicted for Universal kriging\") +\nabline(0,1)\n\n\n\n\ninteger(0)\n\n\n\n\n9.4.2 Métricas de calidad\nLa validación cruzada ya es una pista muy buena de si la interpolación que hemos generado es adecuada o no, ya que nos permite evaluar los sesgos en las predicciones - una predicción no sesgada debería ajustarse de manera simétrica y cercana a la recta 1:1 entre valores observados y predichos-. Pero hay maneras más cuantitativas de realizar una evaluación de la calidad del modelo. Para ello podemos calcular algunos indicadores o métricas:\n\nCorrelación observados-predichos\n\nLógicamente, cuanto mayor sea la correlación entre valores observados y predichos, mejor será el modelo ajustado. Podemos calcularlo para el IDW y el kriging:\n\n# IDW\ncor(idw_cv$var1.pred, idw_cv$observed)\n\n[1] 0.8598952\n\n# Ordinary Krigging\ncor(ok_cv$var1.pred, ok_cv$observed)\n\n[1] 0.8713472\n\n# Universal Krigging\ncor(uk_cv$var1.pred, uk_cv$observed)\n\n[1] 0.8774411\n\n\nVemos que en todos los casos son muy altos, y son valores muy similares.\n\nMedia de los residuos (error medio, ME)\n\nTal y como vimos en la unidad relativa a la regresión lineal, nos interesa aquí que los residuos sean lo más pequeños posible (en valor absoluto) y que además tengan media próxima a cero. Podemos calcular la media:\n\n#IDW\nmean(idw_cv$residual)\n\n[1] -0.07808131\n\n# Ordinary Kriging\nmean(ok_cv$residual)\n\n[1] -0.02131264\n\n# Universal Kriging\nmean(uk_cv$residual)\n\n[1] -0.02044329\n\n\n…y además construir el boxplot o histograma\n\nhist(idw_cv$residual, main = \"Histograma de residuos para IDW\")\n\n\n\nhist(ok_cv$residual,  main = \"Histograma de residuos para ordinary kriging\")\n\n\n\nhist(uk_cv$residual,  main = \"Histograma de residuos para universal kriging\")\n\n\n\n\nVemos también que parecen normales y centrados en el cero.\n\nMedia estandarizada del error de predicción (mean square predictor error; MSPE)\n\nEl MSPE es la media del cuadrado de los errores de predicción, es decir, de los residuos. Interesa por tanto que sea lo más pequeño posible:\n\n# Para IDW\nmean(idw_cv$residual^2)\n\n[1] 1.254002\n\n# Para ordinary Kriging\nmean(ok_cv$residual^2)\n\n[1] 1.030548\n\n# Para universal Kriging\nmean(uk_cv$residual^2)\n\n[1] 0.98516\n\n\n\nRaíz del error cuadrático medio (Root of Mean Squared Error; RMSE):\n\nEl RMSE es una medida muy común de performance de un modelo. Es la raíz del cociente entre la suma de los cuadrados de los residuos y el número de observaciones. Tiene la ventaja de que está en las mismas unidades que la variable respuesta, por lo que su valor es fácilmente interpretable como una especie de “error medio” en las predicciones:\n\n# Para IDW\nsqrt(sum(idw_cv$residual^2)/length(idw_cv$residual))\n\n[1] 1.119822\n\n# Para ordinary kriging\nsqrt(sum(ok_cv$residual^2)/length(ok_cv$residual))\n\n[1] 1.015159\n\n# Para universal kriging\nsqrt(sum(uk_cv$residual^2)/length(uk_cv$residual))\n\n[1] 0.9925523\n\n\nPodemos incluso hacer una tabla resumen con los parámetros:\n\n\n\n\n\nMetodo\nCorrelacion\nME\nMSPE\nMRSE\n\n\n\n\nIDW\n0.8598952\n-0.0780813\n1.254002\n1.1198223\n\n\nOrdinary kriging\n0.8713472\n-0.0213126\n1.030548\n1.0151591\n\n\nUniversal kriging\n0.8774411\n-0.0204433\n0.985160\n0.9925523\n\n\n\n\n\nEn este caso, todos los indicadores parecen favorecer el kriging: los residuos son más bajos, las métricas de error también, y la correlación entre valores observados y predichos es ligeramente mejor. Por tanto, consideraremos que esta interpolación es más adecuada que la de IDW. En concreto, el universal kriging parece ser el método que produce las mejores predicciones (aunque por poco, los tres métodos son bastante similares)."
  },
  {
    "objectID": "07_RegresionEspacial.html#introducción.-regresión-lineal-y-estructura-espacial",
    "href": "07_RegresionEspacial.html#introducción.-regresión-lineal-y-estructura-espacial",
    "title": "10  Regresión espacial en R",
    "section": "10.1 Introducción. Regresión lineal y estructura espacial",
    "text": "10.1 Introducción. Regresión lineal y estructura espacial\nEn las unidades acerca de la regresión lineal hemos visto que uno de los supuestos que deben cumplir los datos es el de independencia de los residuos. Sin embargo, sabemos por la primera ley de la geografía que las observaciones más próximas suelen ser más similares entre sí. De hecho, en el momento en que nuestros datos presenten algún tipo de estructura espacial, se inclumplirá muy probablemente el supuesto de independencia, ya que los residuos del modelo fácilmente estarán espacialmente autocorrelacionados.\nCuando realizamos una regresión lineal solíamos evaluar las asunciones utilizando los residuos. Tomemos como ejemplo los datos de estaciones meteorológicas que hemos estado trabajando durante el curso. En este caso, como tendremos en cuenta la estructura espacial, usaremos el shapefile:\n\nlibrary(tmap)\nlibrary(sfdep)\nlibrary(spdep)\nlibrary(spatialreg)\nlibrary(spgwr)\n\n\nestaciones &lt;- st_read('data/meteo/meteo_espacial/estaciones_meteo.shp') \n\nReading layer `estaciones_meteo' from data source \n  `C:\\Users\\Usuari\\OneDrive - udl.cat\\Teaching\\EFCN_Geoestadística\\Labs_Geoestadistica_Forestal\\data\\meteo\\meteo_espacial\\estaciones_meteo.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 90 features and 13 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 574966 ymin: 4514365 xmax: 818327 ymax: 4635648\nProjected CRS: ETRS89 / UTM zone 30N\n\nprovincias &lt;- st_read('data/meteo/meteo_espacial/provincias_spain.shp') \n\nReading layer `provincias_spain' from data source \n  `C:\\Users\\Usuari\\OneDrive - udl.cat\\Teaching\\EFCN_Geoestadística\\Labs_Geoestadistica_Forestal\\data\\meteo\\meteo_espacial\\provincias_spain.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 51 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -14129.47 ymin: 3892590 xmax: 1126923 ymax: 4859517\nProjected CRS: ETRS89 / UTM zone 30N\n\n\nVamos a ajustar un modelo de regresión lineal normal, como hacíamos en la primera unidad del curso. En este caso, usaremos como variable dependiente T_MAX_abs, la temperatura máxima absoluta del mes de junio en cada estación, y como variable explicativa, la elevación:\n\nmod_lm &lt;- lm(T_MAX_abs ~ ALTITUD, data = estaciones)\nsummary(mod_lm)\n\n\nCall:\nlm(formula = T_MAX_abs ~ ALTITUD, data = estaciones)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6521 -0.9053  0.0539  1.0965  4.7273 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.6718641  0.3208108 114.310  &lt; 2e-16 ***\nALTITUD     -0.0049314  0.0005468  -9.019 3.75e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.533 on 88 degrees of freedom\nMultiple R-squared:  0.4804,    Adjusted R-squared:  0.4745 \nF-statistic: 81.35 on 1 and 88 DF,  p-value: 3.746e-14\n\nplot(mod_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVemos que el modelo parece adecuado: la variable predictora es significativa, el modelo no presenta problemas de falta de normalidad o heterocedasticidad, y además explica casi el 50% de la variabilidad en temperatura. Con lo visto hasta ahora, aceptaríamos el modelo sin ningún problema.\nSin embargo, si los datos de origen (las temperaturas) presentan autocorrelación espacial, es muy posible que los residuos del modelo también la presenten. Podemos comprobarlo, de momento visualmente. En primer lugar evaluaremos los valores de temperatura:\n\ntm_shape(estaciones) + \n    tm_dots(col = \"T_MAX_abs\", size = 1) +\n    tm_legend(outside = TRUE, text.size = .8) +\n    tm_shape(provincias) +\n    tm_borders()\n\n\n\n\nEs posible que haya cierta autocorrelación. Ahora veamos lo mismo para los residuos del modelo:\n\n# Guardamos los residuos dentro del dataset espacial\nestaciones$residuals &lt;- residuals(mod_lm)\n\ntm_shape(estaciones) + \n    tm_dots( col = \"residuals\", palette=\"YlGn\", size = 1) +\n    tm_legend(outside = TRUE, text.size = .8) +\n    tm_shape(provincias) +\n    tm_borders()\n\n\n\n\nTambién parece que puede haber cierta autocorrelación en los residuos. Vamos a comprobarlo de manera más cuantitativa. Recordemos, del tema de autocorrelación espacial, que primero debemos crear una lista de vecinos, y luego ya podemos calcular la autocorrelación:\n\nveins &lt;- st_knn(estaciones, k = 10)\n\nUna vez definidos los vecinos podemos ahora testar la autocorrelación de los residuos del modelo de regresión. Para ello usaremos la función lm.morantest(), que tiene como argumentos un modelo de regresión lineal y el listado de vecinos:\n\nlist_veins &lt;- nb2listw(veins)\nlm.morantest(mod_lm, nb2listw(veins))\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = T_MAX_abs ~ ALTITUD, data = estaciones)\nweights: nb2listw(veins)\n\nMoran I statistic standard deviate = 3.8269, p-value = 6.489e-05\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n     0.135013008     -0.018502527      0.001609228 \n\n\nVemos que aunque el valor de la I de Moran es bastante bajo 0.135, sí que resulta significativo, lo que indica que existe una cierta autocorrelación en los residuos. En consecuencia, podríamos decir que el modelo no cumple el principio de independencia de las observaciones, y deberíamos intentar tener en cuenta la estructura espacial de los datos en la regresión."
  },
  {
    "objectID": "07_RegresionEspacial.html#modelos-de-regresión-espacial",
    "href": "07_RegresionEspacial.html#modelos-de-regresión-espacial",
    "title": "10  Regresión espacial en R",
    "section": "10.2 Modelos de regresión espacial",
    "text": "10.2 Modelos de regresión espacial\nAunque la presencia de autocorrelación en los residuos no necesariamente implica que debamos descartar el modelo, sí que podemos intentar ajustar un modelo de regresión que tenga en cuenta la estructura espacial de los datos. En realidad hay dos tipos de modelos, que difieren básicamente en cómo tratan la autocorrelación espacial de los residuos: un modelo de error espacial lo trata como si la agrupación espacial de los residuos fuera algo accidental, que se produce por azar o por variables que no hemos tenido en cuenta. Por otro lado, un modelo de lag espacial simplemente introduce la estructura espacial como un variable explicativa más en el modelo. A menudo la realidad es una combinación de los dos procesos - accidente y causa subyacente -. Podemos ajustar ambos tipos de modelo y tomar la decisión según cuál se ajusta mejor a posteriori.\n\n10.2.1 Modelo de error espacial (Spatial error model)\nVamos a ajustar en primer lugar un modelo de error espacial, que asume que no hay causalidad en la autocorrelación de los residuos. Este modelo se construye como:\n\\(y_i= \\beta_0 + \\beta_1X_1+\\lambda\\omega_i\\xi_i+\\epsilon_i\\)\ndonde el término \\(\\lambda\\omega_i\\xi_i\\) representa la parte “espacial” del error, que se extrae del error y se añade como una variable explicativa implícita.\nPara ajustar este modelo usaremos la función errorsarlm(), del paquete spatialreg. Debemos definir la fórmula de la regresión que queremos ajustar, el dataset (estaciones), y el listado de los vecinos (list_veins)\n\nerror_model &lt;- errorsarlm(formula =T_MAX_abs ~ ALTITUD, data = estaciones, listw = list_veins, zero.policy = T)\n\nsummary(error_model)\n\n\nCall:errorsarlm(formula = T_MAX_abs ~ ALTITUD, data = estaciones, \n    listw = list_veins, zero.policy = T)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-4.17159 -0.81944 -0.10297  0.99736  4.56937 \n\nType: error \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept) 36.77909882  0.47673440 77.1480 &lt; 2.2e-16\nALTITUD     -0.00524450  0.00071829 -7.3014 2.849e-13\n\nLambda: 0.49598, LR test value: 6.6032, p-value: 0.01018\nAsymptotic standard error: 0.15548\n    z-value: 3.1901, p-value: 0.0014223\nWald statistic: 10.177, p-value: 0.0014223\n\nLog likelihood: -161.8396 for error model\nML residual variance (sigma squared): 2.0785, (sigma: 1.4417)\nNumber of observations: 90 \nNumber of parameters estimated: 4 \nAIC: 331.68, (AIC for lm: 336.28)\n\n\nLa salida de este tipo de modelo nos resultará familiar, muy similar a la de un modelo de regresión clásico. Vemos, por ejemplo, los estimadores, errores y significaciones de los coeficientes, igual que en la regresión lineal tradicional (si bien aquí no se añaden estrellas a los p-valores). El coeficiente de ALTITUD es ligeramente diferente que en el modelo tradicional.\nDebajo de esta información sobre los coeficientes tenemos los valores de \\(\\lambda\\), que sería el parámetro que multiplica al término espacial del error que hemos creado, y un test LR (likelihood ratio) para determinar si ese término espacial del error es significativo. Además se compara el modelo ajustado con el modelo de regresión lineal original via el criterio de Información de Akaike (AIC). Finalmente, se utiliza el test de Wald para comprobar si existe dependencia espacial en los residuos del modelo. Los valores significativos (&lt; 0.05) en estos tests indica que aún existe una cierta autocorrelación que queda a pesar de usar el modelo de error espacial. En definitiva, este modelo ha mejorado en cierta medida el ajuste (se puede ver en la comparación del AIC respecto al del modelo lineal), pero que no ha abordado del todo los problemas espaciales que hemos señalado antes.\n\n\n10.2.2 Spatial lag model\nAjustemos ahora un modelo de lag espacial. Este modelo añade una variable independiente adicional, que toma el valor de la media de los vecinos de cada observación. Esta variable no se mostrará en la salida de resultados “estándar”, pero el modelo de spatial lag la incluye pero la deja en un segundo plano. De esta manera, no tratamos la variable dependiente como independiente en cada observación sino que añadimos un término que asume explícitamente que las observaciones son parcialmente dependiente de los vecinos.\n\\(y_i= \\beta_0 + \\beta_1X_1+\\rho\\omega_iy_i+\\epsilon_i\\)\nUn valor positivo de \\(\\rho\\) indica que el valor de \\(y_i\\) aumentará cuando lo hagan los vecinos de \\(x_i\\).\nUsaremos ahora la función lagsarlm(), también del paquete spatialreg, y con la misma notación que antes:\n\nlag_model &lt;- lagsarlm(formula =T_MAX_abs ~ ALTITUD, data = estaciones, listw = list_veins, zero.policy = T)\nsummary(lag_model)\n\n\nCall:\nlagsarlm(formula = T_MAX_abs ~ ALTITUD, data = estaciones, listw = list_veins, \n    zero.policy = T)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-4.162483 -0.928503 -0.019984  1.119895  4.527344 \n\nType: lag \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept) 28.58681365  5.85406512  4.8832 1.044e-06\nALTITUD     -0.00426025  0.00076296 -5.5838 2.353e-08\n\nRho: 0.22604, LR test value: 1.9639, p-value: 0.1611\nAsymptotic standard error: 0.16285\n    z-value: 1.388, p-value: 0.16514\nWald statistic: 1.9265, p-value: 0.16514\n\nLog likelihood: -164.1593 for lag model\nML residual variance (sigma squared): 2.2376, (sigma: 1.4959)\nNumber of observations: 90 \nNumber of parameters estimated: 4 \nAIC: 336.32, (AIC for lm: 336.28)\nLM test for residual autocorrelation\ntest value: 6.1901, p-value: 0.012847\n\n\nAl incluir ese término de lag espacial, vemos que tanto el test de LR como el de Wald ya no detectan autocorrelación espacial. Sin mebargo, en este caso el modelo resulta muy similar al modelo lineal en términos de AIC.\n\n\n10.2.3 Selección del mejor modelo\nSin embargo, no siempre pasa esto. En numerosos casos, ni el modelo de error espacial ni el de lag espacial son capaces de eliminar la autocorrelación, a pesar de reducirla. En otros casos, al contrario, ambos modelos son capaces de considerar y eliminar la autocorrelación.\nPara elegir cuál es el mejor de los dos modelos, podemos usar un multiplicador de Lagrange. Este valor nos indicará si una unidad dada (una estación meteorológica) está aún influenciada por las estaciones a su alrededor incluso después de tener en cuenta y corregir la autocorrelación espacial.En lineas generales, el modelo que presenta un valor mayor del test del Multiplicador de Lagrange es el modelo más adecuado.\nPara ejecutar el test del multiplicador de Lagrange usaremos la función lm.LMtests(), del paquete spatialreg. A esta función le debemos proporcionar como argumentos el modelo original (el que no tiene en cuenta la estructura espacial), el nombre del listado de vecinos, y los tipos de modelos espaciales que queremos testar (en este caso LMerr para el modelo de error espacial, y LMlag para el lag espacial):\n\ntest_Lagrange &lt;- lm.LMtests(model = mod_lm,\n                            listw = list_veins, \n                            test=c(\"LMerr\", \"LMlag\"))\n\nPlease update scripts to use lm.RStests in place of lm.LMtests\n\ntest_Lagrange\n\n\n    Rao's score (a.k.a Lagrange multiplier) diagnostics for spatial\n    dependence\n\ndata:  \nmodel: lm(formula = T_MAX_abs ~ ALTITUD, data = estaciones)\ntest weights: listw\n\nRSerr = 8.9812, df = 1, p-value = 0.002728\n\n\n    Rao's score (a.k.a Lagrange multiplier) diagnostics for spatial\n    dependence\n\ndata:  \nmodel: lm(formula = T_MAX_abs ~ ALTITUD, data = estaciones)\ntest weights: listw\n\nRSlag = 2.4428, df = 1, p-value = 0.1181\n\nsummary(test_Lagrange)\n\n    Rao's score (a.k.a Lagrange multiplier) diagnostics for spatial\n    dependence\ndata:  \nmodel: lm(formula = T_MAX_abs ~ ALTITUD, data = estaciones)\ntest weights: listw\n \n      statistic parameter  p.value   \nRSerr    8.9812         1 0.002728 **\nRSlag    2.4428         1 0.118065   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEn este caso se confirma lo que habíamos visto antes: a pesar de que el modelo de error espacial no soluciona del todo el problema de la autocorrelación, resulta un mejor modelo, y es preferible respecto al modelo de lag espacial."
  },
  {
    "objectID": "07_RegresionEspacial.html#geographically-weighted-regression",
    "href": "07_RegresionEspacial.html#geographically-weighted-regression",
    "title": "10  Regresión espacial en R",
    "section": "10.3 Geographically weighted regression",
    "text": "10.3 Geographically weighted regression\nHemos visto que una tercera opción para tener en cuenta la estructura espacial de los datos es realizar una regresión ponderada geográficamente (geographically weighted regression). GWR es el término introducido por Fotheringham, Charlton y Brunsdon (1997, 2002) para describir una familia de modelos de regresión en los que se permite que los coeficientes varíen espacialmente. GWR funciona moviendo una ventana de búsqueda (kernel) de un punto de la muestra al siguiente, trabajando secuencialmente a través de todos los puntos existentes en el conjunto de datos. A continuación, se ajusta un modelo de regresión a todos los datos contenidos en la ventana identificada alrededor de cada punto, ponderando más los puntos de datos más cercanos al punto de muestra que los más alejados. Este proceso se repite para todos los puntos del conjunto de datos. Para un conjunto de datos de 150 observaciones, GWR ajustará 150 modelos de regresión ponderados. La diferencia de este método respecto a los anteriores es que no asume que la relación entre y y x es constante en toda la zona de estudio, e incluso permite que haya cambios de signo locales en la relación entre ambas. Por todo ello se suele considerar el método más flexible.\n\n10.3.1 Kernel fijo o variable\nUna cuestión clave es decidir entre dos opciones de kernels espaciales: un kernel fijo o un kernel adaptativo o variable. Intuitivamente, un kernel fijo implica el uso de un ancho de banda fijo para definir una región alrededor de cada uno los puntos de regresión, como se muestra en la Figura de abajo. La extensión del kernel viene determinada por la distancia al punto para el que se quiere ajustar la regresión, siendo el kernel idéntico en cualquier punto del espacio. Un kernel adaptativo implica el uso de un ancho de banda variable para definir una región alrededor de los puntos de regresión, tal y como se muestra abajo. La extensión del kernel viene determinada por el número de vecinos más próximos de un punto de regresión dado. Los kernel variables tienen anchos de banda mayores cuando los datos son escasos.\n\n\n\nFig.1 Ejemplo de kernel con amplitud de banda fija\n\n\n\n\n\nFig.2 Ejemplo de kernel con amplitud de banda variable\n\n\n\n\n10.3.2 Optimizando la amplitud de banda del kernel\nEl primer paso para ajustar una GWR es determinar el ancho de banda que se utilizará para seleccionar las sucesivas muestras. Esto lo haremos con la función gwr.sel() del paquete spgwr. Esta función ncesita que le especifiquemos la fórmula del modelo a ajustar y el dataset, pero además tiene un argumento más (adapt) para definir el tipo de ancho de banda a usar para definir la muestra de cada modelo de regresión parcial que ajustemos. Dicho ancho de banda puede ser fijo (adapt = FALSE) o variable (adapt = TRUE).\n\n10.3.2.1 GWR con ancho de banda fijo\nSi ajustamos un ancho de banda fijo el resultado de la función gwr.sel es una distancia de muestreo. Lo que hace la función es ajustar modelos con diferentes anchos de banda y compara los residuos por validación cruzada. El resultado será la distancia que minimiza los residuos.\n\n# Ancho de banda fijo\nkernel_fijo &lt;- gwr.sel(T_MAX_abs ~ ALTITUD, data=estaciones, coords = st_coordinates(estaciones), adapt=FALSE) \n\nBandwidth: 104027.8 CV score: 212.1603 \nBandwidth: 168152.5 CV score: 215.2661 \nBandwidth: 64396.57 CV score: 203.6106 \nBandwidth: 39903.13 CV score: 186.06 \nBandwidth: 24765.35 CV score: 169.7168 \nBandwidth: 15409.69 CV score: 166.0013 \nBandwidth: 12961.17 CV score: 172.8897 \nBandwidth: 19357.41 CV score: 165.7408 \nBandwidth: 21423.06 CV score: 166.9419 \nBandwidth: 17690.01 CV score: 165.2484 \nBandwidth: 17591.82 CV score: 165.2387 \nBandwidth: 17198.02 CV score: 165.2279 \nBandwidth: 16514.94 CV score: 165.3359 \nBandwidth: 17300.12 CV score: 165.2262 \nBandwidth: 17305.09 CV score: 165.2262 \nBandwidth: 17302.89 CV score: 165.2262 \nBandwidth: 17302.89 CV score: 165.2262 \nBandwidth: 17302.89 CV score: 165.2262 \nBandwidth: 17302.89 CV score: 165.2262 \nBandwidth: 17302.89 CV score: 165.2262 \nBandwidth: 17302.89 CV score: 165.2262 \nBandwidth: 17302.89 CV score: 165.2262 \n\nkernel_fijo\n\n[1] 17302.89\n\n\nEn este caso vemos que el ancho previsto son 1.7302891^{4} metros.\nPodemos ahora ajustar el modelo GWR mediante la función gwr, en la que el ancho de banda óptimo anterior se utiliza como entrada en el argumento bandwidth.\n\ngwr.model = gwr(T_MAX_abs ~ ALTITUD, data=estaciones, coords = st_coordinates(estaciones), \n                bandwidth = kernel_fijo, \n                hatmatrix = TRUE, se.fit=TRUE) \n\nVemos que ahora no tenemos un sólo valor de los parámetros del modelo, como habitualmente, sino una serie de valores, de los que el otuput nos informa del mínimo, cuartiles y máximo. Los valores globales de los coeficientes coincidirán con los del modelo de regresión no espacial. Después veremos como interpretar algunos de estos resultados, de momento vamos a tomar los coeficientes, que se guardan en un spatialDataFrame (SDF) dentro del objeto del modelo. Este SDF contiene los coeficientes del modelo (que se guardan con el nombre de la variable a que multiplican), el error estandard de los coeficientes, las predicciones, y los valores de R2 de cada uno de los n modelos ajustados:\n\nView(gwr.model$SDF@data)\n\nPodemos guardar los coeficientes estimados con nuestro dataset original (estaciones), para así poder plotear los valores:\n\nestaciones_gwr &lt;- cbind(estaciones, gwr.model$SDF@data)\n\nPodemos por tanto visualizar los coeficientes estimados por el modelo y ver cómo varían espacialmente:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(estaciones_gwr) +\n    tm_dots(col=\"ALTITUD.1\")\n\nVariable(s) \"ALTITUD.1\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nVemos que, si bien la mayoría de los valores del coeficiente entre altitud y temperatura son negativos (lo que cabría esperar), algunos son incluso positivos. En concreto, los de la zona más norte del valle del Ebro, en la provincia de Zaragoza. Podemos plotear también los valores locales de R2\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(estaciones_gwr) +\n    tm_dots(col=\"localR2\", palette = \"viridis\", style = \"cont\")\n\n\n\n\n\n\nVemos que los valores de R2 son razonablemente altos para la mayoría de los puntos, salvo en una zona del norte del Ebro (no la misma que tenía valores positivos de los coeficientes). En los GWR de ancho de banda fijo, esto pasa a veces en zonas con menor densidad de puntos, donde el modelo se ajusta con menor muestra. Veamos si cambian los resultados con un modelo de ancho de banda variable:\n\n\n10.3.2.2 GWR con ancho de banda variable\nLos anchos de banda variables adaptan su tamaño a la densidad de puntos existente, de manera que se hacen más amplios en las zonas donde hay menos muestra y más estrechos en zonas con más densidad de puntos. Como antes, el primer paso es calcular el valor óptimo:\n\nkernel_variable &lt;- gwr.sel(T_MAX_abs ~ ALTITUD, data=estaciones, \n                           coords = st_coordinates(estaciones),\n                           adapt=TRUE) \n\nAdaptive q: 0.381966 CV score: 210.2743 \nAdaptive q: 0.618034 CV score: 213.1541 \nAdaptive q: 0.236068 CV score: 203.8234 \nAdaptive q: 0.145898 CV score: 195.2934 \nAdaptive q: 0.09016994 CV score: 185.2813 \nAdaptive q: 0.05572809 CV score: 183.4313 \nAdaptive q: 0.05372177 CV score: 183.2515 \nAdaptive q: 0.03320188 CV score: 177.9722 \nAdaptive q: 0.02051989 CV score: 177.9002 \nAdaptive q: 0.02648624 CV score: 176.896 \nAdaptive q: 0.02675132 CV score: 176.7541 \nAdaptive q: 0.02921521 CV score: 176.571 \nAdaptive q: 0.02820316 CV score: 176.4186 \nAdaptive q: 0.02824385 CV score: 176.4199 \nAdaptive q: 0.02808295 CV score: 176.4175 \nAdaptive q: 0.02757431 CV score: 176.4674 \nAdaptive q: 0.02812364 CV score: 176.4173 \nAdaptive q: 0.02812364 CV score: 176.4173 \n\nkernel_variable\n\n[1] 0.02812364\n\n\nEsto quiere decir que el kernel óptimo es el que incluye un 2.8% (3%) de las observaciones vecinas en cada punto. Parece que con considerar los 3 vecinos más próximos a cada estación es suficiente para tener un modelo adecuado. Podemos ahora ajsutar el modelo de ancho variable, con la diferencia que ahora debemos usar el kernel que acabamos de estimar dentro del argumento adapt:\n\ngwr.model_var = gwr(T_MAX_abs ~ ALTITUD, data=estaciones, coords = st_coordinates(estaciones), \n                    adapt =kernel_variable, \n                    hatmatrix = TRUE, se.fit=TRUE) \ngwr.model_var\n\nCall:\ngwr(formula = T_MAX_abs ~ ALTITUD, data = estaciones, coords = st_coordinates(estaciones), \n    adapt = kernel_variable, hatmatrix = TRUE, se.fit = TRUE)\nKernel function: gwr.Gauss \nAdaptive quantile: 0.02812364 (about 2 of 90 data points)\nSummary of GWR coefficient estimates at data points:\n                   Min.    1st Qu.     Median    3rd Qu.       Max.  Global\nX.Intercept. 31.2417729 35.4879874 37.0954469 38.2761989 40.3838836 36.6719\nALTITUD      -0.0140602 -0.0080613 -0.0055531 -0.0021106  0.0131413 -0.0049\nNumber of data points: 90 \nEffective number of parameters (residual: 2traceS - traceS'S): 34.66184 \nEffective degrees of freedom (residual: 2traceS - traceS'S): 55.33816 \nSigma (residual: 2traceS - traceS'S): 1.274504 \nEffective number of parameters (model: traceS): 26.05466 \nEffective degrees of freedom (model: traceS): 63.94534 \nSigma (model: traceS): 1.18563 \nSigma (ML): 0.9993839 \nAICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 333.9131 \nAIC (GWR p. 96, eq. 4.22): 281.3527 \nResidual sum of squares: 89.88913 \nQuasi-global R2: 0.7741255 \n\n\nPodemos guardar los coeficientes estimados con nuestro dataset original (estaciones), para así poder plotear los valores:\n\nestaciones_gwr_var &lt;- cbind(estaciones, gwr.model_var$SDF@data)\n\nVolvamos a visualizar la distribución espacial de los valores estimados, coeficientes y R2 como antes:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(estaciones_gwr_var) +\n    tm_dots(col=\"ALTITUD.1\")\n\nVariable(s) \"ALTITUD.1\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\nQuizá el contraste entre los valores negativos y positivos de los coeficientes sea incluso más marcado. Veamos si se ha mejorado la estimación de R2 de los puntos donde teníamos valores bajos:\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(estaciones_gwr_var) +\n    tm_dots(col=\"localR2\", palette = \"viridis\", style = \"cont\")\n\n\n\n\n\n\nParece que no, por lo que el bajo R2 no se debería a una escasez de datos, sino a que en aquella zona la relación entre altitud y temperatura es más débil. Esto puede tener sentido en zonas llanas junto a los ríos, donde incluso es común tener fenómenos de inversión térmica que trastocan la relación negativa entre ambas variables, la más habitual y esperada."
  }
]